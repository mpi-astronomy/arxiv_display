# Arxiv on Deck 2: Logs - 2025-04-22

* Arxiv had 82 new papers
    * 4 with possible author matches

## Sucessful papers


|||
|---:|:---|
| [![arXiv](https://img.shields.io/badge/arXiv-2504.13999-b31b1b.svg)](https://arxiv.org/abs/2504.13999) | **Multidimensional half-moment multigroup radiative transfer. Improving moment-based thermal models of circumstellar disks**  |
|| <mark>D. M. Fuksman</mark>, <mark>M. Flock</mark>, <mark>H. Klahr</mark>, <mark>G. Mattia</mark>, <mark>D. Muley</mark> |
|*Appeared on*| *2025-04-22*|
|*Comments*| *Submitted to Astronomy & Astrophysics, comments welcome*|
|**Abstract**|            Common radiative transfer methods, such as flux-limited diffusion (FLD) and the M1 closure, suffer from artificial interactions between crossing beams. In protoplanetary disks, this leads to an overestimation of the midplane temperature due to the merging of vertical inward and outward fluxes. Methods that avoid these artifacts typically require angular discretization, which can be computationally expensive. In the spirit of the two-stream approximation, we aim to remove the interaction between beams in a fixed spatial direction by introducing a half-moment (HM) closure, which integrates the radiative intensity over hemispheres. We derive a multidimensional HM closure via entropy maximization and replace it with an approximate expression that closely matches it, coinciding in the diffusion and free-streaming regimes while remaining expressible through simple operations. We implement the HM and M1 closures via implicit-explicit (IMEX) schemes, including multiple frequency groups. We test these methods in numerical benchmarks, including computing the temperature in an irradiated disk around a T Tauri star, comparing the results with Monte Carlo (MC) radiative transfer simulations. The resulting HM closure tends to the correct limit in the diffusion regime and prevents interactions between crossing fluxes in a chosen spatial direction. In disk simulations with 22 frequency groups, the M1 closure disagrees with the MC midplane temperature by up to 21%, while HM reduces this discrepancy to 6%. Even with just 3 frequency groups, HM significantly outperforms M1, with maximum departures of 8% compared to M1's 23%.         |

## Failed papers

### affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found. 


|||
|---:|:---|
| [![arXiv](https://img.shields.io/badge/arXiv-2504.14180-b31b1b.svg)](https://arxiv.org/abs/2504.14180) | **Deep Neural Networks for Modeling Astrophysical Nuclear reacting flows**  |
|| <mark>X. Zhang</mark>, et al. |
|*Appeared on*| *2025-04-22*|
|*Comments*| **|
|**Abstract**|            In astrophysical simulations, nuclear reacting flows pose computational challenges due to the stiffness of reaction networks. We introduce neural network-based surrogate models using the DeePODE framework to enhance simulation efficiency while maintaining accuracy and robustness. Our method replaces conventional stiff ODE solvers with deep learning models trained through evolutionary Monte Carlo sampling from zero-dimensional simulation data, ensuring generalization across varied thermonuclear and hydrodynamic conditions. Tested on 3-species and 13-species reaction networks, the models achieve $\lesssim 1\%$ accuracy relative to semi-implicit numerical solutions and deliver a $\sim 2.6\times$ speedup on CPUs. A temperature-thresholded deployment strategy ensures stability in extreme conditions, sustaining neural network utilization above 75\% in multi-dimensional simulations. These data-driven surrogates effectively mitigate stiffness constraints, offering a scalable approach for high-fidelity modeling of astrophysical nuclear reacting flows.         |
|<p style="color:green"> **ERROR** </p>| <p style="color:green">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |


|||
|---:|:---|
| [![arXiv](https://img.shields.io/badge/arXiv-2504.14836-b31b1b.svg)](https://arxiv.org/abs/2504.14836) | **Systematic search for blue hyper-velocity stars from LAMOST survey**  |
|| Y. Sun, et al. -- incl., <mark>J. Liu</mark>, <mark>J. Shi</mark> |
|*Appeared on*| *2025-04-22*|
|*Comments*| *21 pages, 11 figures, accepted for publication in APJ*|
|**Abstract**|            Hypervelocity stars (HVSs) represent a unique class of objects capable of escaping the gravitational pull of the Milky Way due to extreme acceleration events, such as close encounters with the supermassive black hole at the Galactic center (GC), supernova explosions in binary systems, or multi-body dynamical interactions. Finding and studying HVSs are crucial to exploring these ejection mechanisms, characterizing central black holes, probing the GC environment, and revealing the distribution of dark matter in our galaxy. The Large Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) spectroscopic surveys have so far identified four B-type unbound HVSs. To expand this sample with the second-phase LAMOST survey that started in 2018, we conducted a systematic search for early-type HVSs using the LAMOST Data Release 10. We identified 125 early-type high-velocity candidates with total velocities exceeding 300 km\,s$^{-1}$. Among them, we report ten new unbound B- and A-type hypervelocity star (HVS) candidates (designated LAMOST-HVS5 through LAMOST-HVS14), tripling the number of unbound HVSs previously identified by LAMOST. Kinematic analyses suggest that these newly discovered HVS candidates likely originated either from the Galactic Center or via dynamical interactions. Future high-resolution follow-up observations promise to refine the stellar parameters, distances, and elemental abundances of these candidates, thereby providing deeper insights into their origins and broadening their potential applications across astrophysics.         |
|<p style="color:green"> **ERROR** </p>| <p style="color:green">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |


|||
|---:|:---|
| [![arXiv](https://img.shields.io/badge/arXiv-2504.15086-b31b1b.svg)](https://arxiv.org/abs/2504.15086) | **Configuration Requirements for 21-cm Forest Background Quasar Searches with the Moon-based Interferometer**  |
|| S. Zhang, Q. Niu, Y. Li, <mark>X. Zhang</mark> |
|*Appeared on*| *2025-04-22*|
|*Comments*| *8 pages, 5 figures*|
|**Abstract**|            The 21-cm forest offers a powerful cosmological probe of the thermal history and small-scale structure of the intergalactic medium during the Epoch of Reionization (EoR). Its success, however, critically depends on the availability of high-redshift radio-loud quasars (HzRLQs) as background sources. In this work, we investigate the configuration requirements for a Moon-based low-frequency radio interferometer aimed at maximizing the detection of HzRLQs for future 21-cm forest studies. Building upon a previously developed quasar luminosity function (QLF), we forecast HzRLQ abundances under various array configurations. Assuming a total survey area of $10^4\,\mathrm{deg}^2$ and 1 year of observation, we compare continuum surveys with 10 MHz bandwidth and 21-cm forest surveys with 5 kHz resolution. Our results show that a minimum collecting area of $\sim$6 500 m$^2$ enables detection at $z \sim 6$, while SKA-like arrays ($N_{\mathrm{st}} = 512$) extend the detection limit to $z \sim 10$ for 21-cm forest survey and $z \sim 16$ for continuum survey. Larger arrays with $N_{\mathrm{st}} = 2048$ can reach $z \sim 11$ in 21-cm forest mode. We also explore configurations that maintain fixed collecting areas while increasing the number to enhance survey efficiency. This boosts source detection but significantly increases the data volume and computational demands. These results underscore the importance of optimizing array design for different survey goals and balancing sensitivity, spectral resolution, and data management. A well-designed Moon-based array could open a new observational window on reionization and early cosmic structure formation.         |
|<p style="color:green"> **ERROR** </p>| <p style="color:green">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |

