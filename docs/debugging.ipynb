{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37a5752",
   "metadata": {},
   "source": [
    "# MPIA Arxiv on Deck 2: Debugging notebook\n",
    "\n",
    "In this notebook, I keep some first order commands for diagnostic of issues with papers.\n",
    "Main definitions are taken from the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d232022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 \n",
    "\n",
    "# Some useful definitions.\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf91a3",
   "metadata": {},
   "source": [
    "We get the author list from the MPIA website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -f tmp_mpia_authors.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the list of authors can take sometimes (internet connection)\n",
    "# Caching the MPIA author list to avoid running this line every time we restart the kernel.\n",
    "import yaml\n",
    "try:\n",
    "    with open('tmp_mpia_authors.yml', 'r') as fin:\n",
    "        mpia_authors = yaml.load(fin, yaml.BaseLoader)\n",
    "    print(\"`mpia.get_mpia_mitarbeiter_list()`: restored from cache\")\n",
    "except FileNotFoundError:\n",
    "    print(\"`mpia.get_mpia_mitarbeiter_list()`: cannot be restored from cache.\")\n",
    "    # get list from MPIA website\n",
    "    # it automatically filters identified non-scientists :func:`mpia.filter_non_scientists`\n",
    "    mpia_authors = mpia.get_mpia_mitarbeiter_list()\n",
    "    with open('tmp_mpia_authors.yml', 'w') as fout:\n",
    "        fout.write(yaml.dump(mpia_authors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464cd28",
   "metadata": {},
   "source": [
    "We get the paper to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "which = \"2303.13172\"\n",
    "paper = get_paper_from_identifier(which)\n",
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c199068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check author list with their initials\n",
    "normed_author_list = [mpia.get_initials(k) for k in paper['authors']]\n",
    "normed_mpia_authors = [k[1] for k in mpia_authors]\n",
    "hl_authors = highlight_authors_in_list(normed_author_list, normed_mpia_authors, verbose=True)\n",
    "matches = [(hl, orig) for hl, orig in zip(hl_authors, paper['authors']) if 'mark' in hl]\n",
    "if not matches:\n",
    "    warnings.warn(AffiliationWarning(\"WARNING: This paper does not seem to have MPIA authors.\"))\n",
    "    \n",
    "paper['authors'] = hl_authors\n",
    "paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f295192e",
   "metadata": {},
   "source": [
    "We get the (TeX) source\n",
    "* retrieve the tarball\n",
    "* find the main tex file and parse it\n",
    "* parse for affiliations (but debugging so we do not stop if not found)\n",
    "* generate the the output markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdd37f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "paper_id = f'{which:s}'\n",
    "folder = f'tmp_{paper_id:s}'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "\n",
    "try:\n",
    "    doc = latex.LatexDocument(folder, validation=validation)    \n",
    "except AffiliationError as affilerror:\n",
    "    msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "    print(msg)\n",
    "\n",
    "# Hack because sometimes author parsing does not work well\n",
    "if (len(doc.authors) != len(paper['authors'])):\n",
    "    doc._authors = paper['authors']\n",
    "else:\n",
    "    # highlight authors (FIXME: doc.highlight_authors)\n",
    "    # done on arxiv paper already\n",
    "    doc._authors = highlight_authors_in_list(\n",
    "        [mpia.get_initials(k) for k in doc.authors], \n",
    "        normed_mpia_authors, verbose=True)\n",
    "if (doc.abstract) in (None, ''):\n",
    "    doc._abstract = paper['abstract']\n",
    "\n",
    "doc.comment = get_markdown_badge(paper_id) + \" _\" + paper['comments'] + \"_\"\n",
    "# doc.highlight_authors_in_list(hl_list, verbose=True)\n",
    "\n",
    "full_md = doc.generate_markdown_text()\n",
    "\n",
    "# replace citations\n",
    "try:\n",
    "    bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "    full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eebb72b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Markdown(full_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_markdown_summary(full_md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88063f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
