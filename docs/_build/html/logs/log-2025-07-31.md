# Arxiv on Deck 2: Logs - 2025-07-31

* Arxiv had 61 new papers
    * 2 with possible author matches

## Sucessful papers


|||
|---:|:---|
| [![arXiv](https://img.shields.io/badge/arXiv-2507.22780-b31b1b.svg)](https://arxiv.org/abs/2507.22780) | **Euclid: Forecasts on $Î›$CDM consistency tests with growth rate data**  |
|| I. Ocampo, et al. -- incl., <mark>K. Jahnke</mark> |
|*Appeared on*| *2025-07-31*|
|*Comments*| *17 pages, 4 figures, 3 tables*|
|**Abstract**|            The large-scale structure (LSS) of the Universe is an important probe for deviations from the canonical cosmological constant $\Lambda$ and cold dark matter ($\Lambda$CDM) model. A statistically significant detection of any deviations would signify the presence of new physics or the breakdown of any number of the underlying assumptions of the standard cosmological model or possible systematic errors in the data. In this paper, we quantify the ability of the LSS data products of the spectroscopic survey of the Euclid mission, together with other contemporary surveys, to improve the constraints on deviations from $\Lambda$CDM in the redshift range $0<z<1.75$. We consider both currently available growth rate data and simulated data with specifications from Euclid and external surveys, based on $\Lambda$CDM and a modified gravity (MoG) model with an evolving Newton's constant (denoted $\mu$CDM), and carry out a binning method and a machine learning reconstruction, based on genetic algorithms (GAs), of several LSS null tests. Using the forecast Euclid growth data from the spectroscopic survey in the range $0.95<z<1.75$, we find that in combination with external data products (covering the range $0<z<0.95$), Euclid will be able to improve on current constraints of null tests of the LSS on average by a factor of eight when using a binning method and a factor of six when using the GAs. Our work highlights the need for synergies between Euclid and other surveys, but also the usefulness of statistical analyses, such as GAs, in order to disentangle any degeneracies in the cosmological parameters. Both are necessary to provide tight constraints over an extended redshift range and to probe for deviations from the $\Lambda$CDM model.         |

## Failed papers

### affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found. 


|||
|---:|:---|
| [![arXiv](https://img.shields.io/badge/arXiv-2507.22618-b31b1b.svg)](https://arxiv.org/abs/2507.22618) | **LiteBIRD Science Goals and Forecasts: Improved full-sky reconstruction of the gravitational lensing potential through the combination of Planck and LiteBIRD data**  |
|| M. Ruiz-Granda, et al. -- incl., <mark>H. Jiang</mark> |
|*Appeared on*| *2025-07-31*|
|*Comments*| *49 pages, 22 figures, submitted to JCAP*|
|**Abstract**|            Cosmic microwave background (CMB) photons are deflected by large-scale structure through gravitational lensing. This secondary effect introduces higher-order correlations in CMB anisotropies, which are used to reconstruct lensing deflections. This allows mapping of the integrated matter distribution along the line of sight, probing the growth of structure, and recovering an undistorted view of the last-scattering surface. Gravitational lensing has been measured by previous CMB experiments, with $\textit{Planck}$'s $42\,\sigma$ detection being the current best full-sky lensing map. We present an enhanced $\textit{LiteBIRD}$ lensing map by extending the CMB multipole range and including the minimum-variance estimation, leading to a $49$ to $58\,\sigma$ detection over $80\,\%$ of the sky, depending on the final complexity of polarized Galactic emission. The combination of $\textit{Planck}$ and $\textit{LiteBIRD}$ will be the best full-sky lensing map in the 2030s, providing a $72$ to $78\,\sigma$ detection over $80\,\%$ of the sky, almost doubling $\textit{Planck}$'s sensitivity. Finally, we explore different applications of the lensing map, including cosmological parameter estimation using a lensing-only likelihood and internal delensing, showing that the combination of both experiments leads to improved constraints. The combination of $\textit{Planck}$ + $\textit{LiteBIRD}$ will improve the $S_8$ constraint by a factor of 2 compared to $\textit{Planck}$, and $\textit{Planck}$ + $\textit{LiteBIRD}$ internal delensing will improve $\textit{LiteBIRD}$'s tensor-to-scalar ratio constraint by $6\,\%$. We have tested the robustness of our results against foreground models of different complexity, showing that a significant improvement remains even for the most complex foregrounds.         |
|<p style="color:green"> **ERROR** </p>| <p style="color:green">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |

