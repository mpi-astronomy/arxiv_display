{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {},
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {},
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Wolf', 'Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Zähringer', 'Scheerer', 'Hoffmann', 'Düe',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'Jäger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J. Li  ->  J. Li  |  ['J. Li']\n",
      "J. Liu  ->  J. Liu  |  ['J. Liu']\n",
      "J. Liu  ->  J. Liu  |  ['J. Liu']\n",
      "L. Kreidberg  ->  L. Kreidberg  |  ['L. Kreidberg']\n",
      "P. Mollière  ->  P. Mollière  |  ['P. Mollière']\n",
      "T. Henning  ->  T. Henning  |  ['T. Henning']\n",
      "M. Samland  ->  M. Samland  |  ['M. Samland']\n",
      "G. Perotti  ->  G. Perotti  |  ['G. Perotti']\n",
      "K. Schwarz  ->  K. Schwarz  |  ['K. Schwarz']\n",
      "Arxiv has 60 new papers today\n",
      "          4 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [mpia.get_initials(k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {},
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975c68d86b66407db67b933ac0268938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: tmp_2406.09991/sample631.tex, 353 lines\n",
      "  1: tmp_2406.09991/fbd_lt.tex, 344 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577: LatexWarning: Found 2 candidates with documentclass definition.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577: LatexWarning: Assuming tmp_2406.09991/sample631.tex as main document.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L. Kreidberg  ->  L. Kreidberg  |  ['L. Kreidberg']\n",
      "P. Mollière  ->  P. Mollière  |  ['P. Mollière']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure empty.eps\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:707: LatexWarning: Could not find graphic \\includegraphics[width=\\hsize]{empty.eps}\n",
      "  warnings.warn(LatexWarning(f\"Could not find graphic {k}\"))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure empty.eps\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:707: LatexWarning: Could not find graphic \\includegraphics[angle=-90,width=3cm]{empty.eps}\n",
      "  warnings.warn(LatexWarning(f\"Could not find graphic {k}\"))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure empty.eps\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:707: LatexWarning: Could not find graphic \\includegraphics[width=3cm]{empty.eps}\n",
      "  warnings.warn(LatexWarning(f\"Could not find graphic {k}\"))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure empty.eps\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:707: LatexWarning: Could not find graphic \\includegraphics[bb=10 20 100 300,width=3cm,clip]{empty.eps}\n",
      "  warnings.warn(LatexWarning(f\"Could not find graphic {k}\"))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure 1787f23.eps\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:707: LatexWarning: Could not find graphic \\includegraphics[width=10.9cm]{1787f23.eps}\n",
      "  warnings.warn(LatexWarning(f\"Could not find graphic {k}\"))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure 1787f24.ps\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/arxiv_on_deck_2/latex.py:707: LatexWarning: Could not find graphic \\includegraphics[width=16.4cm,clip]{1787f24.ps}\n",
      "  warnings.warn(LatexWarning(f\"Could not find graphic {k}\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 158 bibliographic references in tmp_2406.10032/aanda.bbl.\n",
      "Error retrieving bib data for Li24: 'author'\n",
      "Found 88 bibliographic references in tmp_2406.10217/main.bbl.\n",
      "syntax error in line 74: '=' expected\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [mpia.get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {},
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2406.10032-b31b1b.svg)](https://arxiv.org/abs/2406.10032) | **GASTLI: An open-source coupled interior-atmosphere model to unveil gas giant composition**  |\n",
       "|| L. Acuña, <mark>L. Kreidberg</mark>, M. Zhai, <mark>P. Mollière</mark> |\n",
       "|*Appeared on*| *2024-06-17*|\n",
       "|*Comments*| *18 pages, 9 figures. In review in Astronomy & Astrophysics*|\n",
       "|**Abstract**|            The metal mass fractions of gas giants are a powerful tool to constrain their formation mechanisms and evolution. The metal content is inferred by comparing mass and radius measurements with interior structure and evolution models. In the midst of the JWST, CHEOPS, TESS, and the forthcoming PLATO era, we are at the brink of obtaining unprecedented precision in radius, age and atmospheric metallicity measurements. To prepare for this wealth of data, we present the GAS gianT modeL for Interiors (GASTLI), an easy-to-use, publicly available Python package. The code is optimized to rapidly calculate mass-radius relations, and radius and luminosity thermal evolution curves for a variety of envelope compositions and core mass fractions. Its applicability spans planets with masses $17 \\ M_{\\oplus} < M < 6 \\ M_{Jup}$, and equilibrium temperatures $T_{eq} < 1000$ K. The interior model is stratified in a core composed of water and rock, and an envelope constituted by H/He and metals (water). The interior is coupled to a grid of self-consistent, cloud-free atmospheric models to determine the atmospheric and boundary interior temperature, as well as the contribution of the atmosphere to the total radius. We successfully validate GASTLI by comparing it to previous work and data of the Solar System's gas giants and Neptune. We also test GASTLI on the Neptune-mass exoplanet HAT-P-26 b, finding a bulk metal mass fraction between 0.60-0.78 and a core mass of 8.5-14.4 $M_{\\oplus}$. Finally, we explore the impact of different equations of state and assumptions, such as C/O ratio and transit pressure, in the estimation of bulk metal mass fraction. These differences between interior models entail a change in radius of up to 2.5% for Jupiter-mass planets, but more than 10\\% for Neptune-mass. These are equivalent to variations in core mass fraction of 0.07, or 0.10 in envelope metal mass fraction.         |"
      ],
      "text/plain": [
       "[2406.10032] GASTLI: An open-source coupled interior-atmosphere model to unveil gas giant composition\n",
       "\tL. Acuña, <mark>L. Kreidberg</mark>, M. Zhai, <mark>P. Mollière</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2406.10217-b31b1b.svg)](https://arxiv.org/abs/2406.10217) | **MINDS. A multi-instrument investigation into the molecule-rich JWST-MIRI spectrum of the DF Tau binary system**  |\n",
       "|| S. L. Grant, et al. -- incl., <mark>T. Henning</mark>, <mark>M. Samland</mark>, <mark>G. Perotti</mark>, <mark>K. Schwarz</mark> |\n",
       "|*Appeared on*| *2024-06-17*|\n",
       "|*Comments*| *Submitted to A&A on May 17th, 2024. The reduced and calibrated JWST and ALMA data will become publicly available upon publication*|\n",
       "|**Abstract**|            Most stars form in multiple systems whose properties can significantly impact circumstellar disk evolution. We investigate the physical and chemical properties of the equal-mass, small separation (~66 mas, ~9 au) DF Tau binary system. Previous observations indicated that only DF Tau A has a circumstellar disk. We present JWST-MIRI MRS observations of DF Tau. The MIRI spectrum shows a forest of H2O lines and emission from CO, C2H2, HCN, CO2, and OH. LTE slab models are used to determine the properties of the gas, and we analyze high angular spatial and spectral resolution data from ALMA, VLTI-GRAVITY, and IRTF-iSHELL to aid in the interpretation of the JWST data. The 1.3 mm ALMA continuum data show two equal-brightness sources of compact (R<3 au) emission, with separations and movement consistent with astrometry from VLTI-GRAVITY and the known orbit. This is interpreted as a robust detection of a disk around DF Tau B, which we suggest may host a small (~1 au) cavity to reconcile all observations. The disk around DF Tau A is expected to be a full disk, and spatially and spectrally resolved dust and gas emission points to hot, close-in (<0.2 au) material. Hot (~500-1000 K) H2O, HCN, and C2H2 emission in the MIRI data likely originate in the DF Tau A disk, while a cold (<200 K) H2O component with an extended emitting area is consistent with an origin from both disks. Despite the very compact outer disks, the inner disk composition and conditions are similar to isolated systems, suggesting that the close binary nature is not a driving factor in setting the inner disk chemistry. However, constraining the geometry of the disks, for instance, via higher resolution ALMA observations, would provide additional insight into the mid-infrared gas emission. JWST observations of spatially resolved binaries will be important for understanding the impact of binarity on inner disk chemistry more generally.         |"
      ],
      "text/plain": [
       "[2406.10217] MINDS. A multi-instrument investigation into the molecule-rich JWST-MIRI spectrum of the DF Tau binary system\n",
       "\tS. L. Grant, et al. -- incl., <mark>T. Henning</mark>, <mark>M. Samland</mark>, <mark>G. Perotti</mark>, <mark>K. Schwarz</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2406.09813-b31b1b.svg)](https://arxiv.org/abs/2406.09813) | **Diffuse X-ray Explorer: a high-resolution X-ray spectroscopic sky surveyor on the China Space Station**  |\n",
       "|| H. Jin, et al. -- incl., <mark>J. Li</mark>, <mark>J. Liu</mark> |\n",
       "|*Appeared on*| *2024-06-17*|\n",
       "|*Comments*| *12 pages, 6 figures, the full version is published by Journal of Low Temperature Physics*|\n",
       "|**Abstract**|            DIffuse X-ray Explorer (DIXE) is a proposed high-resolution X-ray spectroscopic sky surveyor on the China Space Station (CSS). DIXE will focus on studying hot baryons in the Milky Way. Galactic hot baryons like the X-ray emitting Milky Way halo and eROSITA bubbles are best observed in the sky survey mode with a large field of view. DIXE will take advantage of the orbital motion of the CSS to scan a large fraction of the sky. High-resolution X-ray spectroscopy, enabled by superconducting microcalorimeters based on the transition-edge sensor (TES) technology, will probe the physical properties (e.g., temperature, density, elemental abundances, kinematics) of the Galactic hot baryons. This will complement the high-resolution imaging data obtained with the eROSITA mission. Here we present the preliminary design of DIXE. The payload consists mainly of a detector assembly and a cryogenic cooling system. The key components of the detector assembly are a microcalorimeter array and frequency-domain multiplexing readout electronics. To provide a working temperature for the detector assembly, the cooling system consists of an adiabatic demagnetization refrigerator and a mechanical cryocooler system.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2406.09991-b31b1b.svg)](https://arxiv.org/abs/2406.09991) | **On the Interacting/Active Lifetime of Supernova Fallback Disk around Isolated Neutron Stars**  |\n",
       "|| K. Xu, et al. -- incl., <mark>J. Liu</mark> |\n",
       "|*Appeared on*| *2024-06-17*|\n",
       "|*Comments*| *Accepted in ApJ, comments are welcome*|\n",
       "|**Abstract**|            The fallback disk model is widely accepted to explain long-period neutron stars (NSs) which can't be simulated by magnetic dipole radiation. However, no confirmed detection of disk was found from the newly discovered long period pulsars GLEAM-X 162759.5-523504.3, GPM J1839-10 and the known slowest isolated NSs 1E 161348-5055. This might be that the disks have either been in noninteracting/inactive state where its emission is too weak to be detected or have been disrupted. In this work, we conduct simulations to examine the lifetime of supernova fallback disks around isolated neutron stars. We assume that the disk's mass varies in a self-similar way and its interaction with the NS occurs only in interacting/active state. Our results reveal that nearly all the interacting lifetimes for the disk are shorter than 0.1 Myr while the existence lifetimes are considerably longer.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {},
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found figures ['tmp_2406.10032/./Figures/Saturn_MRrel_comparison_v2.png', 'tmp_2406.10032/./Figures/Neptune_MRrel_comparison_v2.png', 'tmp_2406.10032/./Figures/atmospheric_profiles_Jupiter_v2_referee.png', 'tmp_2406.10032/./Figures/Jupiter_MRrel_comparison_v2_referee.png']\n",
      "copying  tmp_2406.10032/./Figures/Saturn_MRrel_comparison_v2.png to _build/html/\n",
      "copying  tmp_2406.10032/./Figures/Neptune_MRrel_comparison_v2.png to _build/html/\n",
      "copying  tmp_2406.10032/./Figures/atmospheric_profiles_Jupiter_v2_referee.png to _build/html/\n",
      "copying  tmp_2406.10032/./Figures/Jupiter_MRrel_comparison_v2_referee.png to _build/html/\n",
      "exported in  _build/html/2406.10032.md\n",
      "    + _build/html/tmp_2406.10032/./Figures/Saturn_MRrel_comparison_v2.png\n",
      "    + _build/html/tmp_2406.10032/./Figures/Neptune_MRrel_comparison_v2.png\n",
      "    + _build/html/tmp_2406.10032/./Figures/atmospheric_profiles_Jupiter_v2_referee.png\n",
      "    + _build/html/tmp_2406.10032/./Figures/Jupiter_MRrel_comparison_v2_referee.png\n",
      "found figures ['tmp_2406.10217/./DFTau_miri_corner_examples.png', 'tmp_2406.10217/./GRAVITY.png', 'tmp_2406.10217/./DFTau_lineprofiles.png']\n",
      "copying  tmp_2406.10217/./DFTau_miri_corner_examples.png to _build/html/\n",
      "copying  tmp_2406.10217/./GRAVITY.png to _build/html/\n",
      "copying  tmp_2406.10217/./DFTau_lineprofiles.png to _build/html/\n",
      "exported in  _build/html/2406.10217.md\n",
      "    + _build/html/tmp_2406.10217/./DFTau_miri_corner_examples.png\n",
      "    + _build/html/tmp_2406.10217/./GRAVITY.png\n",
      "    + _build/html/tmp_2406.10217/./DFTau_lineprofiles.png\n"
     ]
    }
   ],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {},
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# GASTLI\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2406.10032-b31b1b.svg)](https://arxiv.org/abs/2406.10032)<mark>Appeared on: 2024-06-17</mark> -  _18 pages, 9 figures. In review in Astronomy & Astrophysics_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "L. Acuña, <mark>L. Kreidberg</mark>, M. Zhai, <mark>P. Mollière</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** The metal mass fractions of gas giants are a powerful tool to constrain their formation mechanisms and evolution. The metal content is inferred by comparing mass and radius measurements with interior structure and evolution models. In the midst of the JWST, CHEOPS, TESS, and the forthcoming PLATO era, we are at the brink of obtaining unprecedented precision in radius, age and atmospheric metallicity measurements.   To prepare for this wealth of data, we present the GAS gianT modeL for Interiors (GASTLI), an easy-to-use, publicly available Python package. The code is optimized to rapidly calculate mass-radius relations, and radius and luminosity thermal evolution curves for a variety of envelope compositions and core mass fractions. Its applicability spans planets with masses $17  M_{\\oplus} < M < 6  M_{Jup}$ , and equilibrium temperatures $T_{eq} < 1000$ K.   The interior model is stratified in a core composed of water and rock, and an envelope constituted by H/He and metals (water). The interior is coupled to a grid of self-consistent, cloud-free atmospheric models to determine the atmospheric and boundary interior temperature, as well as the contribution of the atmosphere to the total radius.   We successfully validate GASTLI by comparing it to previous work and data of the Solar System’s gas giants and Neptune. We also test GASTLI on the Neptune-mass exoplanet HAT-P-26 b, finding a bulk metal mass fraction between 0.60-0.78 and a core mass of 8.5-14.4 $M_{\\oplus}$ . Finally, we explore the impact of different equations of state and assumptions, such as C/O ratio and transit pressure, in the estimation of bulk metal mass fraction. These differences between interior models entail a change in radius of up to 2.5 \\% for Jupiter-mass planets, but more than 10 \\% for Neptune-mass. These are equivalent to variations in core mass fraction of 0.07, or 0.10 in envelope metal mass fraction.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2406.10032/./Figures/Saturn_MRrel_comparison_v2.png\" alt=\"Fig10.1\" width=\"50%\"/><img src=\"tmp_2406.10032/./Figures/Neptune_MRrel_comparison_v2.png\" alt=\"Fig10.2\" width=\"50%\"/>\n",
       "\n",
       "**Figure 10. -** Left: Mass-radius relations for Saturn. GASTLI's fiducial model for Saturn can reproduce with a better precision Saturn's mass and radius data than HG21. We assumed an equilibrium temperature of $T_{eq} = $ 100 K across all models, while we adopt an internal temperature $T_{int}$ = 77 for Saturn. Models for Saturn were calculated for a fixed envelope metallicity of 8.9 $\\times$ solar, equivalent to $Z_{env}$ = 0.10 for the HG21 model. Right: Mass-radius relations for Neptune. The fiducial model (black) agrees well with mass and radius data. We assumed an internal temperature $T_{int}$ = 52 K for Neptune. (*fig:Saturn_and_Neptune*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2406.10032/./Figures/atmospheric_profiles_Jupiter_v2_referee.png\" alt=\"Fig5\" width=\"100%\"/>\n",
       "\n",
       "**Figure 5. -** Atmospheric profiles for Jupiter's interior-atmosphere models. Our clear petitCODE fiducial model is 50 K warmer than Jupiter's atmospheric data provided by the Voyager and the Galileo probe  ([Seiff, Kirk and Knight 1998](), [Gupta, Atreya and Steffes 2022](), Li24) . We assumed the fiducial case, with an internal temperature of $T_{int} $ = 107 K, a solar composition, and a core mass fraction of CMF = 0.03. For the [ and Guillot (2010)]() atmospheric models, we adopted an infrared opacity $\\kappa_{th}$ = 0.01 cm$^{2}$/g, and a visible-to-thermal opacity ratio of $\\kappa_{v}/\\kappa_{th} = \\gamma$ = 0.4. (*fig:Jupiter_atm_prof*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2406.10032/./Figures/Jupiter_MRrel_comparison_v2_referee.png\" alt=\"Fig9\" width=\"100%\"/>\n",
       "\n",
       "**Figure 9. -** Left: GASTLI models for Jupiter. GASTLI can reproduce Jupiter's mass and radius data with the fiducial model within 1.6\\%. Solid lines show the total radius obtained with GASTLI for core mass fractions (CMF) equal to 0 and 0.03 (fiducial) assuming a solar metallicity in the envelope. The global average equilibrium temperature (122 K) and internal temperature (107 K) of Jupiter were adopted .\n",
       "      Right: Comparison of mass-radius relations between GASTLI and two widely used interior models for gas giants: [Fortney, Marley and Barnes (2007)]()(F07) and [ and Müller (2021)]()(MH21). For the same composition, GASTLI agrees within uncertainties with other publicly available mass-radius relations. The fiducial case at CMF = 0.03 is indicated in black for all models. F07 and MH21 models were obtained assuming the irradiation and age of Jupiter. For MH21 at CMF = 0, a solar $Z_{env}$ = 0.013 is not available, so $Z_{env}$ = 0 is assumed instead. (*fig:Jupiter_MRrel*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2406.10032\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\orcid}[1]{\\unskip\\protect\\href{https://orcid.org/#1}{\\protect\\includegraphics[width=8pt,clip]{logo_orcid}}}$\n",
       "$\\newcommand{\\Lsun}{L_{\\odot}}$\n",
       "$\\newcommand{\\Msun}{M_{\\odot}}$\n",
       "$\\newcommand{\\Mearth}{M_{\\oplus}}$\n",
       "$\\newcommand{\\Rsun}{R_{\\odot}}$\n",
       "$\\newcommand{\\Mdot}{\\dot{M}}$\n",
       "$\\newcommand{\\Mdust}{{M_{\\rm{dust}}}}$\n",
       "$\\newcommand{\\Mdisk}{{M_{\\rm{disk}}}}$\n",
       "$\\newcommand{\\Av}{A_V}$\n",
       "$\\newcommand{\\msunyr}{\\rm{M_{\\sun}   yr^{-1}}}$\n",
       "$\\newcommand{\\Teff}{T_{\\rm eff}}$\n",
       "$\\newcommand{\\mic}{\\mum}$\n",
       "$\\newcommand{\\tstar}{T_{*}}$\n",
       "$\\newcommand{\\rstar}{R_{*}}$\n",
       "$\\newcommand{\\mstar}{M_{*}}$\n",
       "$\\newcommand{\\rdisk}{r_{\\rm{disk}}}$\n",
       "$\\newcommand{\\hwall}{h_{\\rm{wall}}}$\n",
       "$\\newcommand{\\amaxbig}{a_{\\rm{max,big}}}$\n",
       "$\\newcommand{\\amaxsmall}{a_{\\rm{max,small}}}$\n",
       "$\\newcommand{\\brgamma}{Br\\gamma}$\n",
       "$\\newcommand{\\Lacc}{L_{\\rm{acc}}}$\n",
       "$\\newcommand{\\LaccL}{L_{\\rm{acc}}/L_{*}}$\n",
       "$\\newcommand{\\Lbrg}{L_{\\rm{Br\\gamma}}}$\n",
       "$\\newcommand{\\Fbrg}{F_{\\rm{Br\\gamma}}}$\n",
       "$\\newcommand{\\angstrom}{\\mbox{\\normalfontÅ}}$\n",
       "$\\newcommand{\\Lstar}{L_{*}}$\n",
       "$\\newcommand{\\LNIR}{L_{\\rm{NIR}}}$\n",
       "$\\newcommand{\\LIR}{L_{\\rm{IR}}}$\n",
       "$\\newcommand{\\vsini}{vsin(i)}$\n",
       "$\\newcommand{\\Ri}{R_{i}}$\n",
       "$\\newcommand{\\mdotmdisk}{\\dot{M}--M_{\\rm{disk}}}$\n",
       "$\\newcommand{\\tdisk}{t_{\\rm{disk}}}$\n",
       "$\\newcommand{\\nk}[1]{\\textcolor{teal}{Nico}: #1}$\n",
       "$\\newcommand{\\sg}[1]{\\textcolor{red}{Sierra}: #1}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# MINDS. A multi-instrument investigation into the molecule-rich JWST-MIRI spectrum of the DF Tau binary system\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2406.10217-b31b1b.svg)](https://arxiv.org/abs/2406.10217)<mark>Appeared on: 2024-06-17</mark> -  _Submitted to A&A on May 17th, 2024. The reduced and calibrated JWST and ALMA data will become publicly available upon publication_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "S. L. Grant, et al. -- incl., <mark>T. Henning</mark>, <mark>M. Samland</mark>, <mark>G. Perotti</mark>, <mark>K. Schwarz</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** The majority of young stars form in multiple systems, the properties of which can significantly impact the evolution of any circumstellar disks. We investigate the physical and chemical properties of the equal-mass, small separation ( $\\sim$ 66 milliarcsecond, $\\sim$ 9 au) binary system DF Tau. Previous spatially resolved observations indicate that only DF Tau A has a circumstellar disk, while DF Tau B does not, as concluded by a lack of accretion signatures and near-infrared excess. We present JWST-MIRI MRS observations of DF Tau. The MIRI spectrum shows emission from a forest of $H_2$ O lines and emission from CO, $C_2$ $H_2$ , HCN, $CO_2$ , and OH. Localthermodynamic equilibrium slab models are used to determine the properties of the gas. The binary system is not spatially or spectrally resolved in the MIRI observations, therefore, we analyze high angular spatial and spectral resolution observations from ALMA, VLTI-GRAVITY, and IRTF-iSHELL to aid in the interpretation of the molecular emission observed with JWST. The 1.3 mm ALMA observations show two equal brightness sources of compact ( $R\\lesssim$ 3 au) continuum emission that are detected at high significance, with separations consistent with astrometry from VLTI-GRAVITY and movement consistent with the known orbital parameters of the system. This is interpreted as a robust detection of the disk around DF Tau B, which we suggest may host a small ( $\\sim$ 1 au) cavity to reconcile all of the observations of this source. In contrast, the disk around DF Tau A is expected to be a full disk, and spatially and spectrally resolved dust and gas emission traced by ground-based infrared observations point to hot, close-in ( $\\lesssim0.2$ au) material around this star.High temperature ( $\\sim$ 500-1000 K) emission from $H_2$ O, HCN, and potentially $C_2$ $H_2$ in the MIRI data likely originates in the disk around DF Tau A, while a cold ( $\\lesssim$ 200 K) $H_2$ O component with an extended emitting area is consistent with an origin from both disks. Given the unique characteristics of this binary pair, complementary observations are critical for constraining the properties of these disks. Despite the very compact outer disk properties, the inner disk composition and conditions of the DF Tau disks are remarkably similar to isolated systems, suggesting that neither the outer disk evolution nor the close binary nature are driving factors in setting the inner disk chemistry in this system. However, constraining the geometry of the disk around DF Tau B, via higher angular resolution ALMA observations, for instance, would provide additional insight into the properties of the mid-infrared gas emission observed with MIRI. JWST observations of spatially resolved binaries, at a range of separations, will be important for understanding the impact of binarity on inner disk chemistry more generally.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2406.10217/./DFTau_miri_corner_examples.png\" alt=\"Fig11\" width=\"100%\"/>\n",
       "\n",
       "**Figure 11. -** The posterior distributions of the MCMC modeling of the JWST-MIRI spectra. The column densities, $N$, are in log$_{10}$ space. Examples of the correlations seen in optically thick and optically thin cases are shown in the upper right.  (*fig: corner plot*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2406.10217/./GRAVITY.png\" alt=\"Fig10\" width=\"100%\"/>\n",
       "\n",
       "**Figure 10. -** The VLTI-GRAVITY visibilities squared (top) and the closure phases (bottom) in the observations (colors) compared to the best-fit model (red). (*fig: gravity model*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2406.10217/./DFTau_lineprofiles.png\" alt=\"Fig1\" width=\"100%\"/>\n",
       "\n",
       "**Figure 1. -** The stacked line profiles for CO v=1-0 (black), CO v=2-1 (gray), and the 5 $\\mic$ $H_2$O (blue) lines from IRFT-iSHELL spectrum of DF Tau \\citep{banzatti23a}. A Keplerian line profile, calculated using an inclination of 67$^\\circ$ and a stellar mass of 0.55 $\\Msun$, is shown in red, which matches the v=2-1 lines.   (*fig: line profiles*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2406.10217\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {},
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
