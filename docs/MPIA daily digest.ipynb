{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {},
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex, \n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14622700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional CSS to consider. \n",
    "# TODO: Current into each exported file. \n",
    "#       This should be set once into the webpages directly.\n",
    "#       With only the class/id definitions in the .md files.\n",
    "\n",
    "debug_html = \"\"\"\n",
    "<style>\n",
    "#wrap{ overflow:auto; }\n",
    "#fig1{ background:yellow; width:100%; float:left; padding:5px;  }\n",
    "#fig2{ background:red; width:50%; float:left; clear:left; padding:5px;  }\n",
    "#fig3{ background:green; width:50%; float:left; padding:5px;   }\n",
    ".macros{ background:yellow; visibility:visible;}\n",
    "h1 {margin: 0 0 0 0;}\n",
    "mark {background-color:#fff3b6;}\n",
    "img {object-fit:contain; max-height:250px; display:inline-block; text-align: center;}\n",
    "</style>\n",
    "\"\"\" \n",
    "html = \"\"\"\n",
    "<style>\n",
    "#wrap{ overflow:auto; }\n",
    "#fig1{ width:100%; float:left; padding: 5px;  }\n",
    "#fig2{ width:50%; float:left; clear:left; padding: 5px;  }\n",
    "#fig3{ width:50%; float:left; padding: 5px;  }\n",
    ".macros{ visibility:hidden; height:0px; }\n",
    "h1 {margin: 0em 0 0 0;}\n",
    "mark {background-color:#fff3b6;}\n",
    "img {object-fit:contain; max-height:250px; display:inline-block; text-align: center;}\n",
    "</style>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {},
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list from MPIA website\n",
    "# it automatically filters identified non-scientists :func:`mpia.filter_non_scientists`\n",
    "mpia_authors = mpia.get_mpia_mitarbeiter_list()\n",
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "# select only papers with matching author names and highlight authors\n",
    "hl_list = [k[0] for k in mpia_authors]\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    hl_authors = highlight_authors_in_list(paperk['authors'], hl_list)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {},
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576b79e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates[:-1]):\n",
    "    paper_id = paper['identifier'].lower().replace('arxiv:', '')\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = get_markdown_badge(paper_id) + \" _\" + paper['comments'] + \"_\"\n",
    "        doc.highlight_authors_in_list(hl_list)\n",
    "\n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {},
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d733828a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {},
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d426aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {},
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25f625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {},
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf665672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")\n",
    "[ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca0208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"<section class=\"carousel\" aria-label=\"Gallery\">\"\"\",\n",
    "                \"\"\"  <ol class=\"carousel__viewport\">\"\"\",\n",
    "    ]\n",
    "    for k in range(1, npub + 1):\n",
    "        prev_ = k - 1\n",
    "        next_ = k + 1\n",
    "        if prev_ <= 0:\n",
    "            prev_ = npub\n",
    "        if next_ > npub:\n",
    "            next_ = 1\n",
    "        text  = f\"\"\"    <li id=\"carousel__slide{k}\" tabindex=\"0\" class=\"carousel__slide\">\\n\"\"\"\n",
    "        text += f\"\"\"       <div class=\"carousel__snapper\">\\n\"\"\"\n",
    "        text += f\"\"\"         <a href=\"#carousel__slide{prev_}\" class=\"carousel__prev\">Go to previous slide</a>\\n\"\"\"\n",
    "        text += f\"\"\"         <a href=\"#carousel__slide{next_}\" class=\"carousel__next\">Go to next slide</a>\\n\"\"\"\n",
    "        text += f\"\"\"         <div id=\"slide{k}_content\" class=\"md_view\" >Content {k}</div>\\n\"\"\"\n",
    "        text += f\"\"\"       </div>\\n\"\"\"\n",
    "        text += f\"\"\"    </li>\"\"\"\n",
    "        carousel.append(text)\n",
    "\n",
    "    carousel.extend([\n",
    "        \"\"\"  </ol>\"\"\",\n",
    "        \"\"\"  <aside class=\"carousel__navigation\">\"\"\",\n",
    "        \"\"\"    <ol class=\"carousel__navigation-list\">\"\"\"])\n",
    "\n",
    "    for k in range(1, npub + 1):\n",
    "        text  = f\"\"\"      <li class=\"carousel__navigation-item\">\\n\"\"\"\n",
    "        text += f\"\"\"        <a href=\"#carousel__slide{k}\" class=\"carousel__navigation-button\">Go to {k}</a>\\n\"\"\"\n",
    "        text += f\"\"\"      </li>\"\"\"\n",
    "        carousel.append(text)\n",
    "    carousel.extend([\"\"\"    </ol>\"\"\", \"\"\"  </aside>\"\"\", \"\"\"</section>\"\"\"])\n",
    "\n",
    "    return '\\n'.join(carousel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eac5b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}_content\"' for k in range(1, npub + 1)])\n",
    "\n",
    "script = f\"\"\"\n",
    "const docs = [{docs}]\n",
    "\n",
    "const slides = [{slides}]\n",
    "\"\"\" + \"\"\"\n",
    "async function run() {\n",
    "    for (let i = 0; i < docs.length; i++) {\n",
    "        let file = await fetch(docs[i]);\n",
    "        let text = await file.text()\n",
    "        document.getElementById(slides[i]).innerHTML =\n",
    "            marked.parse(text);\n",
    "    }\n",
    "    hljs.highlightAll();\n",
    "}\n",
    "run()\n",
    "\"\"\"\n",
    "\n",
    "page = f\"\"\"<!doctype html>\n",
    "<html lang=\"en\">\n",
    "\n",
    "<head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "  <!-- Bootstrap CSS -->\n",
    "  <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css\" rel=\"stylesheet\"\n",
    "   integrity=\"sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC\" crossorigin=\"anonymous\">\n",
    "  <!-- highlight.js CSS -->\n",
    "  <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/styles/default.min.css\">\n",
    "  <!-- Mathjax 3 -->\n",
    "  <script type=\"text/javascript\" id=\"MathJax-config\" src=\"mathjax_config.js\"> </script>\n",
    "  <script type=\"text/javascript\" id=\"MathJax-script\" async \n",
    "    src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\">\n",
    "  </script>\n",
    "  <link rel=\"stylesheet\" href=\"index_carousel.css\">\n",
    "  <link rel=\"icon\" type=\"image/x-icon\" href=\"https://www.mpia.de/assets/touch-icon-32x32-a66937bcebc4e8894ebff1f41a366c7c7220fd97a38869ee0f2db65a9f59b6c1.png\">\n",
    "  <title>MPIA Arxiv on deck!</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <div id=\"header\"> <img src=\"header_banner.png\" width=\"100%\"></div>\n",
    "  <div id=\"suptitle\"> 7-day archives </div>\n",
    "  <div id=\"info\">\n",
    "    <img src=\"https://pngimg.com/uploads/github/github_PNG58.png\" height=30rem></img>\n",
    "    <a href=https://github.com/mpi-astronomy/arxiv_display style=\"color:black;\">github/mpi-astronomy/arxiv_display</a> \n",
    "  </div>\n",
    "  {carousel:s}\n",
    "</body>\n",
    "\n",
    "<!-- Render Markdown -->\n",
    "\n",
    "<body>\n",
    "  <!-- highlight.js: https://highlightjs.org/download/ -->\n",
    "  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.0/highlight.min.js\"></script>\n",
    "  <!-- marked.js -->\n",
    "  <script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "  <script>{script:s}</script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebacbc",
   "metadata": {},
   "source": [
    "# Debugging papers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "debe7cc6",
   "metadata": {},
   "source": [
    "raise NotImplementedError(\"Manual Stop\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb169192",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from IPython.display import display, Markdown\n",
    "from TexSoup import TexSoup\n",
    "import re\n",
    "\n",
    "def bracket_error(source: str):\n",
    "    \"\"\" Find problematic portions of the document \"\"\"\n",
    "    \n",
    "    print(\"len(source)\", len(source))\n",
    "    \n",
    "    # Checking header\n",
    "    begin_doc = next(re.finditer(r'\\\\begin\\{document\\}', doc.source)).span()[1]\n",
    "    header = source[:begin_doc]\n",
    "    text = header + r\"\\n\\end{document}\"\n",
    "\n",
    "    try:\n",
    "        # print(\"Header check... \", end='')\n",
    "        TexSoup(text)\n",
    "        display(Markdown(f\"**[OK]** - Header\"))\n",
    "    except:\n",
    "        raise RuntimeError(\"Error in the header\")\n",
    "        \n",
    "    # Check the text per section until the end.\n",
    "    # Do not stop and try them all.\n",
    "    \n",
    "    problematic_text = []\n",
    "    \n",
    "    sections = ([(0, begin_doc, 'until first section')] + \n",
    "                [(g.span()[0], g.span()[1], g.group()) for g in re.finditer(r'\\\\section\\{.*\\}', source)] +\n",
    "                [(g.span()[0], g.span()[1], g.group()) for g in re.finditer(r'\\\\begin\\{appendix\\}', source)]\n",
    "               )\n",
    "    sections.append([len(source), len(source), 'end'])\n",
    "    \n",
    "    sections = sorted(sections, key=lambda x: x[0])\n",
    "    \n",
    "    prev_pos, prev_name = (0, 'header')\n",
    "    parsed = []\n",
    "    \n",
    "    for span, span_end, name in sections:\n",
    "\n",
    "        if span - prev_pos <= 0:\n",
    "            continue\n",
    "            \n",
    "\n",
    "        text = source[prev_pos:span]\n",
    "        if prev_pos > begin_doc:\n",
    "            text = r\"\\n\\begin{document}\" + text + r\"\\n\\end{document}\"\n",
    "        else:\n",
    "            text = text + r\"\\n\\end{document}\"\n",
    "        try:\n",
    "            #print(f\"{prev_pos}:{prev_name}-->{span}:{name} check... \", end='')\n",
    "            parsed.append(TexSoup(text, tolerance=1))  # allow not ending env\n",
    "            display(Markdown(f\"**[OK]** - *{prev_pos}*:{prev_name} &rarr; *{span}*:{name}\"))\n",
    "            # print(\"ok\")\n",
    "\n",
    "            prev_pos = span\n",
    "            prev_name = name\n",
    "        except:\n",
    "            # print(f\"error between {prev_pos} and {span}\")\n",
    "            display(Markdown(f\"**[ERR]** *{prev_pos}*:{prev_name} &rarr; *{span}*:{name}\"))\n",
    "            problematic_text.append((prev_pos, source[prev_pos:span]))\n",
    "            prev_pos = span\n",
    "            prev_name = name\n",
    "            # raise\n",
    "    return problematic_text, parsed\n",
    "\n",
    "\n",
    "def check_environment(text, offset=0):\n",
    "    \"\"\" Check environment \"\"\"\n",
    "    env = re.compile(r\"\\\\begin\\{(?P<env>.*)\\}(.*)\\\\end\\{(?P=env)\\}\", re.DOTALL)\n",
    "\n",
    "    for match in env.finditer(text):\n",
    "        beg, end = match.span()\n",
    "        beg += offset\n",
    "        end += offset\n",
    "        envname = match.groups()[0]\n",
    "        try:\n",
    "            latex.TexSoup(match.group())\n",
    "        except Exception as e:\n",
    "            display(e)\n",
    "            print(f\"Error in {envname:s} between {beg} and {end}\")\n",
    "            return match.groups()[1], beg, end"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2315e835",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import importlib\n",
    "importlib.reload(latex)\n",
    "which = \"2204.03253\"\n",
    "paper_id = f'{which:s}'\n",
    "folder = f'tmp_{paper_id:s}'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "\n",
    "try:\n",
    "    doc = latex.LatexDocument(folder, validation=validation)    \n",
    "except AffiliationError as affilerror:\n",
    "    msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "# Hack because sometimes author parsing does not work well\n",
    "if (len(doc.authors) != len(paper['authors'])):\n",
    "    doc._authors = paper['authors']\n",
    "if (doc.abstract) in (None, ''):\n",
    "    doc._abstract = paper['abstract']\n",
    "\n",
    "doc.comment = get_markdown_badge(paper_id) + \" _\" + paper['comments'] + \"_\"\n",
    "doc.highlight_authors_in_list(hl_list)\n",
    "\n",
    "full_md = doc.generate_markdown_text()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd3781db",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6eed834",
   "metadata": {},
   "source": [
    "# [check_environment(k) for k in bracket_error(doc.source)]\n",
    "_, _, a = latex.get_content_per_section(doc.source, verbose=True)\n",
    "if not a:\n",
    "    print(\"no issues per section\")\n",
    "for ak in a:\n",
    "    r = check_environment(ak[1], offset=ak[0])\n",
    "    print(r[1], r[2])\n",
    "    print(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce768a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
