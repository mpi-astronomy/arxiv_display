{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.004089,
     "end_time": "2025-12-23T04:29:25.212308",
     "exception": false,
     "start_time": "2025-12-23T04:29:25.208219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:25.220206Z",
     "iopub.status.busy": "2025-12-23T04:29:25.219904Z",
     "iopub.status.idle": "2025-12-23T04:29:25.447122Z",
     "shell.execute_reply": "2025-12-23T04:29:25.446273Z"
    },
    "papermill": {
     "duration": 0.232992,
     "end_time": "2025-12-23T04:29:25.448697",
     "exception": false,
     "start_time": "2025-12-23T04:29:25.215705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "import re\n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:25.456355Z",
     "iopub.status.busy": "2025-12-23T04:29:25.456074Z",
     "iopub.status.idle": "2025-12-23T04:29:25.464428Z",
     "shell.execute_reply": "2025-12-23T04:29:25.463693Z"
    },
    "papermill": {
     "duration": 0.013382,
     "end_time": "2025-12-23T04:29:25.465532",
     "exception": false,
     "start_time": "2025-12-23T04:29:25.452150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt\n",
    "\n",
    "\n",
    "def clean_non_western_encoded_characters_commands(text: str) -> str:\n",
    "    \"\"\" Remove non-western encoded characters from a string\n",
    "    List may need to grow.\n",
    "    \n",
    "    :param text: the text to clean\n",
    "    :return: the cleaned text\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"(\\\\begin{CJK}{UTF8}{gbsn})(.*?)(\\\\end{CJK})\", r\"\\2\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_initials(name: str) -> str:\n",
    "    \"\"\" Get the short name, e.g., A.-B. FamName\n",
    "    :param name: full name\n",
    "    :returns: initials\n",
    "    \"\"\"\n",
    "    initials = []\n",
    "    # account for non western names often in ()\n",
    "    if '(' in name:\n",
    "        name = clean_non_western_encoded_characters_commands(name)\n",
    "        suffix = re.findall(r\"\\((.*?)\\)\", name)[0]\n",
    "        name = name.replace(f\"({suffix})\", '')\n",
    "    else:\n",
    "        suffix = ''\n",
    "    split = name.split()\n",
    "    for token in split[:-1]:\n",
    "        if '-' in token:\n",
    "            current = '-'.join([k[0] + '.' for k in token.split('-')])\n",
    "        else:\n",
    "            current = token[0] + '.'\n",
    "        initials.append(current)\n",
    "    initials.append(split[-1].strip())\n",
    "    if suffix:\n",
    "        initials.append(f\"({suffix})\")\n",
    "    return ' '.join(initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.003017,
     "end_time": "2025-12-23T04:29:25.471829",
     "exception": false,
     "start_time": "2025-12-23T04:29:25.468812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:25.479136Z",
     "iopub.status.busy": "2025-12-23T04:29:25.478853Z",
     "iopub.status.idle": "2025-12-23T04:29:45.278912Z",
     "shell.execute_reply": "2025-12-23T04:29:45.278157Z"
    },
    "papermill": {
     "duration": 19.805244,
     "end_time": "2025-12-23T04:29:45.280325",
     "exception": false,
     "start_time": "2025-12-23T04:29:25.475081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Zähringer', 'Scheerer', 'Hoffmann', 'Düe',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'Jäger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:45.287719Z",
     "iopub.status.busy": "2025-12-23T04:29:45.287500Z",
     "iopub.status.idle": "2025-12-23T04:29:46.374167Z",
     "shell.execute_reply": "2025-12-23T04:29:46.373489Z"
    },
    "papermill": {
     "duration": 1.091542,
     "end_time": "2025-12-23T04:29:46.375322",
     "exception": false,
     "start_time": "2025-12-23T04:29:45.283780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S. Kraus  ->  S. Kraus  |  ['S. Kraus']\n",
      "E. Bañados  ->  E. Bañados  |  ['E. Bañados']\n",
      "M. Benisty  ->  M. Benisty  |  ['M. Benisty']\n",
      "J. Shi  ->  J. Shi  |  ['J. Shi']\n",
      "Y. Wang  ->  Y. Wang  |  ['Y. Wang']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S. Kumar  ->  S. Kumar  |  ['S. Kumar']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "Arxiv has 104 new papers today\n",
      "          7 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "def robust_call(fn, value, *args, **kwargs):\n",
    "    try:\n",
    "        return fn(value, *args, **kwargs)\n",
    "    except Exception:\n",
    "        return value\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [robust_call(mpia.get_initials, k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.003165,
     "end_time": "2025-12-23T04:29:46.382244",
     "exception": false,
     "start_time": "2025-12-23T04:29:46.379079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:46.389623Z",
     "iopub.status.busy": "2025-12-23T04:29:46.389375Z",
     "iopub.status.idle": "2025-12-23T04:29:53.558152Z",
     "shell.execute_reply": "2025-12-23T04:29:53.557401Z"
    },
    "papermill": {
     "duration": 7.173768,
     "end_time": "2025-12-23T04:29:53.559209",
     "exception": false,
     "start_time": "2025-12-23T04:29:46.385441",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53adf37975f44f63899471a9d0956423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2512.17976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2512.17976... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2512.18421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2864/2822249172.py:52: LatexWarning: 2512.18421 did not run properly\n",
      "not a gzip file\n",
      "  warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2512.18439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2512.18439..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2512.18543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2512.18543..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2512.18839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2512.18839... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2512.19000\n",
      "extracting tarball to tmp_2512.19000... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2512.19218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2512.19218..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(\"Issues with the citations\")\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.003753,
     "end_time": "2025-12-23T04:29:53.567211",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.563458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.576883Z",
     "iopub.status.busy": "2025-12-23T04:29:53.576575Z",
     "iopub.status.idle": "2025-12-23T04:29:53.595652Z",
     "shell.execute_reply": "2025-12-23T04:29:53.594975Z"
    },
    "papermill": {
     "duration": 0.025638,
     "end_time": "2025-12-23T04:29:53.596650",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.571012",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.17976-b31b1b.svg)](https://arxiv.org/abs/2512.17976) | **Bridging stellar evolution and planet formation: from birth, to survivors of the fittest, to the second generation of planets**  |\n",
       "|| A. Corporaal, et al. -- incl., <mark>S. Kraus</mark> |\n",
       "|*Appeared on*| *2025-12-23*|\n",
       "|*Comments*| *Science white paper submitted in the context of ESO's Expanding Horizons call*|\n",
       "|**Abstract**|            Stars and planets form, live, and evolve in unison. Throughout the life of a star, dusty circumstellar discs and stellar outflows influence the further evolution of both the star(s) and their orbiting planet(s). Planet-forming discs, winds of red giant branch (RGB) or asymptotic giant branch (AGB) stars, and post-RGB/post-AGB discs are examples of such host environments where dust physics plays a key role. The physical processes that occur during each of these stages establishes how the Solar System as well as exoplanetary systems were formed, are evolving, and will eventually die. This White Paper aims to bridge the fields of stellar evolution and planet formation by peering into the dust kinematics and macrostructure formation, and its effect on planet-host interaction, in dusty environments from stellar birth to death. Near-future advancements in the 2030s will enable the detection, orbital monitoring and atmospheric/mineralogical characterisation of close-in (proto)planets across diverse stages of stellar evolution. To take full advantage of these developments by the 2040s, we should develop the capabilities required to image the varied dusty environments in which planets are entrained over their lifetime. This will enable extensive testing of current theoretical understandings - from the micro-scales of dust assembly to the deeply interlinked macro-scales of planet-host interactions - across diverse settings often too small, distant, and faint to be resolved in the next decade, simultaneously providing valuable constraints on the two-way interplay of dusty host environments and planetary formation/evolution.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.18439-b31b1b.svg)](https://arxiv.org/abs/2512.18439) | **Imaging the LkCa 15 system in polarimetry and total intensity without self-subtraction artefacts**  |\n",
       "|| C. Swastik, et al. -- incl., <mark>M. Benisty</mark> |\n",
       "|*Appeared on*| *2025-12-23*|\n",
       "|*Comments*| *Accepted for publication in Astronomy & Astrophysics*|\n",
       "|**Abstract**|            Studying young protoplanetary disks is essential for understanding planet formation, but traditional angular differential imaging can introduce self-subtraction artefacts that hinder interpretation of small-scale structures. We present high-resolution total- and polarized-intensity Ks-band images of the LkCa~15 system obtained with SPHERE using near-simultaneous reference-star differential imaging (star-hopping), yielding self-subtraction-free images beyond 0.1 arcsec. LkCa~15 hosts a ~160 au protoplanetary disk and has previously been reported to harbour candidate protoplanets at separations of 15--18 au. We analyse the disk morphology and dust properties and search for super-Jupiter planets beyond 20 au. We first model the near-infrared scattered-light images together with ALMA submillimetre continuum data using RADMC-3D and a two grain-size (micron and millimetre) compact olivine model. While this model broadly reproduces the disk geometry, it overpredicts the degree of forward scattering in the near-infrared. To investigate this discrepancy, we extract the scattering phase function S(theta) and polarized fraction P(theta) from the SPHERE data and compare them with aggregate-scattering models. The observed phase functions disfavour compact Mie spheres and are better matched by porous aggregates (CAHP). Recomputing the scattered-light models with porous CAHP grains in the disk surface layer significantly improves agreement with the observed Ks-band morphology and polarization, while retaining compact millimetre grains to reproduce the ALMA continuum. No new planetary companions are detected; we place upper mass limits of ~1.5 MJ beyond 200 au and ~3.6 MJ in the inner disk. Our results demonstrate that combining star-hopping imaging with phase-function diagnostics provides strong constraints on dust grain properties in protoplanetary disks.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.18543-b31b1b.svg)](https://arxiv.org/abs/2512.18543) | **Searches for Prompt Low-Frequency Radio Counterparts to Gravitational Wave Event S250206dm with the OVRO-LWA Time Machine**  |\n",
       "|| N. Kosogorov, et al. -- incl., <mark>J. Shi</mark> |\n",
       "|*Appeared on*| *2025-12-23*|\n",
       "|*Comments*| *Accepted for publication in The Astrophysical Journal (ApJ). 19 pages, 6 figures*|\n",
       "|**Abstract**|            We report on a search for prompt, low-frequency radio emission from the gravitational-wave (GW) merger S250206dm using the Owens Valley Radio Observatory Long Wavelength Array (OVRO-LWA). Early alerts favored a neutron-star-containing merger, making this a compelling target. Motivated by theoretical predictions of coherent radio bursts from mergers involving a neutron star, we utilized the OVRO-LWA Time Machine system to analyze voltage data recorded around the time of the event. The Time Machine is a two-stage voltage buffer and processing pipeline that continuously buffers raw data from all antennas across the array's nearly full-hemisphere instantaneous field of view, enabling retrospective beamforming, dedispersion, and fast-transient candidate identification. For this event, we analyzed a 30-minute interval beginning 3.5 minutes after the merger, which included two minutes of pre-alert data recovered by the ring buffer. We searched the 50% localization probability region with millisecond time resolution in the 69-86 MHz frequency band. No radio counterpart was detected above a 7-sigma fluence detection threshold of ~150 Jy ms. Using Bayesian analysis, we place a 95% confidence upper limit on the source luminosity of L95 = 4 x 10^41 erg s^-1. These constraints start to probe the bright end of the coherent-emission parameter space predicted by jet-ISM shock processes, magnetar and blitzar-like mechanisms, and recent simulation-based scenarios for neutron-star-containing mergers. This study presents the first sensitive, large-area, millisecond-timescale search for prompt low-frequency radio emission from a GW merger with the OVRO-LWA, establishing a framework in which about ten additional events will yield stringent population-level constraints.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.18839-b31b1b.svg)](https://arxiv.org/abs/2512.18839) | **Accretion geometry in neutron star low-mass X-ray binaries during the hard spectral state**  |\n",
       "|| E. Meyer-Hofmeister, <mark>Y. Wang</mark>, B. F. Liu |\n",
       "|*Appeared on*| *2025-12-23*|\n",
       "|*Comments*| *8 pages, 5 figures; Accepted for publication in MNRAS*|\n",
       "|**Abstract**|            We investigate the accretion geometry in neutron star low-mass X-ray binaries (LMXBs) in the hard spectral state. It is commonly accepted that, for low mass transfer rates, an advection-dominated accretion flow (ADAF) is present in the inner region. But the observed relativistically broadened emission lines in the reflection spectra clearly indicate the existence of discs near the innermost stable circular orbit $(R_{\\rm{ISCO}})$. We investigate the interaction between the coronal flow and the disc in neutron star LMXBs, and find that gas condensation from the dominant, coronal accretion flow to an inner disc is enhanced as compared to that in black hole LMXBs as a consequence of irradiation of the corona by the neutron star surface. Computations show that for low mass transfer rates ($\\sim 0.005-0.02$ Eddington rate) a persistent weak disc can coexist with a coronal flow in the innermost region, where a pure ADAF would have been expected. The inner disc extends outwards from $R_{\\rm{ISCO}}$ to $\\sim 10 R_{\\rm{ISCO}}$ for Eddington ratios ($L/L_{\\rm{Edd}}$) as low as $\\sim 0.002$, covers a larger region for higher Eddington ratios, and eventually connects to the outer disc at $L/L_{\\rm{Edd}} \\sim 0.02$, thereby transiting to a soft state. We demonstrate that the observationally inferred region of the broad iron lines in the hard-state sources generally lies within the extension of the inner discs predicted by the condensation model. Disappearance of the broad iron lines is predicted at very low luminosities, either caused by very low accretion rates or disc truncation by strong magnetic fields.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.19000-b31b1b.svg)](https://arxiv.org/abs/2512.19000) | **$Ω_1Ω_2$-$Λ$CDM: A promising natural extension of the standard model of cosmology**  |\n",
       "|| <mark>S. Kumar</mark> |\n",
       "|*Appeared on*| *2025-12-23*|\n",
       "|*Comments*| *8 pages, 2 figures*|\n",
       "|**Abstract**|            We investigate a natural extension of the standard $\\Lambda$CDM framework, the $\\Omega_1\\Omega_2$-$\\Lambda$CDM model, in which the total energy density of the universe is expanded in powers of $1+z$. This parameterization recovers the standard $\\Lambda$CDM scenario and introduces two additional, observationally testable contributions to the dark energy sector, $\\Omega_1(1+z)$ and $\\Omega_2(1+z)^2$, alongside the cosmological constant. Using Planck CMB and DESI BAO data, we find that this framework is suitable for relaxing the Hubble tension. The Planck CMB data alone allow substantial freedom in late-time dynamics, yielding $H_0 = 75.4^{+3.9}_{-2.3}\\;\\mathrm{km\\;s^{-1}\\;Mpc^{-1}}$, fully consistent with distance-ladder measurements from the SH0ES collaboration. When DESI BAO data are included in the analysis, the late-time expansion history becomes more tightly anchored, reducing the $H_0$ discrepancy to $\\sim 2.5\\sigma$ level. This highlights the limited constraining power of currently available low-redshift data measurements, especially in the context of the $\\Omega_1\\Omega_2$-$\\Lambda$CDM model, where dynamical dark energy dominates the background expansion over a relatively large redshift range. The model naturally exhibits a smooth quintessence--phantom transition followed by asymptotic de Sitter behavior of the dark energy equation of state, alters late-time cosmic dynamics, and preserves standard early-universe physics. Overall, our results demonstrate that controlled late-time deviations from $\\Lambda$CDM can improve cosmological concordance.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.19218-b31b1b.svg)](https://arxiv.org/abs/2512.19218) | **Multi-wavelength study of the pre-eruption dip in the recurrent nova T Coronae Borealis preceding imminent nova eruption**  |\n",
       "|| S. Pei, et al. -- incl., <mark>X. Zhang</mark> |\n",
       "|*Appeared on*| *2025-12-23*|\n",
       "|*Comments*| *12 pages, 4 figures. Accepted by Astronomy and Astrophysics*|\n",
       "|**Abstract**|            We present a multi-wavelength study of the symbiotic recurrent nova (RN) T Coronae Borealis (T CrB) using Swift Burst Alert Telescope (BAT) / X-Ray Telescope (XRT) / UltraViolet Optical Telescope (UVOT) and American Association of Variable Stars Observers (AAVSO) observations from 2005 to 2025. Our analysis spans quiescent, high, and pre-eruption dip states. We find that brightening amplitudes increase toward shorter wavelengths in both optical and UV bands, while the UV and X-ray fluxes are generally anti-correlated throughout all phases. During the 2023-2024 pre-eruption dip, soft and hard X-rays increased as optical and ultraviolet (UV) brightness declined, consistent with a transition from an optically thick to thin boundary layer driven by a reduction in the accretion rate. We also report, for the first time, a second, lower-amplitude dip occurring between September 2024 and February 2025 following the primary 2023-2024 pre-eruption dip. The observed variability supports an accretion-variation scenario as a unifying explanation for both the high and dip states, and may signal an imminent nova eruption.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.18421-b31b1b.svg)](https://arxiv.org/abs/2512.18421) | **The evolution of obscured AGN across cosmic time -- A large quasar survey for the 2040s**  |\n",
       "|| T. Urrutia, et al. -- incl., <mark>E. Bañados</mark> |\n",
       "|*Appeared on*| *2025-12-23*|\n",
       "|*Comments*| *White paper in response to ESO's \"Expanding Horizons\" call*|\n",
       "|**Abstract**|            We propose a large quasar demographic optical multi-object spectroscopic (MOS) survey targeting over 50 million AGN candidates up to the highest redshifts possible in the optical (z~6.5), with repeat visits, using a variety of selection criteria available by 2040. A large MOS survey combining all AGN selection methods is the only way to unify a diverse range of different obscured AGN populations within a single, variability- and spectroscopy-based framework, rather than as disjoint classes selected by different methods.         |\n",
       "|<p style=\"color:red\"> **ERROR** </p>| <p style=\"color:red\">latex error not a gzip file</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.004818,
     "end_time": "2025-12-23T04:29:53.606571",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.601753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.625008Z",
     "iopub.status.busy": "2025-12-23T04:29:53.624621Z",
     "iopub.status.idle": "2025-12-23T04:29:53.634064Z",
     "shell.execute_reply": "2025-12-23T04:29:53.633230Z"
    },
    "papermill": {
     "duration": 0.020362,
     "end_time": "2025-12-23T04:29:53.635262",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.614900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.646461Z",
     "iopub.status.busy": "2025-12-23T04:29:53.646191Z",
     "iopub.status.idle": "2025-12-23T04:29:53.649513Z",
     "shell.execute_reply": "2025-12-23T04:29:53.648804Z"
    },
    "papermill": {
     "duration": 0.010295,
     "end_time": "2025-12-23T04:29:53.650721",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.640426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.008212,
     "end_time": "2025-12-23T04:29:53.663964",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.655752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.675402Z",
     "iopub.status.busy": "2025-12-23T04:29:53.675118Z",
     "iopub.status.idle": "2025-12-23T04:29:53.678983Z",
     "shell.execute_reply": "2025-12-23T04:29:53.678145Z"
    },
    "papermill": {
     "duration": 0.011191,
     "end_time": "2025-12-23T04:29:53.680129",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.668938",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.00473,
     "end_time": "2025-12-23T04:29:53.692568",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.687838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.703679Z",
     "iopub.status.busy": "2025-12-23T04:29:53.703389Z",
     "iopub.status.idle": "2025-12-23T04:29:53.711201Z",
     "shell.execute_reply": "2025-12-23T04:29:53.710600Z"
    },
    "papermill": {
     "duration": 0.014874,
     "end_time": "2025-12-23T04:29:53.712249",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.697375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.723823Z",
     "iopub.status.busy": "2025-12-23T04:29:53.723506Z",
     "iopub.status.idle": "2025-12-23T04:29:53.736245Z",
     "shell.execute_reply": "2025-12-23T04:29:53.735623Z"
    },
    "papermill": {
     "duration": 0.019715,
     "end_time": "2025-12-23T04:29:53.737257",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.717542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.748387Z",
     "iopub.status.busy": "2025-12-23T04:29:53.748128Z",
     "iopub.status.idle": "2025-12-23T04:29:53.753112Z",
     "shell.execute_reply": "2025-12-23T04:29:53.752511Z"
    },
    "papermill": {
     "duration": 0.011728,
     "end_time": "2025-12-23T04:29:53.754138",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.742410",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.765047Z",
     "iopub.status.busy": "2025-12-23T04:29:53.764821Z",
     "iopub.status.idle": "2025-12-23T04:29:53.769914Z",
     "shell.execute_reply": "2025-12-23T04:29:53.769253Z"
    },
    "papermill": {
     "duration": 0.01171,
     "end_time": "2025-12-23T04:29:53.770921",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.759211",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.782277Z",
     "iopub.status.busy": "2025-12-23T04:29:53.782065Z",
     "iopub.status.idle": "2025-12-23T04:29:53.788337Z",
     "shell.execute_reply": "2025-12-23T04:29:53.787798Z"
    },
    "papermill": {
     "duration": 0.01313,
     "end_time": "2025-12-23T04:29:53.789335",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.776205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T04:29:53.800537Z",
     "iopub.status.busy": "2025-12-23T04:29:53.800300Z",
     "iopub.status.idle": "2025-12-23T04:29:53.806998Z",
     "shell.execute_reply": "2025-12-23T04:29:53.806396Z"
    },
    "papermill": {
     "duration": 0.013519,
     "end_time": "2025-12-23T04:29:53.808001",
     "exception": false,
     "start_time": "2025-12-23T04:29:53.794482",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.800157,
   "end_time": "2025-12-23T04:29:54.030092",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2025-12-23T04:29:24.229935",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "4f5f0f99ee884060b876bec6b4be0e52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "53adf37975f44f63899471a9d0956423": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f1fbf585ce014cf4ab3ea08f232d6949",
        "IPY_MODEL_b226b27da98e4b3a97a764bd06fb2409",
        "IPY_MODEL_ca523d3343d24ef9bb304b13c1a0f682"
       ],
       "layout": "IPY_MODEL_c6450795da5b463b83dd0c0a2c53cbaf",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5afee68299af4ef9b0f3ee288ce4ce2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6b7b30146886475cb2dce1192efbe6af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7694b01c961f4eaea940e54165ffcabb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a069ac969a4947c1bec294f4c9ccdde3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b226b27da98e4b3a97a764bd06fb2409": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d7ed6c7a1617482c8226496ff9a76ec2",
       "max": 7.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4f5f0f99ee884060b876bec6b4be0e52",
       "tabbable": null,
       "tooltip": null,
       "value": 7.0
      }
     },
     "c6450795da5b463b83dd0c0a2c53cbaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ca523d3343d24ef9bb304b13c1a0f682": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6b7b30146886475cb2dce1192efbe6af",
       "placeholder": "​",
       "style": "IPY_MODEL_5afee68299af4ef9b0f3ee288ce4ce2c",
       "tabbable": null,
       "tooltip": null,
       "value": " 7/7 [00:07&lt;00:00,  1.20it/s]"
      }
     },
     "d7ed6c7a1617482c8226496ff9a76ec2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1fbf585ce014cf4ab3ea08f232d6949": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a069ac969a4947c1bec294f4c9ccdde3",
       "placeholder": "​",
       "style": "IPY_MODEL_7694b01c961f4eaea940e54165ffcabb",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}