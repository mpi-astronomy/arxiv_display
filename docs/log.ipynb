{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.00391,
     "end_time": "2024-09-18T04:11:27.523543",
     "exception": false,
     "start_time": "2024-09-18T04:11:27.519633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:11:27.530900Z",
     "iopub.status.busy": "2024-09-18T04:11:27.530485Z",
     "iopub.status.idle": "2024-09-18T04:11:27.867833Z",
     "shell.execute_reply": "2024-09-18T04:11:27.867130Z"
    },
    "papermill": {
     "duration": 0.34257,
     "end_time": "2024-09-18T04:11:27.869380",
     "exception": false,
     "start_time": "2024-09-18T04:11:27.526810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:11:27.876916Z",
     "iopub.status.busy": "2024-09-18T04:11:27.876425Z",
     "iopub.status.idle": "2024-09-18T04:11:27.881432Z",
     "shell.execute_reply": "2024-09-18T04:11:27.880866Z"
    },
    "papermill": {
     "duration": 0.009787,
     "end_time": "2024-09-18T04:11:27.882426",
     "exception": false,
     "start_time": "2024-09-18T04:11:27.872639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.002938,
     "end_time": "2024-09-18T04:11:27.888514",
     "exception": false,
     "start_time": "2024-09-18T04:11:27.885576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:11:27.895558Z",
     "iopub.status.busy": "2024-09-18T04:11:27.895006Z",
     "iopub.status.idle": "2024-09-18T04:11:47.387988Z",
     "shell.execute_reply": "2024-09-18T04:11:47.387371Z"
    },
    "papermill": {
     "duration": 19.497867,
     "end_time": "2024-09-18T04:11:47.389320",
     "exception": false,
     "start_time": "2024-09-18T04:11:27.891453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Wolf', 'Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Zähringer', 'Scheerer', 'Hoffmann', 'Düe',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'Jäger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:11:47.396859Z",
     "iopub.status.busy": "2024-09-18T04:11:47.396449Z",
     "iopub.status.idle": "2024-09-18T04:11:48.161130Z",
     "shell.execute_reply": "2024-09-18T04:11:48.160385Z"
    },
    "papermill": {
     "duration": 0.769511,
     "end_time": "2024-09-18T04:11:48.162194",
     "exception": false,
     "start_time": "2024-09-18T04:11:47.392683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M. Ramirez  ->  M. Ramirez-Tannus  |  ['M. Ramirez']\n",
      "M. Prunier  ->  M. Prunier  |  ['M. Prunier']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "J. Li  ->  J. Li  |  ['J. Li']\n",
      "J. Li  ->  J. Li  |  ['J. Li']\n",
      "I. J. M. Crossfield  ->  I. J. M. Crossfield  |  ['I. J. M. Crossfield']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "M. Samland  ->  M. Samland  |  ['M. Samland']\n",
      "T. Henning  ->  T. Henning  |  ['T. Henning']\n",
      "G. Perotti  ->  G. Perotti  |  ['G. Perotti']\n",
      "I. J. M. Crossfield  ->  I. J. M. Crossfield  |  ['I. J. M. Crossfield']\n",
      "Arxiv has 75 new papers today\n",
      "          9 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [mpia.get_initials(k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.003067,
     "end_time": "2024-09-18T04:11:48.168762",
     "exception": false,
     "start_time": "2024-09-18T04:11:48.165695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:11:48.176061Z",
     "iopub.status.busy": "2024-09-18T04:11:48.175631Z",
     "iopub.status.idle": "2024-09-18T04:12:32.886496Z",
     "shell.execute_reply": "2024-09-18T04:12:32.885850Z"
    },
    "papermill": {
     "duration": 44.715693,
     "end_time": "2024-09-18T04:12:32.887575",
     "exception": false,
     "start_time": "2024-09-18T04:11:48.171882",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c828a5f1d5884bf4969a52dc1e2aa8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2409.10701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.10701..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.10711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.10711..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M. Prunier  ->  M. Prunier  |  ['M. Prunier']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63 bibliographic references in tmp_2409.10711/CNN-Xray.bbl.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.10799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.10799..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.10961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.10961..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.10963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.10963..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.11083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.11083..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.11173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.11173... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.11176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.11176..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:488: LatexWarning: Error parsing the document directly. Trying to recover.\n",
      "  warnings.warn(LatexWarning(f\"Error parsing the document directly. Trying to recover.\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✘ → 0:header\n",
      "  ↳ 7105:\\section{Introduction} \\label{sec:intro}\n",
      "✔ → 7105:\\section{Introduction} \\label{sec:intro}\n",
      "  ↳ 10400:\\section{Observations and Data Reduction} \\label{reduction}\n",
      "✔ → 10400:\\section{Observations and Data Reduction} \\label{reduction}\n",
      "  ↳ 14003:\\section{Analysis}\\label{analysis}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ → 14003:\\section{Analysis}\\label{analysis}\n",
      "  ↳ 24748:\\section{Discussion}\n",
      "✔ → 24748:\\section{Discussion}\n",
      "  ↳ 30542:\\section{Conclusions}\n",
      "✔ → 30542:\\section{Conclusions}\n",
      "  ↳ 31661:\\section{Acknowledgements}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ → 31661:\\section{Acknowledgements}\n",
      "  ↳ 35039:\\section{Software \\& Facilities}\n",
      "✔ → 35039:\\section{Software \\& Facilities}\n",
      "  ↳ 35365:\\begin{appendix}\n",
      "✔ → 35365:\\begin{appendix}\n",
      "  ↳ 35382:\\section{Image De-convolution}\\label{app:deconvolution}\n",
      "✔ → 35382:\\section{Image De-convolution}\\label{app:deconvolution}\n",
      "  ↳ 36244:\\section{Fits to Atomic Lines}\\label{app:atom}\n",
      "✔ → 36244:\\section{Fits to Atomic Lines}\\label{app:atom}\n",
      "  ↳ 37793:end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2742/1211882699.py:51: LatexWarning: 2409.11176 did not run properly\n",
      "list index out of range\n",
      "  warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2409.11395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.11395..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [mpia.get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.004313,
     "end_time": "2024-09-18T04:12:32.896681",
     "exception": false,
     "start_time": "2024-09-18T04:12:32.892368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:32.906481Z",
     "iopub.status.busy": "2024-09-18T04:12:32.905976Z",
     "iopub.status.idle": "2024-09-18T04:12:32.925543Z",
     "shell.execute_reply": "2024-09-18T04:12:32.924927Z"
    },
    "papermill": {
     "duration": 0.025558,
     "end_time": "2024-09-18T04:12:32.926540",
     "exception": false,
     "start_time": "2024-09-18T04:12:32.900982",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.10711-b31b1b.svg)](https://arxiv.org/abs/2409.10711) | **Deconvolving X-ray Galaxy Cluster Spectra Using a Recurrent Inference Machine**  |\n",
       "|| C. Rhea, et al. -- incl., <mark>M. Prunier</mark> |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *Submitted to AJ*|\n",
       "|**Abstract**|            Recent advances in machine learning algorithms have unlocked new insights in observational astronomy by allowing astronomers to probe new frontiers. In this article, we present a methodology to disentangle the intrinsic X-ray spectrum of galaxy clusters from the instrumental response function. Employing state-of-the-art modeling software and data mining techniques of the Chandra data archive, we construct a set of 100,000 mock Chandra spectra. We train a recurrent inference machine (RIM) to take in the instrumental response and mock observation and output the intrinsic X-ray spectrum. The RIM can recover the mock intrinsic spectrum below the 1-$\\sigma$ error threshold; moreover, the RIM reconstruction of the mock observations are indistinguishable from the observations themselves. To further test the algorithm, we deconvolve extracted spectra from the central regions of the galaxy group NGC 1550, known to have a rich X-ray spectrum, and the massive galaxy clusters Abell 1795. Despite the RIM reconstructions consistently remaining below the 1-$\\sigma$ noise level, the recovered intrinsic spectra did not align with modeled expectations. This discrepancy is likely attributable to the RIM's method of implicitly encoding prior information within the neural network. This approach holds promise for unlocking new possibilities in accurate spectral reconstructions and advancing our understanding of complex X-ray cosmic phenomena.         |"
      ],
      "text/plain": [
       "[2409.10711] Deconvolving X-ray Galaxy Cluster Spectra Using a Recurrent Inference Machine\n",
       "\tC. Rhea, et al. -- incl., <mark>M. Prunier</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.10701-b31b1b.svg)](https://arxiv.org/abs/2409.10701) | **A Novel Optimal Transport-Based Approach for Interpolating Spectral Time Series: Paving the Way for Photometric Classification of Supernovae**  |\n",
       "|| <mark>M. Ramirez</mark>, et al. |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *Accepted for publication in A&A*|\n",
       "|**Abstract**|            This paper introduces a novel method for creating spectral time series, which can be used for generating synthetic light curves for photometric classification but also for applications like K-corrections and bolometric corrections. This approach is particularly valuable in the era of large astronomical surveys, where it can significantly enhance the analysis and understanding of an increasing number of SNe, even in the absence of extensive spectroscopic data. methods: By employing interpolations based on optimal transport theory, starting from a spectroscopic sequence, we derive weighted average spectra with high cadence. The weights incorporate an uncertainty factor, for penalizing interpolations between spectra with significant epoch differences and with poor match between the synthetic and observed photometry. results: Our analysis reveals that even with phase difference of up to 40 days between pairs of spectra, optical transport can generate interpolated spectral time series that closely resemble the original ones. Synthetic photometry extracted from these spectral time series aligns well with observed photometry. The best results are achieved in the V band, with relative residuals less than 10% for 87% and 84% of the data for type Ia and II, respectively. For the B, g, R and r bands the relative residuals are between 65% and 87% within the previously mentioned 10% threshold for both classes. The worse results correspond to the i and I bands where, in the case, of SN~Ia the values drop to 53% and 42%, respectively. conclusions: We introduce a new method to construct spectral time series for individual SN starting from a sparse spectroscopic sequence, demonstrating its capability to produce reliable light curves that can be used for photometric classification.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.10799-b31b1b.svg)](https://arxiv.org/abs/2409.10799) | **Alpha-Proton Differential Flow of A Coronal Mass Ejection at 15 Solar Radii**  |\n",
       "|| <mark>X. Zhang</mark>, et al. |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *8 pages, 3 figures*|\n",
       "|**Abstract**|            Alpha-proton differential flow ($V_{\\alpha p}$) of coronal mass ejections (CMEs) and solar wind from the Sun to 1 au and beyond could influence the instantaneous correspondence of absolute abundances of alpha particles (He$^{2+}$/H$^{+}$) between solar corona and interplanetary space as the abundance of a coronal source can vary with time. Previous studies based on Ulysses and Helios showed that $V_{\\alpha p}$ is negligible within CMEs from 5 to 0.3 au, similar to slow solar wind ($<$ 400 km s$^{-1}$). However, recent new observations using Parker Solar Probe (PSP) revealed that the $V_{\\alpha p}$ of slow wind increases to $\\sim$60 km s$^{-1}$ inside 0.1 au. It is significant to answer whether the $V_{\\alpha p}$ of CMEs exhibits the similar behavior near the Sun. In this Letter, we report the $V_{\\alpha p}$ of a CME measured by PSP at $\\sim$15 $R_\\odot$ for the first time, which demonstrates that the $V_{\\alpha p}$ of CMEs is obvious and complex inside 0.1 au while keeps lower than the local Alfvén speed. A very interesting point is that the same one CME duration can be divided into A and B intervals clearly with Coulomb number below and beyond 0.5, respectively. The means of $V_{\\alpha p}$ and alpha-to-proton temperature ratios of interval A (B) is 96.52 (21.96) km s$^{-1}$ and 7.65 (2.23), respectively. This directly illustrates that Coulomb collisions play an important role in reducing the non-equilibrium features of CMEs. Our study indicates that the absolute elemental abundances of CMEs also might vary during their propagation.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.10961-b31b1b.svg)](https://arxiv.org/abs/2409.10961) | **The ALMA-CRISTAL Survey: Spatially-resolved Star Formation Activity and Dust Content in 4 < z < 6 Star-forming Galaxies**  |\n",
       "|| <mark>J. Li</mark>, et al. |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *30 pages, 16 figures; re-submitted to ApJ*|\n",
       "|**Abstract**|            Using a combination of HST, JWST, and ALMA data, we perform spatially resolved spectral energy distributions (SED) fitting of fourteen 4<z<6 UV-selected main-sequence galaxies targeted by the [CII] Resolved ISM in Star-forming Galaxies with ALMA (CRISTAL) Large Program. We consistently model the emission from stars and dust in ~0.5-1kpc spatial bins to obtain maps of their physical properties. We find no offsets between the stellar masses (M*) and star formation rates (SFRs) derived from their global emission and those from adding up the values in our spatial bins, suggesting there is no bias of outshining by young stars on the derived global properties. We show that ALMA observations are important to derive robust parameter maps because they reduce the uncertainties in Ldust (hence Av and SFR). Using these maps we explore the resolved star-forming main sequence for z~5 galaxies, finding that this relation persists in typical star-forming galaxies in the early Universe. We find less obscured star formation where the M* (and SFR) surface densities are highest, typically in the central regions, contrary to the global relation between these parameters. We speculate this could be caused by feedback driving gas and dust out of these regions. However, more observations of infrared luminosities with ALMA are needed to verify this. Finally, we test empirical SFR prescriptions based on the UV+IR and [CII] line luminosity, finding they work well at the scales probed (~kpc). Our work demonstrates the usefulness of joint HST, JWST, and ALMA resolved SED modeling analyses at high redshift.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.10963-b31b1b.svg)](https://arxiv.org/abs/2409.10963) | **JWST PRIMER: A lack of outshining in four normal z =4-6 galaxies from the ALMA-CRISTAL Survey**  |\n",
       "|| N. E. P. Lines, et al. -- incl., <mark>J. Li</mark> |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *16 pages, 8 figures, 3 tables, plus 4 page appendix. Submitted to MNRAS*|\n",
       "|**Abstract**|            We present a spatially resolved analysis of four star-forming galaxies at $z = 4.44-5.64$ using data from the JWST PRIMER and ALMA-CRISTAL surveys to probe the stellar and inter-stellar medium properties on the sub-kpc scale. In the $1-5\\,\\mu{\\rm m}$ JWST NIRCam imaging we find that the galaxies are composed of multiple clumps (between $2$ and $\\sim 8$) separated by $\\simeq 5\\,{\\rm kpc}$, with comparable morphologies and sizes in the rest-frame UV and optical. Using BAGPIPES to perform pixel-by-pixel SED fitting to the JWST data we show that the SFR ($\\simeq 25\\,{\\rm M}_{\\odot}/{\\rm yr}$) and stellar mass (${\\rm log}_{10}(M_{\\star}/{\\rm M}_{\\odot}) \\simeq 9.5$) derived from the resolved analysis are in close ($ \\lesssim 0.3\\,{\\rm dex}$) agreement with those obtained by fitting the integrated photometry. In contrast to studies of lower-mass sources, we thus find a reduced impact of outshining of the older (more massive) stellar populations in these normal $z \\simeq 5$ galaxies. Our JWST analysis recovers bluer rest-frame UV slopes ($\\beta \\simeq -2.1$) and younger ages ($\\simeq 100\\,{\\rm Myr}$) than archival values. We find that the dust continuum from ALMA-CRISTAL seen in two of these galaxies correlates, as expected, with regions of redder rest-frame UV slopes and the SED-derived $A_{\\rm V}$, as well as the peak in the stellar mass map. We compute the resolved IRX-$\\beta$ relation, showing that the IRX is consistent with the local starburst attenuation curve and further demonstrating the presence of an inhomogeneous dust distribution within the galaxies. A comparison of the CRISTAL sources to those from the FirstLight zoom-in simulation of galaxies with the same $M_{\\star}$ and SFR reveals similar age and colour gradients, suggesting that major mergers may be important in the formation of clumpy galaxies at this epoch.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.11083-b31b1b.svg)](https://arxiv.org/abs/2409.11083) | **Characterisation of TOI-406 as showcase of the THIRSTEE program: A 2-planet system straddling the M-dwarf density gap**  |\n",
       "|| G. Lacedelli, et al. -- incl., <mark>I. J. M. Crossfield</mark> |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *24 pages, 21 figures. SUBMITTED to A&A*|\n",
       "|**Abstract**|            The exoplanet sub-Neptune population currently poses a conundrum. Are small-size planets volatile-rich cores without atmosphere, or are they rocky cores surrounded by H-He envelope? To test the different hypotheses from an observational point of view, a large sample of small-size planets with precise mass and radius measurements is the first necessary step. On top of that, much more information will likely be needed, including atmospheric characterisation and a demographic perspective on their bulk properties. We present the concept and strategy of THIRSTEE, a project which aims at shedding light on the composition of the sub-Neptune population across stellar types by increasing their number and improving the accuracy of bulk density measurements, as well as investigating their atmospheres and performing statistical, demographic analysis. We report the first results of the program, characterising a 2-planet system around the M dwarf TOI-406. We analyse TESS and ground-based photometry, together with ESPRESSO and NIRPS/HARPS RVs to derive the orbital parameters and investigate the internal composition of the 2 planets orbiting TOI-406, which have radii and masses of $R_b = 1.32 \\pm 0.12 R_{\\oplus}$, $M_b = 2.08_{-0.22}^{+0.23} M_{\\oplus}$ and $R_c = 2.08_{-0.15}^{+0.16} R_{\\oplus}$, $M_c = 6.57_{-0.90}^{+1.00} M_{\\oplus}$, and periods of $3.3$ and $13.2$ days, respectively. Planet b is consistent with an Earth-like composition, while planet c is compatible with multiple internal composition models, including volatile-rich planets without H/He atmospheres. The 2 planets are located in 2 distinct regions in the mass-density diagram, supporting the existence of a density gap among small exoplanets around M dwarfs. With an equilibrium temperature of only 368 K, TOI-406 c stands up as a particularly interesting target for atmospheric characterisation with JWST in the low-temperature regime.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.11173-b31b1b.svg)](https://arxiv.org/abs/2409.11173) | **Exploring the Key Features of Repeating Fast Radio Bursts with Machine Learning**  |\n",
       "|| W.-P. Sun, et al. -- incl., <mark>X. Zhang</mark> |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *15 pages, 7 figures*|\n",
       "|**Abstract**|            Fast radio bursts (FRBs) are enigmatic high-energy events with unknown origins, which are observationally divided into two categories, i.e., repeaters and non-repeaters. However, there are potentially a number of non-repeaters that may be misclassified, as repeating bursts are missed due to the limited sensitivity and observation periods, thus misleading the investigation of their physical properties. In this work, we propose a repeater identification method based on the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm and apply the classification to the first Canadian Hydrogen Intensity Mapping Experiment Fast Radio Burst (CHIME/FRB) catalog. We find that the spectral morphology parameters, specifically spectral running ($r$), represent the key features for identifying repeaters from the non-repeaters. Also, the results suggest that repeaters are more biased towards narrowband emission, whereas non-repeaters are inclined toward broadband emission. We provide a list of 163 repeater candidates, with $5$ of which are confirmed with an updated repeater catalog from CHIME/FRB. Our findings help to the understanding of the various properties underlying repeaters and non-repeaters, as well as guidelines for future FRB detection and categorization.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.11395-b31b1b.svg)](https://arxiv.org/abs/2409.11395) | **Quartz Clouds in the Dayside Atmosphere of the Quintessential Hot Jupiter HD 189733 b**  |\n",
       "|| J. Inglis, et al. -- incl., <mark>I. J. M. Crossfield</mark> |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *21 pages, 7 Figures, 3 Tables, Accepted to ApJL*|\n",
       "|**Abstract**|            Recent mid-infrared observations with JWST/MIRI have resulted in the first direct detections of absorption features from silicate clouds in the transmission spectra of two transiting exoplanets, WASP-17 b and WASP-107 b. In this paper, we measure the mid-infrared ($5-12$ $\\mu$m) dayside emission spectrum of the benchmark hot Jupiter HD 189733 b with MIRI LRS by combining data from two secondary eclipse observations. We confirm the previous detection of H$_2$O absorption at 6.5 $\\mu$m from Spitzer/IRS and additionally detect H$_2$S as well as an absorption feature at 8.7 $\\mu$m in both secondary eclipse observations. The excess absorption at 8.7 $\\mu$m can be explained by the presence of small ($\\sim$0.01 $\\mu$m) grains of SiO$_2$[s] in the uppermost layers of HD 189733 b's dayside atmosphere. This is the first direct detection of silicate clouds in HD 189733 b's atmosphere, and the first detection of a distinct absorption feature from silicate clouds on the day side of any hot Jupiter. We find that models including SiO$_2$[s] are preferred by $6-7\\sigma$ over clear models and those with other potential cloud species. The high altitude location of these silicate particles is best explained by formation in the hottest regions of HD 189733 b's dayside atmosphere near the substellar point. We additionally find that HD 189733 b's emission spectrum longward of 9 $\\mu$m displays residual features not well captured by our current atmospheric models. When combined with other JWST observations of HD 189733 b's transmission and emission spectrum at shorter wavelengths, these observations will provide us with the most detailed picture to date of the atmospheric composition and cloud properties of this benchmark hot Jupiter.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.11176-b31b1b.svg)](https://arxiv.org/abs/2409.11176) | **MINDS. JWST-MIRI Observations of a Spatially Resolved Atomic Jet and Polychromatic Molecular Wind Toward SY Cha**  |\n",
       "|| K. R. Schwarz, et al. -- incl., <mark>M. Samland</mark>, <mark>T. Henning</mark>, <mark>G. Perotti</mark> |\n",
       "|*Appeared on*| *2024-09-18*|\n",
       "|*Comments*| *16 pages, 13 figures, 4 tables, submitted to ApJ Letters*|\n",
       "|**Abstract**|            The removal of angular momentum from protostellar systems drives accretion onto the central star and may drive the dispersal of the protoplanetary disk. Winds and jets can contribute to removing angular momentum from the disk, though the dominant process remain unclear. To date, observational studies of resolved disk winds have mostly targeted highly inclined disks. We report the detection of extended H2 and [Ne II] emission toward the young stellar object SY Cha with the JWST Mid-InfraRed Instrument Medium Resolution Spectrometer (MIRI-MRS). This is one of the first polychromatic detections of extended H2 toward a moderately inclined, i=51.1 degrees, Class II source. We measure the semi-opening angle of the H2 emission as well as build a rotation diagram to determine the H2 excitation temperature and abundance. We find a wide semi-opening angle, high temperature, and low column density for the H2 emission, all of which are characteristic of a disk wind. These observations demonstrate MIRI-MRS's utility in expanding studies of resolved disk winds beyond edge-on sources.         |\n",
       "|<p style=\"color:red\"> **ERROR** </p>| <p style=\"color:red\">latex error list index out of range</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.00542,
     "end_time": "2024-09-18T04:12:32.937496",
     "exception": false,
     "start_time": "2024-09-18T04:12:32.932076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:32.949767Z",
     "iopub.status.busy": "2024-09-18T04:12:32.949199Z",
     "iopub.status.idle": "2024-09-18T04:12:32.956068Z",
     "shell.execute_reply": "2024-09-18T04:12:32.955533Z"
    },
    "papermill": {
     "duration": 0.014056,
     "end_time": "2024-09-18T04:12:32.956972",
     "exception": false,
     "start_time": "2024-09-18T04:12:32.942916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:32.968977Z",
     "iopub.status.busy": "2024-09-18T04:12:32.968653Z",
     "iopub.status.idle": "2024-09-18T04:12:32.973440Z",
     "shell.execute_reply": "2024-09-18T04:12:32.972884Z"
    },
    "papermill": {
     "duration": 0.011911,
     "end_time": "2024-09-18T04:12:32.974419",
     "exception": false,
     "start_time": "2024-09-18T04:12:32.962508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found figures ['tmp_2409.10711/./ModelComparison.png', 'tmp_2409.10711/./ObsID5289.png', 'tmp_2409.10711/./RIM.png']\n",
      "copying  tmp_2409.10711/./ModelComparison.png to _build/html/\n",
      "copying  tmp_2409.10711/./ObsID5289.png to _build/html/\n",
      "copying  tmp_2409.10711/./RIM.png to _build/html/\n",
      "exported in  _build/html/2409.10711.md\n",
      "    + _build/html/tmp_2409.10711/./ModelComparison.png\n",
      "    + _build/html/tmp_2409.10711/./ObsID5289.png\n",
      "    + _build/html/tmp_2409.10711/./RIM.png\n"
     ]
    }
   ],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.005474,
     "end_time": "2024-09-18T04:12:32.985479",
     "exception": false,
     "start_time": "2024-09-18T04:12:32.980005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:32.997781Z",
     "iopub.status.busy": "2024-09-18T04:12:32.997233Z",
     "iopub.status.idle": "2024-09-18T04:12:33.001697Z",
     "shell.execute_reply": "2024-09-18T04:12:33.001178Z"
    },
    "papermill": {
     "duration": 0.011695,
     "end_time": "2024-09-18T04:12:33.002691",
     "exception": false,
     "start_time": "2024-09-18T04:12:32.990996",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# Deconvolving X-ray Galaxy Cluster Spectra Using a Recurrent Inference Machine\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2409.10711-b31b1b.svg)](https://arxiv.org/abs/2409.10711)<mark>Appeared on: 2024-09-18</mark> -  _Submitted to AJ_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "C. L. Rhea, et al. -- incl., <mark>M. Prunier</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** Recent advances in machine learning algorithms have unlocked new insights in observational astronomy by allowing astronomers to probe new frontiers. In this article, we present a methodology to disentangle the intrinsic X-ray spectrum of galaxy clusters from the instrumental response function. Employing state-of-the-art modeling software and data mining techniques of the Chandra data archive, we construct a set of 100,000 mock Chandra spectra. We train a recurrent inference machine (RIM) to take in the instrumental response and mock observation and output the intrinsic X-ray spectrum. The RIM can recover the mock intrinsic spectrum below the 1- $\\sigma$ error threshold; moreover, the RIM reconstruction of the mock observations are indistinguishable from the observations themselves. To further test the algorithm, we deconvolve extracted spectra from the central regions of the galaxy group NGC 1550, known to have a rich X-ray spectrum, and the massive galaxy clusters Abell 1795.  Despite the RIM reconstructions consistently remaining below the 1- $\\sigma$ noise level, the recovered intrinsic spectra did not align with modeled expectations. This discrepancy is likely attributable to the RIM's method of implicitly encoding prior information within the neural network. This approach holds promise for unlocking new possibilities in accurate spectral reconstructions and advancing our understanding of  complex X-ray cosmic phenomena.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2409.10711/./ModelComparison.png\" alt=\"Fig2\" width=\"100%\"/>\n",
       "\n",
       "**Figure 2. -** In this figure we compare the RIM solution for both ObIDs (ObsID 3186 and ObsID 3187 in red) and the model taken from literature values (green) for NGC 1550. The later was obtained by estimating the thermodynamic properties of the cluster from the convolved observed spectrum in Kolokythas2020 and then creating a mock spectrum using in \\texttt{SOXS}. (*fig:modelComparison*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2409.10711/./ObsID5289.png\" alt=\"Fig8\" width=\"100%\"/>\n",
       "\n",
       "**Figure 8. -** Results of the RIM on the massive galaxy cluster Abell 1795. In the left panels, we show the RIM solution (i.e. the result of the deconvolution process) for ObsID 5289 (red). The middle panel shows the observed spectrum after background subtraction (black) and the RIM reconstruction (blue). The RIM reconstruction results from passing the RIM solution through the forward model developed in equation \\ref{eqn:spec_mat}. The right panel shows the residual between the observed spectrum and the RIM reconstruction normalized to the noise level of the observation. (*fig:realObs5289*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2409.10711/./RIM.png\" alt=\"Fig1\" width=\"100%\"/>\n",
       "\n",
       "**Figure 1. -** Schematic view of the RIM. Nodes in dark gray are treated as inputs to the RIM. Note that we separate the hidden layers before applying the RIM and combine them after applying the RIM. The teal box represents the RIM itself. (*fig:RIM*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2409.10711\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.005708,
     "end_time": "2024-09-18T04:12:33.014335",
     "exception": false,
     "start_time": "2024-09-18T04:12:33.008627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:33.026898Z",
     "iopub.status.busy": "2024-09-18T04:12:33.026503Z",
     "iopub.status.idle": "2024-09-18T04:12:33.034309Z",
     "shell.execute_reply": "2024-09-18T04:12:33.033791Z"
    },
    "papermill": {
     "duration": 0.015101,
     "end_time": "2024-09-18T04:12:33.035227",
     "exception": false,
     "start_time": "2024-09-18T04:12:33.020126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:33.047855Z",
     "iopub.status.busy": "2024-09-18T04:12:33.047426Z",
     "iopub.status.idle": "2024-09-18T04:12:33.061680Z",
     "shell.execute_reply": "2024-09-18T04:12:33.061146Z"
    },
    "papermill": {
     "duration": 0.02161,
     "end_time": "2024-09-18T04:12:33.062673",
     "exception": false,
     "start_time": "2024-09-18T04:12:33.041063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:33.075428Z",
     "iopub.status.busy": "2024-09-18T04:12:33.075241Z",
     "iopub.status.idle": "2024-09-18T04:12:33.079962Z",
     "shell.execute_reply": "2024-09-18T04:12:33.079447Z"
    },
    "papermill": {
     "duration": 0.012018,
     "end_time": "2024-09-18T04:12:33.080837",
     "exception": false,
     "start_time": "2024-09-18T04:12:33.068819",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:33.093883Z",
     "iopub.status.busy": "2024-09-18T04:12:33.093274Z",
     "iopub.status.idle": "2024-09-18T04:12:33.098228Z",
     "shell.execute_reply": "2024-09-18T04:12:33.097724Z"
    },
    "papermill": {
     "duration": 0.01241,
     "end_time": "2024-09-18T04:12:33.099198",
     "exception": false,
     "start_time": "2024-09-18T04:12:33.086788",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:33.111947Z",
     "iopub.status.busy": "2024-09-18T04:12:33.111708Z",
     "iopub.status.idle": "2024-09-18T04:12:33.118069Z",
     "shell.execute_reply": "2024-09-18T04:12:33.117528Z"
    },
    "papermill": {
     "duration": 0.013774,
     "end_time": "2024-09-18T04:12:33.119021",
     "exception": false,
     "start_time": "2024-09-18T04:12:33.105247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:12:33.131964Z",
     "iopub.status.busy": "2024-09-18T04:12:33.131759Z",
     "iopub.status.idle": "2024-09-18T04:12:33.137852Z",
     "shell.execute_reply": "2024-09-18T04:12:33.137340Z"
    },
    "papermill": {
     "duration": 0.013675,
     "end_time": "2024-09-18T04:12:33.138838",
     "exception": false,
     "start_time": "2024-09-18T04:12:33.125163",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.688704,
   "end_time": "2024-09-18T04:12:33.361085",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2024-09-18T04:11:26.672381",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "18a0904b10564320b6ee08bc2075f45f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "337b94e4abb84532bc0e0a8098a2d3e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5cb6fd631079425abdbcdec9cdc896a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7061e6d97528472c9ebf7057a5736699": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70727879eff14a559e0fe1af063edc9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7fa32c04e8ee416e8c81fbc92fff3b2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c20d109b6bc54d43bf1f1d89a43e3531": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7061e6d97528472c9ebf7057a5736699",
       "placeholder": "​",
       "style": "IPY_MODEL_70727879eff14a559e0fe1af063edc9e",
       "tabbable": null,
       "tooltip": null,
       "value": " 9/9 [00:44&lt;00:00,  5.02s/it]"
      }
     },
     "c2fb66035ecf4f81957779db7aef3984": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18a0904b10564320b6ee08bc2075f45f",
       "max": 9.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_337b94e4abb84532bc0e0a8098a2d3e1",
       "tabbable": null,
       "tooltip": null,
       "value": 9.0
      }
     },
     "c828a5f1d5884bf4969a52dc1e2aa8ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f0c68b1b888348af8a75b8ef980b9436",
        "IPY_MODEL_c2fb66035ecf4f81957779db7aef3984",
        "IPY_MODEL_c20d109b6bc54d43bf1f1d89a43e3531"
       ],
       "layout": "IPY_MODEL_def3b76d05284442b40f5e37aa6d3c07",
       "tabbable": null,
       "tooltip": null
      }
     },
     "def3b76d05284442b40f5e37aa6d3c07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0c68b1b888348af8a75b8ef980b9436": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7fa32c04e8ee416e8c81fbc92fff3b2d",
       "placeholder": "​",
       "style": "IPY_MODEL_5cb6fd631079425abdbcdec9cdc896a8",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}