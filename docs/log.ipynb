{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.004591,
     "end_time": "2023-11-08T04:07:58.984353",
     "exception": false,
     "start_time": "2023-11-08T04:07:58.979762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:07:58.994831Z",
     "iopub.status.busy": "2023-11-08T04:07:58.994133Z",
     "iopub.status.idle": "2023-11-08T04:07:59.467415Z",
     "shell.execute_reply": "2023-11-08T04:07:59.466759Z"
    },
    "papermill": {
     "duration": 0.479621,
     "end_time": "2023-11-08T04:07:59.469297",
     "exception": false,
     "start_time": "2023-11-08T04:07:58.989676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:07:59.478325Z",
     "iopub.status.busy": "2023-11-08T04:07:59.477679Z",
     "iopub.status.idle": "2023-11-08T04:07:59.484943Z",
     "shell.execute_reply": "2023-11-08T04:07:59.483752Z"
    },
    "papermill": {
     "duration": 0.013432,
     "end_time": "2023-11-08T04:07:59.486410",
     "exception": false,
     "start_time": "2023-11-08T04:07:59.472978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.003342,
     "end_time": "2023-11-08T04:07:59.493222",
     "exception": false,
     "start_time": "2023-11-08T04:07:59.489880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:07:59.501300Z",
     "iopub.status.busy": "2023-11-08T04:07:59.500846Z",
     "iopub.status.idle": "2023-11-08T04:08:20.110266Z",
     "shell.execute_reply": "2023-11-08T04:08:20.109574Z"
    },
    "papermill": {
     "duration": 20.615301,
     "end_time": "2023-11-08T04:08:20.111854",
     "exception": false,
     "start_time": "2023-11-08T04:07:59.496553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S. Scheithauer  ->  S. Scheithauer  |  ['S. Scheithauer']\n",
      "J. Li  ->  J. Li  |  ['J. Li']\n",
      "Zhang  ->  X. Zhang  |  ['Zhang']\n",
      "Zhang  ->  X. Zhang  |  ['Zhang']\n",
      "J. L.  ->  J. Li  |  ['J. Li']\n",
      "Zhang  ->  X. Zhang  |  ['Zhang']\n",
      "Zhang  ->  X. Zhang  |  ['Zhang']\n",
      "G. Guiglion  ->  G. Guiglion  |  ['G. Guiglion']\n",
      "M. Hobson  ->  M. Hobson  |  ['M. Hobson']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arxiv has 71 new papers today\n",
      "          5 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "# get list from MPIA website\n",
    "# it automatically filters identified non-scientists :func:`mpia.filter_non_scientists`\n",
    "mpia_authors = mpia.get_mpia_mitarbeiter_list()\n",
    "normed_mpia_authors = [k[1] for k in mpia_authors]   # initials + fullname\n",
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [mpia.get_initials(k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, normed_mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.003907,
     "end_time": "2023-11-08T04:08:20.119662",
     "exception": false,
     "start_time": "2023-11-08T04:08:20.115755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:08:20.128598Z",
     "iopub.status.busy": "2023-11-08T04:08:20.127827Z",
     "iopub.status.idle": "2023-11-08T04:10:06.560743Z",
     "shell.execute_reply": "2023-11-08T04:10:06.560109Z"
    },
    "papermill": {
     "duration": 106.439699,
     "end_time": "2023-11-08T04:10:06.562890",
     "exception": false,
     "start_time": "2023-11-08T04:08:20.123191",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900ca2b598b04807889af0af7de07432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2311.03472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2311.03472..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/mirror-properties\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/mirror-properties as tmp_2311.03472/./figures/mirror-properties.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/overview_model_IP\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/overview_model_IP as tmp_2311.03472/./figures/overview_model_IP.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/fibercoupler\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/fibercoupler as tmp_2311.03472/./figures/fibercoupler.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/spectrometer\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/spectrometer as tmp_2311.03472/./figures/spectrometer.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/Comparison_telescopes\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/Comparison_telescopes as tmp_2311.03472/./figures/Comparison_telescopes.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/mirror-coating\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/mirror-coating as tmp_2311.03472/./figures/mirror-coating.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/wavelength\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/wavelength as tmp_2311.03472/./figures/wavelength.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/overview_model\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/overview_model as tmp_2311.03472/./figures/overview_model.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/res_dolp\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/res_dolp as tmp_2311.03472/./figures/res_dolp.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure figures/res_dolp_cor\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure figures/res_dolp_cor as tmp_2311.03472/./figures/res_dolp_cor.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 bibliographic references in tmp_2311.03472/polarization_v3.bbl.\n",
      "syntax error in line 4: '=' expected\n",
      "Retrieving document from  https://arxiv.org/e-print/2311.03494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2311.03494..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2311.03635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3548: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3548: LatexWarning: Found documentclass in tmp_2311.03494/Revised_main.tex\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2311.03635..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2311.04146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2311.04146..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3548: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3548: LatexWarning: Found documentclass in tmp_2311.04146/main.tex\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:399: LatexWarning: Latex injecting: 'author_list.tex' from 'tmp_2311.04146/author_list.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure paper/fig/SDSS_confusion_05_contamination\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure paper/fig/SDSS_confusion_05_contamination as tmp_2311.04146/./paper/fig/SDSS_confusion_05_contamination.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:120: LatexWarning: attempting recovering figure paper/fig/SDSS_confusion_10_contamination\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:125: LatexWarning: Recovered figure paper/fig/SDSS_confusion_10_contamination as tmp_2311.04146/./paper/fig/SDSS_confusion_10_contamination.pdf\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 bibliographic references in tmp_2311.04146/main.bbl.\n",
      "syntax error in line 165: '=' expected\n",
      "Retrieving document from  https://arxiv.org/e-print/2311.04153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2311.04153..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    paper_id = paper['identifier'].lower().replace('arxiv:', '')\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [mpia.get_initials(k) for k in doc.authors], \n",
    "                normed_mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.005424,
     "end_time": "2023-11-08T04:10:06.573643",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.568219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.585619Z",
     "iopub.status.busy": "2023-11-08T04:10:06.584834Z",
     "iopub.status.idle": "2023-11-08T04:10:06.601436Z",
     "shell.execute_reply": "2023-11-08T04:10:06.600830Z"
    },
    "papermill": {
     "duration": 0.024339,
     "end_time": "2023-11-08T04:10:06.602996",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.578657",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-arXiv:2311.03472-b31b1b.svg)](https://arxiv.org/abs/arXiv:2311.03472) | **Polarization analysis of the VLTI and GRAVITY**  |\n",
       "|| G. Collaboration, et al. -- incl., <mark>S. Scheithauer</mark> |\n",
       "|*Appeared on*| *2023-11-08*|\n",
       "|*Comments*| *Accepted by A&A*|\n",
       "|**Abstract**| The goal of this work is to characterize the polarization effects of the VLTI and GRAVITY. This is needed to calibrate polarimetric observations with GRAVITY for instrumental effects and to understand the systematic error introduced to the astrometry due to birefringence when observing targets with a significant intrinsic polarization. By combining a model of the VLTI light path and its mirrors and dedicated experimental data, we construct a full polarization model of the VLTI UTs and the GRAVITY instrument. We first characterize all telescopes together to construct a UT calibration model for polarized targets. We then expand the model to include the differential birefringence. With this, we can constrain the systematic errors for highly polarized targets. Together with this paper, we publish a standalone Python package to calibrate the instrumental effects on polarimetric observations. This enables the community to use GRAVITY to observe targets in a polarimetric observing mode. We demonstrate the calibration model with the galactic center star IRS 16C. For this source, we can constrain the polarization degree to within 0.4 % and the polarization angle within 5 deg while being consistent with the literature. Furthermore, we show that there is no significant contrast loss, even if the science and fringe-tracker targets have significantly different polarization, and we determine that the phase error in such an observation is smaller than 1 deg, corresponding to an astrometric error of 10 {\\mu}as. With this work, we enable the use of the polarimetric mode with GRAVITY/UTs and outline the steps necessary to observe and calibrate polarized targets. We demonstrate that it is possible to measure the intrinsic polarization of astrophysical sources with high precision and that polarization effects do not limit astrometric observations of polarized targets. |"
      ],
      "text/plain": [
       "[arXiv:2311.03472] Polarization analysis of the VLTI and GRAVITY\n",
       "\tG. Collaboration, et al. -- incl., <mark>S. Scheithauer</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-arXiv:2311.04146-b31b1b.svg)](https://arxiv.org/abs/arXiv:2311.04146) | **Galaxy Spectra neural Network (GaSNet). II. Using Deep Learning for  Spectral Classification and Redshift Predictions**  |\n",
       "|| F. Zhong, et al. -- incl., <mark>G. Guiglion</mark> |\n",
       "|*Appeared on*| *2023-11-08*|\n",
       "|*Comments*| *23 pages and 31 figures. The draft has been submitted to MNRAS*|\n",
       "|**Abstract**| Large sky spectroscopic surveys have reached the scale of photometric surveys in terms of sample sizes and data complexity. These huge datasets require efficient, accurate, and flexible automated tools for data analysis and science exploitation. We present the Galaxy Spectra Network/GaSNet-II, a supervised multi-network deep learning tool for spectra classification and redshift prediction. GaSNet-II can be trained to identify a customized number of classes and optimize the redshift predictions for classified objects in each of them. It also provides redshift errors, using a network-of-networks that reproduces a Monte Carlo test on each spectrum, by randomizing their weight initialization. As a demonstration of the capability of the deep learning pipeline, we use 260k Sloan Digital Sky Survey spectra from Data Release 16, separated into 13 classes including 140k galactic, and 120k extragalactic objects. GaSNet-II achieves 92.4% average classification accuracy over the 13 classes (larger than 90% for the majority of them), and an average redshift error of approximately 0.23% for galaxies and 2.1% for quasars. We further train/test the same pipeline to classify spectra and predict redshifts for a sample of 200k 4MOST mock spectra and 21k publicly released DESI spectra. On 4MOST mock data, we reach 93.4% accuracy in 10-class classification and an average redshift error of 0.55% for galaxies and 0.3% for active galactic nuclei. On DESI data, we reach 96% accuracy in (star/galaxy/quasar only) classification and an average redshift error of 2.8% for galaxies and 4.8% for quasars, despite the small sample size available. GaSNet-II can process ~40k spectra in less than one minute, on a normal Desktop GPU. This makes the pipeline particularly suitable for real-time analyses of Stage-IV survey observations and an ideal tool for feedback loops aimed at night-by-night survey strategy optimization. |"
      ],
      "text/plain": [
       "[arXiv:2311.04146] Galaxy Spectra neural Network (GaSNet). II. Using Deep Learning for  Spectral Classification and Redshift Predictions\n",
       "\tF. Zhong, et al. -- incl., <mark>G. Guiglion</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-arXiv:2311.03494-b31b1b.svg)](https://arxiv.org/abs/arXiv:2311.03494) | **The Effects of the Local Environment on a Compact Radio Interferometer  I: Cross-coupling in the Tianlai Dish Pathfinder Array**  |\n",
       "|| J. Kwak, et al. -- incl., <mark>J. Li</mark> |\n",
       "|*Appeared on*| *2023-11-08*|\n",
       "|*Comments*| *20 pages, 22 figures, accepted for publication by JAI*|\n",
       "|**Abstract**| The visibilities measured by radio astronomical interferometers include non-astronomical correlated signals that arise from the local environment of the array. These correlated signals are especially important in compact arrays such as those under development for 21\\,cm intensity mapping. The amplitudes of the contaminated visibilities can exceed the expected 21\\,cm signal and represent a significant systematic effect. We study the receiver noise radiated by antennas in compact arrays and develop a model for how it couples to other antennas. We apply the model to the Tianlai Dish Pathfinder Array (TDPA), a compact array of 16, 6-m dish antennas. The coupling model includes electromagnetic simulations, measurements with a network analyzer, and measurements of the noise of the receivers. We compare the model to drift-scan observations with the array and set requirements on the level of antenna cross-coupling for 21\\,cm intensity mapping instruments. We find that for the TDPA, cross-coupling would have to be reduced by TBD orders of magnitude in order to contribute negligibly to the visibilities. |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-arXiv:2311.03635-b31b1b.svg)](https://arxiv.org/abs/arXiv:2311.03635) | **A Phase-resolved View of the Low-frequency Quasiperiodic Oscillations  from the Black Hole Binary MAXI J1820+070**  |\n",
       "|| Shui, et al. -- incl., <mark>Zhang</mark>, <mark>Zhang</mark>, <mark>J. L.</mark>, <mark>Zhang</mark>, <mark>Zhang</mark> |\n",
       "|*Appeared on*| *2023-11-08*|\n",
       "|*Comments*| *Accepted for publication in The Astrophysical Journal*|\n",
       "|**Abstract**| Although low-frequency quasiperiodic oscillations (LFQPOs) are commonly detected in the X-ray light curves of accreting black hole X-ray binaries, their origin still remains elusive. In this study, we conduct phase-resolved spectroscopy in a broad energy band for LFQPOs in MAXI J1820+070 during its 2018 outburst, utilizing Insight-HXMT observations. By employing the Hilbert-Huang transform method, we extract the intrinsic quasiperiodic oscillation (QPO) variability, and obtain the corresponding instantaneous amplitude, phase, and frequency functions for each data point. With well-defined phases, we construct QPO waveforms and phase-resolved spectra. By comparing the phase-folded waveform with that obtained from the Fourier method, we find that phase folding on the phase of the QPO fundamental frequency leads to a slight reduction in the contribution of the harmonic component. This suggests that the phase difference between QPO harmonics exhibits time variability. Phase-resolved spectral analysis reveals strong concurrent modulations of the spectral index and flux across the bright hard state. The modulation of the spectral index could potentially be explained by both the corona and jet precession models, with the latter requiring efficient acceleration within the jet. Furthermore, significant modulations in the reflection fraction are detected exclusively during the later stages of the bright hard state. These findings provide support for the geometric origin of LFQPOs and offer valuable insights into the evolution of the accretion geometry during the outburst in MAXI J1820+070. |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-arXiv:2311.04153-b31b1b.svg)](https://arxiv.org/abs/arXiv:2311.04153) | **Kernel-, mean- and noise-marginalised Gaussian processes for exoplanet  transits and $H_0$ inference**  |\n",
       "|| N. Kroupa, D. Yallup, W. Handley, <mark>M. Hobson</mark> |\n",
       "|*Appeared on*| *2023-11-08*|\n",
       "|*Comments*| *17 pages, 11 figures, submitted to Monthly Notices of the Royal Astronomical Society*|\n",
       "|**Abstract**| Using a fully Bayesian approach, Gaussian Process regression is extended to include marginalisation over the kernel choice and kernel hyperparameters. In addition, Bayesian model comparison via the evidence enables direct kernel comparison. The calculation of the joint posterior was implemented with a transdimensional sampler which simultaneously samples over the discrete kernel choice and their hyperparameters by embedding these in a higher-dimensional space, from which samples are taken using nested sampling. This method was explored on synthetic data from exoplanet transit light curve simulations. The true kernel was recovered in the low noise region while no kernel was preferred for larger noise. Furthermore, inference of the physical exoplanet hyperparameters was conducted. In the high noise region, either the bias in the posteriors was removed, the posteriors were broadened or the accuracy of the inference was increased. In addition, the uncertainty in mean function predictive distribution increased due to the uncertainty in the kernel choice. Subsequently, the method was extended to marginalisation over mean functions and noise models and applied to the inference of the present-day Hubble parameter, $H_0$, from real measurements of the Hubble parameter as a function of redshift, derived from the cosmologically model-independent cosmic chronometer and {\\Lambda}CDM-dependent baryon acoustic oscillation observations. The inferred $H_0$ values from the cosmic chronometers, baryon acoustic oscillations and combined datasets are $H_0$ = 66$\\pm$6 km/s/Mpc, $H_0$ = 67$\\pm$10 km/s/Mpc and $H_0$ = 69$\\pm$6 km/s/Mpc, respectively. The kernel posterior of the cosmic chronometers dataset prefers a non-stationary linear kernel. Finally, the datasets are shown to be not in tension with ln(R)=12.17$\\pm$0.02. |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.005862,
     "end_time": "2023-11-08T04:10:06.614783",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.608921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.628012Z",
     "iopub.status.busy": "2023-11-08T04:10:06.627398Z",
     "iopub.status.idle": "2023-11-08T04:10:06.634881Z",
     "shell.execute_reply": "2023-11-08T04:10:06.634285Z"
    },
    "papermill": {
     "duration": 0.015771,
     "end_time": "2023-11-08T04:10:06.636382",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.620611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.650004Z",
     "iopub.status.busy": "2023-11-08T04:10:06.649288Z",
     "iopub.status.idle": "2023-11-08T04:10:06.658427Z",
     "shell.execute_reply": "2023-11-08T04:10:06.657791Z"
    },
    "papermill": {
     "duration": 0.017476,
     "end_time": "2023-11-08T04:10:06.659857",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.642381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported in  _build/html/2311.03472.md\n",
      "    + _build/html/tmp_2311.03472/./figures/GRAVITY_fit.png\n",
      "    + _build/html/tmp_2311.03472/./figures/vlti_pol_paper_fig2.png\n",
      "    + _build/html/tmp_2311.03472/./figures/ev_phaseerror.png\n",
      "exported in  _build/html/2311.04146.md\n",
      "    + _build/html/tmp_2311.04146/./paper/fig/new_pipeline_2.png\n",
      "    + _build/html/tmp_2311.04146/./paper/fig/SDSS_one2one_MC.png\n",
      "    + _build/html/tmp_2311.04146/./paper/fig/SDSS_exgla.png\n"
     ]
    }
   ],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.005928,
     "end_time": "2023-11-08T04:10:06.671892",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.665964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.685660Z",
     "iopub.status.busy": "2023-11-08T04:10:06.685189Z",
     "iopub.status.idle": "2023-11-08T04:10:06.691430Z",
     "shell.execute_reply": "2023-11-08T04:10:06.690809Z"
    },
    "papermill": {
     "duration": 0.015155,
     "end_time": "2023-11-08T04:10:06.693148",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.677993",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# Polarization analysis of the VLTI and GRAVITY\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2311.03472-b31b1b.svg)](https://arxiv.org/abs/2311.03472)<mark>Appeared on: 2023-11-08</mark> -  _Accepted by A&A_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "G. Collaboration, et al. -- incl., <mark>S. Scheithauer</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** The goal of this work is to characterize the polarization effects of the VLTI and GRAVITY. This is needed to calibrate polarimetric observations with GRAVITY for instrumental effects and to understand the systematic error introduced to the astrometry due to birefringence when observing targets with a significant intrinsic polarization. By combining a model of the VLTI light path and its mirrors and dedicated experimental data, we construct a full polarization model of the VLTI UTs and the GRAVITY instrument. We first characterize all telescopes together to construct a UT calibration model for polarized targets. We then expand the model to include the differential birefringence. With this, we can constrain the systematic errors for highly polarized targets. Together with this paper, we publish a standalone Python package to calibrate the instrumental effects on polarimetric observations. This enables the community to use GRAVITY to observe targets in a polarimetric observing mode. We demonstrate the calibration model with the galactic center star IRS 16C. For this source, we can constrain the polarization degree to within 0.4 % and the polarization angle within 5 deg while being consistent with the literature. Furthermore, we show that there is no significant contrast loss, even if the science and fringe-tracker targets have significantly different polarization, and we determine that the phase error in such an observation is smaller than 1 deg, corresponding to an astrometric error of 10 {\\mu}as. With this work, we enable the use of the polarimetric mode with GRAVITY/UTs and outline the steps necessary to observe and calibrate polarized targets. We demonstrate that it is possible to measure the intrinsic polarization of astrophysical sources with high precision and that polarization effects do not limit astrometric observations of polarized targets. \n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2311.03472/./figures/GRAVITY_fit.png\" alt=\"Fig18\" width=\"100%\"/>\n",
       "\n",
       "**Figure 18. -** Measured polarization with GRAVITY in the different observing modes. The left column shows the measurement in the off-axis mode, and the right column in the on-axis mode. In the top row, the linear polarization filter is used for the input light source; in the bottom, it is not. In all plots, the Stokes Q data points are shown in red/orange and the Stokes U in grey. The data is the average over all four GRAVITY beams. The results from the fitted model are shown in black lines. (*fig:grav_full*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2311.03472/./figures/vlti_pol_paper_fig2.png\" alt=\"Fig12\" width=\"100%\"/>\n",
       "\n",
       "**Figure 12. -** Simplified version of the VLTI light path from \\autoref{fig:sketch_path} to show the modeling and the experimental setup. The black rectangles show where the laser is launched and where the polarimeter is mounted. The names of the mirrors used in the text are given. The color of the mirror number shows the grouping which was used for the fitting. Grey mirrors are not fitted in our calibration model. Each colored group is located in one common plane: M4-M8 are in one vertical plane, and M10 - M18 are in one horizontal plane. (*fig:sketch_exp*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2311.03472/./figures/ev_phaseerror.png\" alt=\"Fig20\" width=\"100%\"/>\n",
       "\n",
       "**Figure 20. -** Error in the visibility phases due to differential birefringence for all telescope positions. The left two columns show the error for the first polarization P1 and the right two for the second polarization P2. (*fig:ev_phaseerr*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2311.03472\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\zhong}[1]{{\\color{black}{#1}}}$\n",
       "$\\newcommand{\\zhongblue}[1]{{\\color{black}{#1}}}$\n",
       "$\\newcommand{\\nic}[1]{{\\color{magenta}{#1}}}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# Galaxy Spectra neural Network (GaSNet). II. Using Deep Learning for Spectral Classification and Redshift Predictions\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2311.04146-b31b1b.svg)](https://arxiv.org/abs/2311.04146)<mark>Appeared on: 2023-11-08</mark> -  _23 pages and 31 figures. The draft has been submitted to MNRAS_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "F. Zhong, et al. -- incl., <mark>G. Guiglion</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** Large sky spectroscopic surveys have reached the scale of photometric surveys in terms of sample sizes and data complexity. These huge datasets require efficient, accurate, and flexible automated tools for data analysis and science exploitation. We present the Galaxy Spectra Network/GaSNet-II, a supervised multi-network deep learning tool for spectra classification and redshift prediction. GaSNet-II can be trained to identify a customized number of classes and optimize the redshift predictions for classified objects in each of them.It also provides redshift errors, using a network-of-networks that reproduces a Monte Carlo test on each spectrum, by randomizing their weight initialization.As a demonstration of the capability of the deep learning pipeline, we use 260k Sloan Digital Sky Survey spectra from Data Release 16, separated into 13 classes including 140k galactic, and 120k extragalactic objects.GaSNet-II achieves 92.4 \\% average classification accuracy over the 13 classes (larger than 90 \\% for the majority of them), and an average redshift error of approximately 0.23 \\% for galaxies and 2.1 \\% for quasars.We further train/test the same pipeline to classify spectra and predict redshifts for a sample of 200k 4MOST mock spectra and 21k publicly released DESI spectra. On 4MOST mock data, we reach 93.4 \\% accuracy in 10-class classification and an average redshift error of 0.55 \\% for galaxies and 0.3 \\% for active galactic nuclei. On DESI data, we reach 96 \\% accuracy in (star/galaxy/quasar only) classification and an average redshift error of 2.8 \\% for galaxies and 4.8 \\% for quasars, despite the small sample size available. GaSNet-II can process $\\sim40$ k spectra in less than one minute, on a normal Desktop GPU. This makes the pipeline particularly suitable for real-time analyses of Stage-IV survey observations and an ideal tool for feedback loops aimed at night-by-night survey strategy optimization.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2311.04146/./paper/fig/new_pipeline_2.png\" alt=\"Fig30\" width=\"100%\"/>\n",
       "\n",
       "**Figure 30. -** _ Panel a)_: the general structure of the multi-networks pipeline. $\\it ResNet\\_P$ is used as a classifier and  $\\it ResNet\\_7-12$ is used for redshift prediction of extragalactic targets (note that $\\it ResNet\\_0-6$ are missing because we do not need to predict the redshift of stars). One of the advantages of this structure is that it is simple and controllable, and can be trained and predicted in parallel. _ Panel b)_: the detailed description of single sub-network $\\it ResNet_i$(bottom figures) architecture, made by small blocks. The input of the network is 5001-pixel spectrum flux, and the output is the probability or redshift. The difference between classification ($\\it n=13,  softmax$) and redshift prediction ($\\it n=1,  None$) is the output dimension and the activation in the last layer. A feature-extract block $\\it Block(n)$ and a fully connected block $\\it Dense(n)$ are shown. $\\it cov1d$ is the 1-D convolution layer. In one $\\it cov1d$ rectangle, $5$ is the kernel size; $/3$ is the stride size; $n$ is the number of channels. $\\it relu$, $\\it softmax$ are the activate function, $\\it None$ represents no activate function here, that means liner. The left $\\it cov1d$ in the $\\it Block(n)$ shortcut is used to match the shape. $\\it pool1d$ is a 1-D Maxpooling layer. As a schematic, the top right panel shows how to predict the redshift error of the label 7 (GALAXY\\_nan) subclass in parallel. Though 10 (customized) same sub-networks, trained by the same data but with different initial weights, 10 different redshifts were obtained from a single spectrum input. The expectation and error can be calculated. Other redshift errors are obtained in the same way. (*fig: full pipeline*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2311.04146/./paper/fig/SDSS_one2one_MC.png\" alt=\"Fig32\" width=\"100%\"/>\n",
       "\n",
       "**Figure 32. -** The mean redshift predictions and errors of the 6 extragalactic SDSS subclasses. The error bar of each sample point represents the standard deviation obtained from the MC estimation of 10 sub-networks. In the top left of each main panel the subclass name, MAE, $\\Delta z$, and the GF are displayed. The points in the top panels display the mean of the distribution of the $\\overline{z}_p$ residuals ($\\overline{z}_p-z_t$) with respect to the true values ($z_t$) in each bin, and error bars corresponding mean $\\sigma_z$ values (see text).\n",
       "     (*fig: redshift error*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2311.04146/./paper/fig/SDSS_exgla.png\" alt=\"Fig2\" width=\"100%\"/>\n",
       "\n",
       "**Figure 2. -** Example spectra of SDSS extragalactic sub-classes,\n",
       "    as listed in Table \\ref{Table:1}. We can clearly see the different features characterizing the different classes. From top to bottom, in particular, we can notice the increasing importance of the emission lines that play an important role in redshift prediction. The `nan' type spectra generally lack such emission lines, although they might still contain some low-SNR ones, which are hard to see. This means that the `nan' sample might overlap with other emission line classes. QSOs also show a power-law continuum that does not carry any redshift information. (*fig: spectra_2*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2311.04146\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.00662,
     "end_time": "2023-11-08T04:10:06.706310",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.699690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.720475Z",
     "iopub.status.busy": "2023-11-08T04:10:06.720041Z",
     "iopub.status.idle": "2023-11-08T04:10:06.730266Z",
     "shell.execute_reply": "2023-11-08T04:10:06.729610Z"
    },
    "papermill": {
     "duration": 0.019045,
     "end_time": "2023-11-08T04:10:06.731757",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.712712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.746230Z",
     "iopub.status.busy": "2023-11-08T04:10:06.745659Z",
     "iopub.status.idle": "2023-11-08T04:10:06.768000Z",
     "shell.execute_reply": "2023-11-08T04:10:06.767294Z"
    },
    "papermill": {
     "duration": 0.03124,
     "end_time": "2023-11-08T04:10:06.769564",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.738324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.785068Z",
     "iopub.status.busy": "2023-11-08T04:10:06.784536Z",
     "iopub.status.idle": "2023-11-08T04:10:06.790880Z",
     "shell.execute_reply": "2023-11-08T04:10:06.790216Z"
    },
    "papermill": {
     "duration": 0.015485,
     "end_time": "2023-11-08T04:10:06.792263",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.776778",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.807013Z",
     "iopub.status.busy": "2023-11-08T04:10:06.806595Z",
     "iopub.status.idle": "2023-11-08T04:10:06.812065Z",
     "shell.execute_reply": "2023-11-08T04:10:06.811435Z"
    },
    "papermill": {
     "duration": 0.014224,
     "end_time": "2023-11-08T04:10:06.813427",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.799203",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.828012Z",
     "iopub.status.busy": "2023-11-08T04:10:06.827462Z",
     "iopub.status.idle": "2023-11-08T04:10:06.836275Z",
     "shell.execute_reply": "2023-11-08T04:10:06.835660Z"
    },
    "papermill": {
     "duration": 0.017743,
     "end_time": "2023-11-08T04:10:06.837763",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.820020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T04:10:06.852780Z",
     "iopub.status.busy": "2023-11-08T04:10:06.852188Z",
     "iopub.status.idle": "2023-11-08T04:10:06.859332Z",
     "shell.execute_reply": "2023-11-08T04:10:06.858687Z"
    },
    "papermill": {
     "duration": 0.016158,
     "end_time": "2023-11-08T04:10:06.860752",
     "exception": false,
     "start_time": "2023-11-08T04:10:06.844594",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 129.362726,
   "end_time": "2023-11-08T04:10:07.083756",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2023-11-08T04:07:57.721030",
   "version": "2.5.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "044e0ad2a1f04d7fa0a7df428e744b7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_471c93fd6bd64b81bf87d8c43013f7e0",
       "placeholder": "​",
       "style": "IPY_MODEL_f3644009a77642119a594e367a372b42",
       "tabbable": null,
       "tooltip": null,
       "value": " 5/5 [01:46&lt;00:00, 23.57s/it]"
      }
     },
     "05c312e8f646437b96ba19067f7a2c40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fdfac38cdc1d42ed9d13116c97125237",
       "placeholder": "​",
       "style": "IPY_MODEL_f882215baab14e44b20f6dd7291a36e8",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "471c93fd6bd64b81bf87d8c43013f7e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49784150cb424f338bbd494b64441325": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "900ca2b598b04807889af0af7de07432": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_05c312e8f646437b96ba19067f7a2c40",
        "IPY_MODEL_ec2c9ee25a9441c3b6cab02c1b21a245",
        "IPY_MODEL_044e0ad2a1f04d7fa0a7df428e744b7d"
       ],
       "layout": "IPY_MODEL_49784150cb424f338bbd494b64441325",
       "tabbable": null,
       "tooltip": null
      }
     },
     "de4b2dedb3d94985a71fdfe71b622d62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "debbe610af7b4592ba472d58f798c8a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec2c9ee25a9441c3b6cab02c1b21a245": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_debbe610af7b4592ba472d58f798c8a5",
       "max": 5.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_de4b2dedb3d94985a71fdfe71b622d62",
       "tabbable": null,
       "tooltip": null,
       "value": 5.0
      }
     },
     "f3644009a77642119a594e367a372b42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f882215baab14e44b20f6dd7291a36e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fdfac38cdc1d42ed9d13116c97125237": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}