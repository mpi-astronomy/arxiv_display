{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.00381,
     "end_time": "2025-12-30T04:30:54.484854",
     "exception": false,
     "start_time": "2025-12-30T04:30:54.481044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:30:54.491847Z",
     "iopub.status.busy": "2025-12-30T04:30:54.491579Z",
     "iopub.status.idle": "2025-12-30T04:30:54.693818Z",
     "shell.execute_reply": "2025-12-30T04:30:54.693180Z"
    },
    "papermill": {
     "duration": 0.207134,
     "end_time": "2025-12-30T04:30:54.695172",
     "exception": false,
     "start_time": "2025-12-30T04:30:54.488038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "import re\n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:30:54.702430Z",
     "iopub.status.busy": "2025-12-30T04:30:54.702236Z",
     "iopub.status.idle": "2025-12-30T04:30:54.709983Z",
     "shell.execute_reply": "2025-12-30T04:30:54.709440Z"
    },
    "papermill": {
     "duration": 0.012381,
     "end_time": "2025-12-30T04:30:54.710958",
     "exception": false,
     "start_time": "2025-12-30T04:30:54.698577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt\n",
    "\n",
    "\n",
    "def clean_non_western_encoded_characters_commands(text: str) -> str:\n",
    "    \"\"\" Remove non-western encoded characters from a string\n",
    "    List may need to grow.\n",
    "    \n",
    "    :param text: the text to clean\n",
    "    :return: the cleaned text\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"(\\\\begin{CJK}{UTF8}{gbsn})(.*?)(\\\\end{CJK})\", r\"\\2\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_initials(name: str) -> str:\n",
    "    \"\"\" Get the short name, e.g., A.-B. FamName\n",
    "    :param name: full name\n",
    "    :returns: initials\n",
    "    \"\"\"\n",
    "    initials = []\n",
    "    # account for non western names often in ()\n",
    "    if '(' in name:\n",
    "        name = clean_non_western_encoded_characters_commands(name)\n",
    "        suffix = re.findall(r\"\\((.*?)\\)\", name)[0]\n",
    "        name = name.replace(f\"({suffix})\", '')\n",
    "    else:\n",
    "        suffix = ''\n",
    "    split = name.split()\n",
    "    for token in split[:-1]:\n",
    "        if '-' in token:\n",
    "            current = '-'.join([k[0] + '.' for k in token.split('-')])\n",
    "        else:\n",
    "            current = token[0] + '.'\n",
    "        initials.append(current)\n",
    "    initials.append(split[-1].strip())\n",
    "    if suffix:\n",
    "        initials.append(f\"({suffix})\")\n",
    "    return ' '.join(initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.002896,
     "end_time": "2025-12-30T04:30:54.716820",
     "exception": false,
     "start_time": "2025-12-30T04:30:54.713924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:30:54.723514Z",
     "iopub.status.busy": "2025-12-30T04:30:54.723290Z",
     "iopub.status.idle": "2025-12-30T04:31:16.927571Z",
     "shell.execute_reply": "2025-12-30T04:31:16.926955Z"
    },
    "papermill": {
     "duration": 22.209013,
     "end_time": "2025-12-30T04:31:16.928767",
     "exception": false,
     "start_time": "2025-12-30T04:30:54.719754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Z채hringer', 'Scheerer', 'Hoffmann', 'D체e',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'J채ger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:16.935828Z",
     "iopub.status.busy": "2025-12-30T04:31:16.935616Z",
     "iopub.status.idle": "2025-12-30T04:31:17.508170Z",
     "shell.execute_reply": "2025-12-30T04:31:17.507454Z"
    },
    "papermill": {
     "duration": 0.577174,
     "end_time": "2025-12-30T04:31:17.509251",
     "exception": false,
     "start_time": "2025-12-30T04:31:16.932077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "S. Shahaf  ->  S. Shahaf  |  ['S. Shahaf']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "Z. Fu  ->  Z. Fu  |  ['Z. Fu']\n",
      "Arxiv has 55 new papers today\n",
      "          4 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "def robust_call(fn, value, *args, **kwargs):\n",
    "    try:\n",
    "        return fn(value, *args, **kwargs)\n",
    "    except Exception:\n",
    "        return value\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [robust_call(mpia.get_initials, k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.003033,
     "end_time": "2025-12-30T04:31:17.515850",
     "exception": false,
     "start_time": "2025-12-30T04:31:17.512817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:17.522846Z",
     "iopub.status.busy": "2025-12-30T04:31:17.522611Z",
     "iopub.status.idle": "2025-12-30T04:31:23.726535Z",
     "shell.execute_reply": "2025-12-30T04:31:23.725795Z"
    },
    "papermill": {
     "duration": 6.208723,
     "end_time": "2025-12-30T04:31:23.727646",
     "exception": false,
     "start_time": "2025-12-30T04:31:17.518923",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cf07458c9f4643956899459794d2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2512.22963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2512.22963... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2512.23040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2512.23040..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues with the citations\n",
      "plugin pybtex.database.input.suffixes for suffix .tex not found\n",
      "Retrieving document from  https://arxiv.org/e-print/2512.23060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2512.23060... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2512.23378\n",
      "extracting tarball to tmp_2512.23378... done.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(\"Issues with the citations\")\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.003552,
     "end_time": "2025-12-30T04:31:23.735268",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.731716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.743938Z",
     "iopub.status.busy": "2025-12-30T04:31:23.743668Z",
     "iopub.status.idle": "2025-12-30T04:31:23.757809Z",
     "shell.execute_reply": "2025-12-30T04:31:23.757141Z"
    },
    "papermill": {
     "duration": 0.020138,
     "end_time": "2025-12-30T04:31:23.758875",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.738737",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.23040-b31b1b.svg)](https://arxiv.org/abs/2512.23040) | **A Linearized Approach to Radial-Velocity Extraction. II: Shot-Noise-Limited Precision via Spectral Factorization**  |\n",
       "|| <mark>S. Shahaf</mark>, B. Zackay |\n",
       "|*Appeared on*| *2025-12-30*|\n",
       "|*Comments*| *Submitted for publication in MNRAS*|\n",
       "|**Abstract**|            We generalize the short-time Fourier transform (STFT) formalism for radial velocity extraction to cases where the underlying spectral components are unknown. The method factorizes a spectroscopic time series into principal spectra and time-dependent kernels, enabling simultaneous recovery of both. In Fourier space, each inverse-wavelength slice is decomposed by singular value decomposition, and radial velocity shifts are inferred from phase differences between epochs. In the high-SNR regime, this provides a linearized and statistically tractable estimate of differential velocities. The method is validated on synthetic and SOAP simulations and applied to EXPRES observations of HD 34411 and $\\tau$ Ceti, recovering coherent signals and reaching the instrumental precision limit of ~30 cm/s. Apart from p-mode modulation, the residuals show no significant long-term correlations and allow the detection of signals with semi-amplitudes down to ~50 cm/s with $\\lesssim10$ cm/s uncertainty. The framework thus enables extreme-precision radial velocity measurements in the presence of spectral variability, representing a step toward detecting and characterizing Earth-like planets around solar-type stars.         |"
      ],
      "text/plain": [
       "[2512.23040] A Linearized Approach to Radial-Velocity Extraction. II: Shot-Noise-Limited Precision via Spectral Factorization\n",
       "\t<mark>S. Shahaf</mark>, B. Zackay"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.22963-b31b1b.svg)](https://arxiv.org/abs/2512.22963) | **Impacts of the $^{16}$O($^{16}$O, n)$^{31}$S reaction rate on the evolution and nucleosynthesis in Pop III massive stars**  |\n",
       "|| W. Xin, K. Nomoto, <mark>X. Zhang</mark>, S. Bi |\n",
       "|*Appeared on*| *2025-12-30*|\n",
       "|*Comments*| **|\n",
       "|**Abstract**|            We first present a systematic investigation into the effect of the $^{16}$O($^{16}$O, n)$^{31}$S reaction rate on the evolution and nucleosynthesis of Population III (Pop III) stars. We simulate the evolution of a 15 M$_\\odot$ Pop III star from the zero-age main sequence through to core collapse, while varying the $^{16}$O($^{16}$O, n)$^{31}$S reaction rate by factors of 0.1, 1, and 10. Our results demonstrate that increasing this reaction rate prompts earlier onset and extended duration of core oxygen burning at lower temperatures and densities. A higher reaction rate also increases neutron excess in OSi-rich layers, thereby promoting the synthesis of neutron-rich isotopes, particularly $^{31}$P and $^{39}$K. Most notably, the K yield is enhanced by a factor of 6.4. For a tenfold enhancement of the $^{16}$O($^{16}$O, n)$^{31}$S rate, the predicted [K/Ca] and [K/Fe] values from presupernova models reach 0.29 and 0.22 dex, respectively-values that are consistent with the most recent observational data for extremely metal-poor stars. These findings hold promise as a potential new solution to the problem of potassium underproduction and offer a valuable theoretical reference and motivation for subsequent measurements of oxygen fusion reaction rate.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.23060-b31b1b.svg)](https://arxiv.org/abs/2512.23060) | **Finding Quasars behind the Galactic Plane. IV. Candidate Selection from Chandra with Random Forest**  |\n",
       "|| <mark>X. Zhang</mark>, et al. |\n",
       "|*Appeared on*| *2025-12-30*|\n",
       "|*Comments*| *ApJ, submitted*|\n",
       "|**Abstract**|            Quasar samples remain severely incomplete at low Galactic latitudes because of strong extinction and source confusion. We conduct a systematic search for quasars behind the Galactic plane using X-ray sources from the Chandra Source Catalog (CSC 2.1), combined with optical data from Gaia DR3 and mid-infrared data from CatWISE2020. Using spectroscopically confirmed quasars and stars from data sets including DESI, SDSS, and LAMOST, we apply a Random Forest classifier to identify quasar candidates, with stellar contaminants suppressed using Gaia proper-motion constraints. Photometric redshifts are estimated for the candidates using a Random Forest regression model. Applying this framework to previously unclassified CSC sources, we identify 6286 quasar candidates, including 863 Galactic Plane Quasar (GPQ) candidates at |b|<20째, of which 514 are high-confidence candidates. Relative to the previously known GPQ sample, our selected GPQs reach fainter optical and X-ray fluxes, improving sensitivity to low-flux GPQs. In addition, both the GPQ candidates and known GPQs display harder X-ray spectra than the all-sky quasar sample, consistent with increased absorption through the Galactic plane. Pilot spectroscopy confirms two high-confidence GPQ candidates as quasars at spectroscopic redshifts of z=1.2582 and z=1.1313, and further spectroscopic follow-up of the GPQ sample is underway. This work substantially improves the census of GPQs and provides a valuable target sample for future spectroscopic follow-up, enabling the use of GPQs to refine the reference frames for astrometry and probe the Milky Way interstellar and circumgalactic media with the absorption features of GPQs.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2512.23378-b31b1b.svg)](https://arxiv.org/abs/2512.23378) | **Predicting the detection yields of giant planets and brown dwarfs with CSST astrometry**  |\n",
       "|| Y. Xuan, et al. -- incl., <mark>Z. Fu</mark> |\n",
       "|*Appeared on*| *2025-12-30*|\n",
       "|*Comments*| *18 pages, 8 figures, 2 tables; accepted for publication in the Astronomical Journal*|\n",
       "|**Abstract**|            Chinese Space Station Telescope (CSST), which will begin its scientific operations around 2027, is going to survey the sky area of the median-to-high Galactic latitude and median-to-high ecliptic latitude. The high astrometric precision of the CSST Survey Camera for faint objects enables the detection of a number of giant planets and brown dwarfs around M-dwarfs and brown dwarfs via differential astrometry in its optical survey. In this paper, we predict the number of giant planets and brown dwarfs around stars and brown dwarfs detectable with CSST astrometry. We generate synthetic samples of CSST stellar and substellar sources, and carry out companion injection-recovery simulations in the samples using different occurrence rates for FGK-dwarfs, M-dwarfs, and brown dwarfs. We calculate companion yields based on CSST astrometric precision. Our analysis reveals that over its 10-year mission, the CSST Survey Camera could barely discover giant planets and low-mass BDs around FGK-dwarfs, but is projected to detect 20 - 170 giant planets and low-mass brown dwarfs around M-dwarfs within 300 pc, and 300 - 570 brown dwarf binaries within 600 pc. Therefore, CSST astrometry is likely to significantly increase the current sample of substellar companions around M-dwarfs and brown dwarfs. This sample will deepen our understanding of planet formation and evolution around low-mass stars and brown dwarfs.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.004003,
     "end_time": "2025-12-30T04:31:23.766987",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.762984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.775867Z",
     "iopub.status.busy": "2025-12-30T04:31:23.775610Z",
     "iopub.status.idle": "2025-12-30T04:31:23.782330Z",
     "shell.execute_reply": "2025-12-30T04:31:23.781683Z"
    },
    "papermill": {
     "duration": 0.012296,
     "end_time": "2025-12-30T04:31:23.783333",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.771037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.792366Z",
     "iopub.status.busy": "2025-12-30T04:31:23.792181Z",
     "iopub.status.idle": "2025-12-30T04:31:23.799943Z",
     "shell.execute_reply": "2025-12-30T04:31:23.799416Z"
    },
    "papermill": {
     "duration": 0.013427,
     "end_time": "2025-12-30T04:31:23.800914",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.787487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found figures ['tmp_2512.23040/./sv_phase_vs_zeta.png', 'tmp_2512.23040/./RV_extraction_SOAP.png', 'tmp_2512.23040/./U0_white_noise.png']\n",
      "copying  tmp_2512.23040/./sv_phase_vs_zeta.png to _build/html/\n",
      "copying  tmp_2512.23040/./RV_extraction_SOAP.png to _build/html/\n",
      "copying  tmp_2512.23040/./U0_white_noise.png to _build/html/\n",
      "exported in  _build/html/2512.23040.md\n",
      "    + _build/html/tmp_2512.23040/./sv_phase_vs_zeta.png\n",
      "    + _build/html/tmp_2512.23040/./RV_extraction_SOAP.png\n",
      "    + _build/html/tmp_2512.23040/./U0_white_noise.png\n"
     ]
    }
   ],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.004215,
     "end_time": "2025-12-30T04:31:23.809332",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.805117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.818393Z",
     "iopub.status.busy": "2025-12-30T04:31:23.818164Z",
     "iopub.status.idle": "2025-12-30T04:31:23.822336Z",
     "shell.execute_reply": "2025-12-30T04:31:23.821833Z"
    },
    "papermill": {
     "duration": 0.009848,
     "end_time": "2025-12-30T04:31:23.823324",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.813476",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\barak}[1]{{\\color{blue} #1}}$\n",
       "$\\newcommand{\\sahar}[1]{{\\color{magenta} #1}}$\n",
       "$\\newcommand{\\thebibliography}{\\DeclareRobustCommand{\\VAN}[3]{##3}\\VANthebibliography}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# A Linearized Approach to Radial-Velocity Extraction. II: Shot-Noise-Limited Precision via Spectral Factorization\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2512.23040-b31b1b.svg)](https://arxiv.org/abs/2512.23040)<mark>Appeared on: 2025-12-30</mark> -  _Submitted for publication in MNRAS_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "<mark>S. Shahaf</mark>, B. Zackay\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** We generalize the short-time Fourier transform (STFT) formalism for radial velocity extraction to cases where the underlying spectral components are unknown. The method factorizes a spectroscopic time series into principal spectra and time-dependent kernels, enabling simultaneous recovery of both. In Fourier space, each inverse-wavelength slice is decomposed by singular value decomposition, and radial velocity shifts are inferred from phase differences between epochs. In the high-SNR regime, this provides a linearized and statistically tractable estimate of differential velocities. The method is validated on synthetic and SOAP simulations and applied to EXPRES observations of HD 34411 and $\\tau$ Ceti, recovering coherent signals and reaching the instrumental precision limit of ${\\sim}30$ cm s \\textsuperscript{-1} . Apart from p-mode modulation, the residuals show no significant long-term correlations and allow the detection of signals with semi-amplitudes down to ${\\sim}50$ cm s \\textsuperscript{-1} with $\\lesssim10$ cm s \\textsuperscript{-1} uncertainty. The framework thus enables extreme-precision radial velocity measurements in the presence of spectral variability, representing a step toward detecting and characterizing Earth-like planets around solar-type stars.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2512.23040/./sv_phase_vs_zeta.png\" alt=\"Fig1\" width=\"100%\"/>\n",
       "\n",
       "**Figure 1. -** _Top panel_---the normalized information in the first three principal spectra (corresponding to $\\Sigma_{00}$, $\\Sigma_{11}$ and $\\Sigma_{22}$) versus their corresponding inverse-wavelength, $\\zeta$, for the simulated white-noise spectroscopic time-series. All values are normalized to $\\Sigma_{00}$ at $\\zeta=0$.  _Bottom panel_---relative phases between the first and fourth simulated spectra, shown as a solid black line. The red stripes correspond to the expected relative phase due to the velocity difference between the two observations, i.e., $2\\pi \\zeta \\times (v_4-v_1)$. Notably, the relative phase follows the expected trend for inverse wavelength below $\\sim 0.2$ s km\\textsuperscript{-1}, where the information content falls below the noise level. (*fig: singular values vs zeta*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2512.23040/./RV_extraction_SOAP.png\" alt=\"Fig9\" width=\"100%\"/>\n",
       "\n",
       "**Figure 9. -** _Top panels_---The rectified velocities, $v_{\\rm c}$, extracted for the SOAP simulation described in Section \\ref{sec: SOAP}. The simulated spectroscopic dataset is based on a synthetic spectrum of a Sun-like star, and the noise is assumed to be white and Gaussian. The injected radial velocity signal is a solid red curve.\n",
       "        _Middle panels_---the extracted velocities from the zeroth-order kernel, $U^{(0)}$. These velocities show a combination of the injected Doppler shift and parasitic signal induced by stellar activity.\n",
       "        _Bottom panels_---the extracted velocities from the first-order kernel, $U^{(1)}$, dominated by stellar activity. The solid red curve represents the fitted 5-harmonic model fitted to the extracted velocities (see text). (*fig: RV extraction soap*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2512.23040/./U0_white_noise.png\" alt=\"Fig8\" width=\"100%\"/>\n",
       "\n",
       "**Figure 8. -** _Top panel_---a selected segment from one of the simulated spectra used in Section \\ref{sec: phase ratios}, centered around the MgB lines ($T_{\\rm eff}=5{,}800   {\\rm K}$; $\\log g = 4.5$; ${\\rm[Fe/H]}=0$; $v \\sin i = 2  {\\rm km  s}^{-1}$; and $\\mathcal{R}=10^5$). _Bottom left panel_---the zeroth-order estimated of the principal kernels obtained from $\\mathbf{U}_\\zeta$, for the first seven spectra. The kernels are normalized such that their peak value is one and sorted one on top of the other. The arrows represent the Doppler shift used for each spectrum.\n",
       "        _Bottom right panel_---same as the bottom-left panel, but using the reweighted matrices $\\mathbf{U}_\\zeta \\Sigma_\\zeta$. (*fig: U0 SVD*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2512.23040\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.004549,
     "end_time": "2025-12-30T04:31:23.832291",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.827742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.842043Z",
     "iopub.status.busy": "2025-12-30T04:31:23.841816Z",
     "iopub.status.idle": "2025-12-30T04:31:23.848573Z",
     "shell.execute_reply": "2025-12-30T04:31:23.848039Z"
    },
    "papermill": {
     "duration": 0.01269,
     "end_time": "2025-12-30T04:31:23.849535",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.836845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.859083Z",
     "iopub.status.busy": "2025-12-30T04:31:23.858904Z",
     "iopub.status.idle": "2025-12-30T04:31:23.870300Z",
     "shell.execute_reply": "2025-12-30T04:31:23.869705Z"
    },
    "papermill": {
     "duration": 0.017335,
     "end_time": "2025-12-30T04:31:23.871340",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.854005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.881226Z",
     "iopub.status.busy": "2025-12-30T04:31:23.881042Z",
     "iopub.status.idle": "2025-12-30T04:31:23.885476Z",
     "shell.execute_reply": "2025-12-30T04:31:23.884962Z"
    },
    "papermill": {
     "duration": 0.010589,
     "end_time": "2025-12-30T04:31:23.886478",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.875889",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.896363Z",
     "iopub.status.busy": "2025-12-30T04:31:23.896141Z",
     "iopub.status.idle": "2025-12-30T04:31:23.900840Z",
     "shell.execute_reply": "2025-12-30T04:31:23.900300Z"
    },
    "papermill": {
     "duration": 0.010761,
     "end_time": "2025-12-30T04:31:23.901800",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.891039",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.911569Z",
     "iopub.status.busy": "2025-12-30T04:31:23.911369Z",
     "iopub.status.idle": "2025-12-30T04:31:23.917149Z",
     "shell.execute_reply": "2025-12-30T04:31:23.916615Z"
    },
    "papermill": {
     "duration": 0.011784,
     "end_time": "2025-12-30T04:31:23.918114",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.906330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T04:31:23.928331Z",
     "iopub.status.busy": "2025-12-30T04:31:23.928113Z",
     "iopub.status.idle": "2025-12-30T04:31:23.934167Z",
     "shell.execute_reply": "2025-12-30T04:31:23.933617Z"
    },
    "papermill": {
     "duration": 0.01213,
     "end_time": "2025-12-30T04:31:23.935086",
     "exception": false,
     "start_time": "2025-12-30T04:31:23.922956",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.552129,
   "end_time": "2025-12-30T04:31:24.155363",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2025-12-30T04:30:53.603234",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2c6b2957543b417d9ba931d270257b28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "31b94ccf5bec434d9efda1f56396ec76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4f046d500ef8432b8a22835aebb934ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a4f5b2489374394812ab71e042cf3ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "99f0f52840ba4e78b08d62885b7d7664": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bbbe1d9c8e8a4e66a148f93296fd6176",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2c6b2957543b417d9ba931d270257b28",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     },
     "a8cf07458c9f4643956899459794d2c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c34f2ec5883c456eb3631c182599e1e7",
        "IPY_MODEL_99f0f52840ba4e78b08d62885b7d7664",
        "IPY_MODEL_e16b9108fbdd42afaa431a82f4ad15f2"
       ],
       "layout": "IPY_MODEL_31b94ccf5bec434d9efda1f56396ec76",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bbbe1d9c8e8a4e66a148f93296fd6176": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c34f2ec5883c456eb3631c182599e1e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d828977f028f4bc8b70fa14c6194a747",
       "placeholder": "",
       "style": "IPY_MODEL_e0f11adad8004bfcafea34d3c42eabfe",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "d828977f028f4bc8b70fa14c6194a747": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0f11adad8004bfcafea34d3c42eabfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e16b9108fbdd42afaa431a82f4ad15f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4f046d500ef8432b8a22835aebb934ed",
       "placeholder": "",
       "style": "IPY_MODEL_8a4f5b2489374394812ab71e042cf3ff",
       "tabbable": null,
       "tooltip": null,
       "value": "4/4[00:06&lt;00:00,1.22s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}