{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.003972,
     "end_time": "2024-11-18T04:11:22.208902",
     "exception": false,
     "start_time": "2024-11-18T04:11:22.204930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:11:22.216630Z",
     "iopub.status.busy": "2024-11-18T04:11:22.216084Z",
     "iopub.status.idle": "2024-11-18T04:11:22.651027Z",
     "shell.execute_reply": "2024-11-18T04:11:22.650295Z"
    },
    "papermill": {
     "duration": 0.440226,
     "end_time": "2024-11-18T04:11:22.652425",
     "exception": false,
     "start_time": "2024-11-18T04:11:22.212199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "import re\n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:11:22.659947Z",
     "iopub.status.busy": "2024-11-18T04:11:22.659417Z",
     "iopub.status.idle": "2024-11-18T04:11:22.667359Z",
     "shell.execute_reply": "2024-11-18T04:11:22.666859Z"
    },
    "papermill": {
     "duration": 0.012613,
     "end_time": "2024-11-18T04:11:22.668324",
     "exception": false,
     "start_time": "2024-11-18T04:11:22.655711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt\n",
    "\n",
    "\n",
    "def clean_non_western_encoded_characters_commands(text: str) -> str:\n",
    "    \"\"\" Remove non-western encoded characters from a string\n",
    "    List may need to grow.\n",
    "    \n",
    "    :param text: the text to clean\n",
    "    :return: the cleaned text\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"(\\\\begin{CJK}{UTF8}{gbsn})(.*?)(\\\\end{CJK})\", r\"\\2\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_initials(name: str) -> str:\n",
    "    \"\"\" Get the short name, e.g., A.-B. FamName\n",
    "    :param name: full name\n",
    "    :returns: initials\n",
    "    \"\"\"\n",
    "    initials = []\n",
    "    # account for non western names often in ()\n",
    "    if '(' in name:\n",
    "        name = clean_non_western_encoded_characters_commands(name)\n",
    "        suffix = re.findall(r\"\\((.*?)\\)\", name)[0]\n",
    "        name = name.replace(f\"({suffix})\", '')\n",
    "    else:\n",
    "        suffix = ''\n",
    "    split = name.split()\n",
    "    for token in split[:-1]:\n",
    "        if '-' in token:\n",
    "            current = '-'.join([k[0] + '.' for k in token.split('-')])\n",
    "        else:\n",
    "            current = token[0] + '.'\n",
    "        initials.append(current)\n",
    "    initials.append(split[-1].strip())\n",
    "    if suffix:\n",
    "        initials.append(f\"({suffix})\")\n",
    "    return ' '.join(initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.002951,
     "end_time": "2024-11-18T04:11:22.674348",
     "exception": false,
     "start_time": "2024-11-18T04:11:22.671397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:11:22.681376Z",
     "iopub.status.busy": "2024-11-18T04:11:22.680875Z",
     "iopub.status.idle": "2024-11-18T04:11:39.278865Z",
     "shell.execute_reply": "2024-11-18T04:11:39.278179Z"
    },
    "papermill": {
     "duration": 16.602837,
     "end_time": "2024-11-18T04:11:39.280133",
     "exception": false,
     "start_time": "2024-11-18T04:11:22.677296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Zähringer', 'Scheerer', 'Hoffmann', 'Düe',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'Jäger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:11:39.287732Z",
     "iopub.status.busy": "2024-11-18T04:11:39.287334Z",
     "iopub.status.idle": "2024-11-18T04:11:39.908575Z",
     "shell.execute_reply": "2024-11-18T04:11:39.907929Z"
    },
    "papermill": {
     "duration": 0.626162,
     "end_time": "2024-11-18T04:11:39.909643",
     "exception": false,
     "start_time": "2024-11-18T04:11:39.283481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K. Kreckel  ->  K. Kreckel  |  ['K. Kreckel']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "Zhang  ->  R. Zhang  |  ['Zhang']\n",
      "J. Liu  ->  J. Liu  |  ['J. Liu']\n",
      "K. El-Badry  ->  K. El-Badry  |  ['K. El-Badry']\n",
      "Arxiv has 49 new papers today\n",
      "          4 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "def robust_call(fn, value, *args, **kwargs):\n",
    "    try:\n",
    "        return fn(value, *args, **kwargs)\n",
    "    except Exception:\n",
    "        return value\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [robust_call(mpia.get_initials, k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.003144,
     "end_time": "2024-11-18T04:11:39.916257",
     "exception": false,
     "start_time": "2024-11-18T04:11:39.913113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:11:39.923442Z",
     "iopub.status.busy": "2024-11-18T04:11:39.923035Z",
     "iopub.status.idle": "2024-11-18T04:13:05.550586Z",
     "shell.execute_reply": "2024-11-18T04:13:05.549821Z"
    },
    "papermill": {
     "duration": 85.632353,
     "end_time": "2024-11-18T04:13:05.551743",
     "exception": false,
     "start_time": "2024-11-18T04:11:39.919390",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da640b42552b44e9bf05c55410645a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2411.09729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2411.09729..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Found documentclass in tmp_2411.09729/main.tex\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'authors' from 'tmp_2411.09729/authors.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K. Kreckel  ->  K. Kreckel  |  ['K. Kreckel']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 bibliographic references in tmp_2411.09729/main.bbl.\n",
      "Retrieving document from  https://arxiv.org/e-print/2411.09735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2411.09735..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2411.09753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2411.09753..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "  0: tmp_2411.09753/natnotes.tex, 332 lines\n",
      "  1: tmp_2411.09753/main.tex, 854 lines\n",
      "  2: tmp_2411.09753/natbib.tex, 96 lines\n",
      "  3: tmp_2411.09753/aassymbols.tex, 579 lines\n",
      "Retrieving document from  https://arxiv.org/e-print/2411.09905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Found 4 candidates with documentclass definition.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Assuming tmp_2411.09753/main.tex as main document.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2411.09905..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(\"Issues with the citations\")\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.00388,
     "end_time": "2024-11-18T04:13:05.559786",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.555906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.568465Z",
     "iopub.status.busy": "2024-11-18T04:13:05.568047Z",
     "iopub.status.idle": "2024-11-18T04:13:05.582663Z",
     "shell.execute_reply": "2024-11-18T04:13:05.582022Z"
    },
    "papermill": {
     "duration": 0.020093,
     "end_time": "2024-11-18T04:13:05.583722",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.563629",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2411.09729-b31b1b.svg)](https://arxiv.org/abs/2411.09729) | **The SDSS-V Local Volume Mapper (LVM): Data Analysis Pipeline**  |\n",
       "|| S. F. Sanchez, et al. -- incl., <mark>K. Kreckel</mark> |\n",
       "|*Appeared on*| *2024-11-18*|\n",
       "|*Comments*| *35 pages, 17 figures, 8 tables, accepted for publication in AJ*|\n",
       "|**Abstract**|            We introduce the Data Analysis Pipeline (DAP) for the Sloan Digital Sky Survey V (SDSS-V) Local Volume Mapper (LVM) project, referred to as the LVM-DAP. We outline our methods for recovering both stellar and emission line components from the optical integral field spectroscopy, highlighting the developments and changes implemented to address specific challenges of the data set. The observations from the LVM project are unique because they cover a wide range of physical resolutions, from approximately 0.05 pc to 100 pc, depending on the distance to the targets. This, along with the varying number of stars sampled in each aperture (ranging from zero, just one of a few, to thousands), presents challenges in using previous spectral synthesis methods and interpreting the spectral fits. We provide a detailed explanation of how we model the stellar content and separate it from the ionized gas emission lines. To assess the accuracy of our results, we compare them with both idealized and more realistic simulations, highlighting the limitations of our methods. We find that the DAP robustly correct for stellar continuum features and recover emission line parameters (e.g. flux, equivalent width, systemtic velocity and velocity dispersion) with a precision and accuracy that fulfill the requirements of the primary goal of the analysis. In addition, the recovered stellar parameters are reliable for single stars, the recovery of integrated populations is less precise. We conclude with a description of the data products we provide, instructions for downloading and using our software, and a showcase illustrating the quality of the data and the analysis on a deep exposure taken on the Huygens region at the center of the Orion Nebula.         |"
      ],
      "text/plain": [
       "[2411.09729] The SDSS-V Local Volume Mapper (LVM): Data Analysis Pipeline\n",
       "\tS. F. Sanchez, et al. -- incl., <mark>K. Kreckel</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2411.09735-b31b1b.svg)](https://arxiv.org/abs/2411.09735) | **Gas thermodynamics meets galaxy kinematics: Joint mass measurements for eROSITA galaxy clusters**  |\n",
       "|| P. Li, et al. -- incl., <mark>X. Zhang</mark> |\n",
       "|*Appeared on*| *2024-11-18*|\n",
       "|*Comments*| *14 pages, 9 figures, 2 tables, with 12-page appendix for additional figures and tables. Accepted for publication in A&A*|\n",
       "|**Abstract**|            The mass of galaxy clusters is a critical quantity for probing cluster cosmology and testing theories of gravity, but its measurement could be biased given assumptions are inevitable. In this paper, we employ and compare two mass proxies for galaxy clusters: thermodynamics of the intracluster medium and kinematics of member galaxies. We select 22 galaxy clusters from the cluster catalog in the first SRG/eROSITA All-Sky Survey (eRASS1) that have sufficient optical and near-infrared observations. We generate multi-band images in the energy range of (0.3, 7) keV for each cluster, and derive their temperature profiles, gas mass profiles and hydrostatic mass profiles using a parametric approach that does not assume dark matter halo models. With spectroscopically confirmed member galaxies collected from multiple surveys, we numerically solve the spherical Jeans equation for their dynamical mass profiles. Our results quantify the correlation between dynamical mass and line-of-sight velocity dispersion with an rms scatter of 0.14 dex. We find the two mass proxies lead to roughly the same total mass, with no observed systematic bias. As such, the $\\sigma_8$ tension is not specific to hydrostatic mass or weak lensing shears, but also appears with galaxy kinematics. We also compare our hydrostatic masses with the latest weak lensing masses inferred with scaling relations. The comparison shows the weak lensing mass is significantly higher than our hydrostatic mass by $\\sim$110%. This might explain the significantly larger value of $\\sigma_8$ from the latest measurement using eRASS1 clusters than almost all previous estimates in the literature. Finally, we test the radial acceleration relation (RAR) established in disk galaxies. We confirm the missing baryon problem in the inner region of galaxy clusters using three independent mass proxies for the first time.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2411.09753-b31b1b.svg)](https://arxiv.org/abs/2411.09753) | **The democratic detrender: Ensemble-Based Removal of the Nuisance Signal in Stellar Time-Series Photometry**  |\n",
       "|| D. A. Yahalomi, et al. -- incl., <mark>Zhang</mark>, <mark>J. Liu</mark> |\n",
       "|*Appeared on*| *2024-11-18*|\n",
       "|*Comments*| *15 pages, 10 figures, submitted to ApJS. For source code, documentation, and tutorials, see this https URL*|\n",
       "|**Abstract**|            Accurate, precise, and computationally efficient removal of unwanted activity that exists as a combination of periodic, quasi-periodic, and non-periodic systematic trends in time-series photometric data is a critical step in exoplanet transit analysis. Throughout the years, many different modeling methods have been used for this process, often called \"detrending.\" However, there is no community-wide consensus regarding the favored approach. In order to mitigate model dependency, we present an ensemble-based approach to detrending via community-of-models and the $\\texttt{democratic detrender}$: a modular and scalable open-source coding package that implements ensemble detrending. The $\\texttt{democratic detrender}$ allows users to select from a number of packaged detrending methods (including cosine filtering, Gaussian processes, and polynomial fits) or provide their own set of detrended light curves via methods of their choosing. The $\\texttt{democratic detrender}$ then combines the resulting individually detrended light curves into a single method marginalized (via median selection) light curve. Additionally, the $\\texttt{democratic detrender}$ inflates the uncertainties of each time-series data point using information from the median absolute deviation between the individually detrended light curve, propagating information into the final detrended light curve about the added uncertainty due to the correctness of the underlying models.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2411.09905-b31b1b.svg)](https://arxiv.org/abs/2411.09905) | **Eccentricities of Close Stellar Binaries**  |\n",
       "|| Y. Wu, et al. -- incl., <mark>K. El-Badry</mark> |\n",
       "|*Appeared on*| *2024-11-18*|\n",
       "|*Comments*| *6 pages + 7 appendixes; submitted to ApJ Letters*|\n",
       "|**Abstract**|            Orbits of stellar binaries are in general eccentric. This encodes information about the formation process. Here, we use thousands of main-sequence binaries from the GAIA DR3 catalog to reveal that, binaries inwards of a few AU exhibit a simple Rayleigh distribution with a mode $\\sigma_e \\simeq 0.30$. We find the same distribution for binaries from M to A spectral types, and from tens of days to $10^3$days (possibly extending to tens of AU). This observed distribution is most likely primordial. Its Rayleigh form suggests an origin in weak scattering, while its invariant mode demands a universal process. We experiment with exciting binary eccentricities by ejecting brown dwarfs, and find that the eccentricities reach an equi-partition value of $\\sigma_e \\simeq \\sqrt{M_{\\rm bd}/M_*}$. So to explain the observed mode, these brown dwarfs will have to be of order one tenth the stellar masses, and be at least as abundant in the Galaxy as the close binaries. The veracity of such a proposal remains to be tested.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.004467,
     "end_time": "2024-11-18T04:13:05.592703",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.588236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.602487Z",
     "iopub.status.busy": "2024-11-18T04:13:05.602105Z",
     "iopub.status.idle": "2024-11-18T04:13:05.608816Z",
     "shell.execute_reply": "2024-11-18T04:13:05.608247Z"
    },
    "papermill": {
     "duration": 0.012765,
     "end_time": "2024-11-18T04:13:05.609857",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.597092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.619843Z",
     "iopub.status.busy": "2024-11-18T04:13:05.619431Z",
     "iopub.status.idle": "2024-11-18T04:13:05.628279Z",
     "shell.execute_reply": "2024-11-18T04:13:05.627772Z"
    },
    "papermill": {
     "duration": 0.014829,
     "end_time": "2024-11-18T04:13:05.629209",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.614380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found figures ['tmp_2411.09729/./figures/m_sel-ORION.png', 'tmp_2411.09729/./figures/Scene2_sim_in.png', 'tmp_2411.09729/./figures/Scene2_sim_out.png', 'tmp_2411.09729/./figures/m_fit_Scene1.png', 'tmp_2411.09729/./figures/Rosetta_sim_in.png', 'tmp_2411.09729/./figures/Rosetta_sim_out.png', 'tmp_2411.09729/./figures/m_fit_00006109_cl_SN1_342_5_5_20.0.png']\n",
      "copying  tmp_2411.09729/./figures/m_sel-ORION.png to _build/html/\n",
      "copying  tmp_2411.09729/./figures/Scene2_sim_in.png to _build/html/\n",
      "copying  tmp_2411.09729/./figures/Scene2_sim_out.png to _build/html/\n",
      "copying  tmp_2411.09729/./figures/m_fit_Scene1.png to _build/html/\n",
      "copying  tmp_2411.09729/./figures/Rosetta_sim_in.png to _build/html/\n",
      "copying  tmp_2411.09729/./figures/Rosetta_sim_out.png to _build/html/\n",
      "copying  tmp_2411.09729/./figures/m_fit_00006109_cl_SN1_342_5_5_20.0.png to _build/html/\n",
      "exported in  _build/html/2411.09729.md\n",
      "    + _build/html/tmp_2411.09729/./figures/m_sel-ORION.png\n",
      "    + _build/html/tmp_2411.09729/./figures/Scene2_sim_in.png\n",
      "    + _build/html/tmp_2411.09729/./figures/Scene2_sim_out.png\n",
      "    + _build/html/tmp_2411.09729/./figures/m_fit_Scene1.png\n",
      "    + _build/html/tmp_2411.09729/./figures/Rosetta_sim_in.png\n",
      "    + _build/html/tmp_2411.09729/./figures/Rosetta_sim_out.png\n",
      "    + _build/html/tmp_2411.09729/./figures/m_fit_00006109_cl_SN1_342_5_5_20.0.png\n"
     ]
    }
   ],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.00447,
     "end_time": "2024-11-18T04:13:05.638355",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.633885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.648136Z",
     "iopub.status.busy": "2024-11-18T04:13:05.647782Z",
     "iopub.status.idle": "2024-11-18T04:13:05.652501Z",
     "shell.execute_reply": "2024-11-18T04:13:05.651857Z"
    },
    "papermill": {
     "duration": 0.010733,
     "end_time": "2024-11-18T04:13:05.653576",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.642843",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\lam}{\\lambda}$\n",
       "$\\newcommand{\\hi}{\\ION{H}{i}}$\n",
       "$\\newcommand{\\hii}{\\ION{H}{ii}}$\n",
       "$\\newcommand{\\hh}{\\ION{H}{ii}~}$\n",
       "$\\newcommand{\\hei}{\\ION{He}{i}}$\n",
       "$\\newcommand{\\heii}{\\ION{He}{ii}}$\n",
       "$\\newcommand{\\nii}{[\\ION{N}{ii}]}$\n",
       "$\\newcommand{\\oi}{[\\ION{O}{i}]}$\n",
       "$\\newcommand{\\oii}{[\\ION{O}{ii}]}$\n",
       "$\\newcommand{\\oiii}{[\\ION{O}{iii}]}$\n",
       "$\\newcommand{\\sii}{[\\ION{S}{ii}]}$\n",
       "$\\newcommand{\\siii}{[\\ION{S}{iii}]}$\n",
       "$\\newcommand{\\caii}{[\\ION{Ca}{ii}]}$\n",
       "$\\newcommand{\\feii}{[\\ION{Fe}{ii}]}$\n",
       "$\\newcommand{\\ariii}{[\\ION{Ar}{iii}]}$\n",
       "$\\newcommand{\\neiii}{[\\ION{Ne}{iii}]}$\n",
       "$\\newcommand{\\eduardo}[1]{\\textbf{\\textcolor{blue}{Eduardo: {#1}}}}$\n",
       "$\\newcommand{\\ha}{\\rm{H}\\alpha}$\n",
       "$\\newcommand{\\hb}{\\rm{H}\\beta}$\n",
       "$\\newcommand{\\hd}{\\rm{H}\\delta}$\n",
       "$\\newcommand{\\hg}{\\rm{H}\\gamma}$\n",
       "$\\newcommand{\\he}{\\rm{H}\\epsilon}$\n",
       "$\\newcommand{\\mHa}{\\rm{H}\\alpha}$\n",
       "$\\newcommand{\\Ha}{\\rm{H}\\alpha}$\n",
       "$\\newcommand{\\Hb}{\\rm{H}\\beta}$\n",
       "$\\newcommand{\\logU}{\\log(\\bar U)}$\n",
       "$\\newcommand{\\Kdist}{K_{dist}}$\n",
       "$\\newcommand{\\EWa}{EW(\\Ha)}$\n",
       "$\\newcommand{\\fOB}{f(OB)}$\n",
       "$\\newcommand{\\QHHe}{Q_{0/1}}$\n",
       "$\\newcommand{\\Com}[1]{{\\color{red}*** #1}}$\n",
       "$\\newcommand{\\Te}{T_{\\rm e}}$\n",
       "$\\newcommand{\\Ssfr}{\\Sigma_{\\rm SFR} }$\n",
       "$\\newcommand{\\Sst}{\\Sigma_{\\rm *} }$\n",
       "$\\newcommand{\\Sgas}{\\Sigma_{\\rm mol} }$\n",
       "$\\newcommand{\\Srgas}{\\Sigma_{\\rm gas} }$\n",
       "$\\newcommand{\\eSsfr}{\\Sigma_{\\rm SFR}}$\n",
       "$\\newcommand{\\eSst}{\\Sigma_{\\rm *}}$\n",
       "$\\newcommand{\\eSgas}{\\Sigma_{\\rm mol}}$\n",
       "$\\newcommand{\\Rsfr}{\\rho_{\\rm SFR} }$\n",
       "$\\newcommand{\\Rst}{\\rho_{\\rm *} }$\n",
       "$\\newcommand{\\Rgas}{\\rho_{\\rm gas} }$\n",
       "$\\newcommand{\\alf}{[\\alpha/Fe]}$\n",
       "$\\newcommand{\\oz}{[O/Fe]}$\n",
       "$\\newcommand{\\fe}{[Fe/H]}$\n",
       "$\\newcommand{\\age}{\\mathcal{A}_{\\star,L}}$\n",
       "$\\newcommand{\\met}{\\mathcal{Z}_{\\star,L}}$\n",
       "$\\newcommand{\\kms}{km s^{-1}}$\n",
       "$\\newcommand{\\flux}{erg s^{-1} cm^{-2}}$\n",
       "$\\newcommand{\\edr}{Sánchez et al. (submitted)}$\n",
       "$\\newcommand{\\edrp}{(Sánchez et al., submitted)}$\n",
       "$\\newcommand{\\vdag}{(v)^\\dagger}$\n",
       "$\\newcommand$\n",
       "$\\newcommand$\n",
       "$\\newcommand{\\OSU}{\\label{OSU} Department of Astronomy, The Ohio State University, 140 West 18th Avenue, Columbus, Ohio 43210, USA}$\n",
       "$\\newcommand{\\Alberta}{\\label{Alberta} Department of Physics, University of Alberta, Edmonton, AB T6G 2E1, Canada}$\n",
       "$\\newcommand{\\ANU}{\\label{ANU} Research School of Astronomy and Astrophysics, Australian National University, Canberra, ACT 2611, Australia}$\n",
       "$\\newcommand{\\IPAC}{\\label{IPAC} Caltech-IPAC, 1200 E. California Blvd. Pasadena, CA 91125, USA}$\n",
       "$\\newcommand{\\Carnegie}{\\label{Carnegie} Observatories of the Carnegie Institution for Science, 813 Santa Barbara Street, Pasadena, CA 91101, USA}$\n",
       "$\\newcommand{ÇAPP}{\\label{CCAPP} Center for Cosmology and Astroparticle Physics, 191 West Woodruff Avenue, Columbus, OH 43210, USA}$\n",
       "$\\newcommand{\\CfA}{\\label{CfA}Harvard-Smithsonian Center for Astrophysics, 60 Garden Street, Cambridge, MA 02138, USA}$\n",
       "$\\newcommand{\\CITEVA}{\\label{CITEVA} Centro de Astronomía (CITEVA), Universidad de Antofagasta, Avenida Angamos 601, Antofagasta, Chile}$\n",
       "$\\newcommand{\\CNRS}{\\label{CNRS} CNRS, IRAP, 9 Av. du Colonel Roche, BP 44346, F-31028 Toulouse cedex 4, France}$\n",
       "$\\newcommand{\\ESO}{\\label{ESO} European Southern Observatory, Karl-Schwarzschild Stra{\\ss}e 2, D-85748 Garching bei München, Germany}$\n",
       "$\\newcommand{\\ESOChile}{\\label{ESOChile} European Southern Observatory, Avenida Alonso de Cordoba 3107, Casilla 19, Santiago 19001, Chile}$\n",
       "$\\newcommand{\\HD}{\\label{HD} Astronomisches Rechen-Institut, Zentrum für Astronomie der Universität Heidelberg, Mönchhofstra\\ss e 12-14, D-69120 Heidelberg, Germany}$\n",
       "$\\newcommand{\\ICRAR}{\\label{ICRAR} International Centre for Radio Astronomy Research, University of Western Australia, 35 Stirling Highway, Crawley, WA 6009, Australia}$\n",
       "$\\newcommand{\\IRAM}{\\label{IRAM} Institut de Radioastronomie Millimétrique (IRAM), 300 Rue de la Piscine, F-38406 Saint Martin d'Hères, France}$\n",
       "$\\newcommand{\\ITA}{\\label{ITA} Universität Heidelberg, Zentrum für Astronomie, Institut für Theoretische Astrophysik, Albert-Ueberle-Str 2, D-69120 Heidelberg, Germany}$\n",
       "$\\newcommand{\\IWR}{\\label{IWR} Universität Heidelberg, Interdisziplinäres Zentrum für Wissenschaftliches Rechnen, Im Neuenheimer Feld 205, D-69120 Heidelberg, Germany}$\n",
       "$\\newcommand{\\JHU}{\\label{JHU} Department of Physics and Astronomy, The Johns Hopkins University, Baltimore, MD 21218, USA}$\n",
       "$\\newcommand{\\Leiden}{\\label{Leiden} Leiden Observatory, Leiden University, P.O. Box 9513, 2300 RA Leiden, The Netherlands}$\n",
       "$\\newcommand{\\Maryland}{\\label{Maryland} Department of Astronomy, University of Maryland, College Park, MD 20742, USA}$\n",
       "$\\newcommand{\\MPE}{\\label{MPE} Max-Planck-Institut für extraterrestrische Physik, Giessenbachstra{\\ss}e 1, D-85748 Garching, Germany}$\n",
       "$\\newcommand{\\MPIA}{\\label{MPIA} Max-Planck-Institut für Astronomie, Königstuhl 17, D-69117, Heidelberg, Germany}$\n",
       "$\\newcommand{\\Nagoya}{\\label{Nagoya} Department of Physics, Nagoya University, Furo-cho, Chikusa-ku, Nagoya, Aichi 464-8602, Japan}$\n",
       "$\\newcommand{\\NRAO}{\\label{NRAO} National Radio Astronomy Observatory, 520 Edgemont Road, Charlottesville, VA 22903-2475, USA}$\n",
       "$\\newcommand{\\OAN}{\\label{OAN} Observatorio Astronómico Nacional (IGN), C/Alfonso XII, 3, E-28014 Madrid, Spain}$\n",
       "$\\newcommand{\\ObsParis}{\\label{ObsParis} Sorbonne Université, Observatoire de Paris, Université PSL, CNRS, LERMA, F-75014, Paris, France}$\n",
       "$\\newcommand{\\Princeton}{\\label{Princeton} Department of Astrophysical Sciences, Princeton University, Princeton, NJ 08544 USA}$\n",
       "$\\newcommand{\\UToledo}{\\label{UToledo} University of Toledo, 2801 W. Bancroft St., Mail Stop 111, Toledo, OH, 43606}$\n",
       "$\\newcommand{\\Toulouse}{\\label{Toulouse} Université de Toulouse, UPS-OMP, IRAP, F-31028 Toulouse cedex 4, France}$\n",
       "$\\newcommand{\\UBonn}{\\label{UBonn} Argelander-Institut für Astronomie, Universität Bonn, Auf dem Hügel 71, 53121 Bonn, Germany}$\n",
       "$\\newcommand{\\UChile}{\\label{UChile} Departamento de Astronomía, Universidad de Chile, Camino del Observatorio 1515, Las Condes, Santiago, Chile}$\n",
       "$\\newcommand{\\UConn}{\\label{UConn} Department of Physics, University of Connecticut, Storrs, CT, 06269, USA}$\n",
       "$\\newcommand{\\UCSD}{\\label{UCSD}Center for Astrophysics and Space Sciences, Department of Physics,  University of California, San Diego, 9500 Gilman Drive, La Jolla, CA 92093, USA}$\n",
       "$\\newcommand{\\UGent}{\\label{UGent} Sterrenkundig Observatorium, Universiteit Gent, Krijgslaan 281 S9, B-9000 Gent, Belgium}$\n",
       "$\\newcommand{\\ULyon}{\\label{ULyon} Univ Lyon, Univ Lyon 1, ENS de Lyon, CNRS, Centre de Recherche Astrophysique de Lyon UMR5574,\\ F-69230 Saint-Genis-Laval, France}$\n",
       "$\\newcommand{\\UMass}{\\label{UMass} University of Massachusetts—Amherst, 710 N. Pleasant Street, Amherst, MA 01003, USA}$\n",
       "$\\newcommand{\\UWyoming}{\\label{UWyoming} Department of Physics and Astronomy, University of Wyoming, Laramie, WY 82071, USA}$\n",
       "$\\newcommand{\\LAM}{\\label{LAM} Aix Marseille Univ, CNRS, CNES, LAM (Laboratoire d’Astrophysique de Marseille), Marseille, France}$\n",
       "$\\newcommand{\\UHawaii}{\\label{UHawaii} Institute for Astronomy, University of Hawaii, 2680 Woodlawn Drive, Honolulu, HI 96822, USA}$\n",
       "$\\newcommand{\\UCM}{\\label{UCM} Departamento de Física de la Tierra y Astrofísica, Universidad Complutense de Madrid, E-28040, Spain}$\n",
       "$\\newcommand{\\IPARC}{\\label{IPARC} Instituto de Física de Partículas y del Cosmos IPARCOS, Facultad de Ciencias Físicas, Universidad Complutense de Madrid, E-28040, Spain}$\n",
       "$\\newcommand{\\STScI}{\\label{STScI} Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD 21218, USA}$\n",
       "$\\newcommand{\\McMaster}{\\label{McMaster} Department of Physics and Astronomy, McMaster University, 1280 Main Street West, Hamilton, ON L8S 4M1, Canada}$\n",
       "$\\newcommand{\\INAF}{\\label{INAF} INAF -- Osservatorio Astrofisico di Arcetri, Largo E. Fermi 5, I-50157, Firenze, Italy}$\n",
       "$\\newcommand{\\Sydney}{\\label{Sydney} Sydney Institute for Astronomy, School of Physics A28, The University of Sydney, NSW 2006, Australia}$\n",
       "$\\newcommand{\\CITA}{\\label{CITA} Canadian Institute for Theoretical Astrophysics (CITA), University of Toronto, 60 St George St, Toronto, ON M5S 3H8, Canada}$\n",
       "$\\newcommand{\\ASIAA}{\\label{ASIAA} Institute of Astronomy and Astrophysics, Academia Sinica, No. 1, Sec. 4, Roosevelt Road, Taipei 10617, Taiwan}$\n",
       "$\\newcommand{\\TKU}{\\label{TKU} Department of Physics, Tamkang University, No.151, Yingzhuan Rd., Tamsui Dist., New Taipei City 251301, Taiwan}$\n",
       "$\\newcommand{\\PSMA}{\\label{PSMA} Penn State Mont Alto, 1 Campus Drive, Mont Alto, PA  17237, USA}$\n",
       "$\\newcommand{\\ILL}{\\label{ILL} ILL}$\n",
       "$\\newcommand{\\stromlo}{\\label{stromlo} Research School of Astronomy and Astrophysics, Australian National University, Mt Stromlo Observatory, Weston Creek, ACT 2611, Australia}$\n",
       "$\\newcommand{\\UCatolica}{\\label{UCatolica} Instituto de Astronomía, Universidad Católica del Norte, Av. Angamos 0610, Antofagasta, Chile}$\n",
       "$\\newcommand{\\UT}{\\label{UT} McDonald Observatory, The University of Texas at Austin, 1 University Station, Austin, TX 78712-0259, USA}$\n",
       "$\\newcommand{\\Vanderbilt}{\\label{Vanderbilt} Department of Physics and Astronomy, Vanderbilt University, VU Station 1807, Nashville, TN 37235, USA}$\n",
       "$\\newcommand{\\UNF}{\\label{UNF} Department of Physics, University of North Florida, 1 UNF Dr. Jacksonville FL 32224}$\n",
       "$\\newcommand{\\NAOC}{\\label{NAOC} Chinese Academy of Sciences South America Center for Astronomy, National Astronomical Observatories, CAS, Beijing 100101, China}$\n",
       "$\\newcommand{\\CASA}{\\label{CASA} Center for Astrophysics and Space Astronomy, University of Colorado, 389 UCB, Boulder, CO 80309-0389, USA}$\n",
       "$\\newcommand{\\UNAM}{\\label{UNAM} Universidad Nacional Autónoma de México, Instituto de Astronomía, AP 106, Ensenada 22800, BC, México}$\n",
       "$\\newcommand{\\UDP}{\\label{UDP} Instituto de Estudios Astrofísicos, Facultad de Ingeniería y Ciencias, Universidad Diego Portales, Av. Ejército Libertador 441, Santiago, Chile}$\n",
       "$\\newcommand{\\Steward}{\\label{Steward} Steward Observatory, University of Arizona, 933 N. Cherry Ave., Tucson, AZ 85721-0065, USA}$\n",
       "$\\newcommand{\\APO}{\\label{APO} Apache Point Observatory and New Mexico State University, P.O. Box 59,$\n",
       "$Sunspot, NM 88349-0059, USA}$\n",
       "$\\newcommand{\\UNAMCU}{\\label{UNAMCU} Universidad Nacional Autónoma de México, Instituto de Astronomía, AP 70-264, CDMX 04510, México}$\n",
       "$\\newcommand{\\UWash}{\\label{UWash}Department of Astronomy, University of Washington, Seattle, WA, 98195}$\n",
       "$\\newcommand{Ç}{\\label{CC}Department of Physics, Colorado College, Colorado Springs, CO 80903}$\n",
       "$\\newcommand{\\Utah}{\\label{Utah}Department of Physics and Astronomy, University of Utah, 115 S. 1400 E., Salt Lake City, UT 84112, USA}$\n",
       "$\\newcommand{\\UConcepcion}{\\label{UConcepcion}Departamento de Astronomía, Universidad de Concepción, Casilla 160-C, Concepción, Chile}$\n",
       "$\\newcommand{\\FCLA}{\\label{FCLA}Franco-Chilean Laboratory for Astronomy, IRL 3386, CNRS and Universidad de Chile, Santiago, Chile}$\n",
       "$\\newcommand{\\Oklahoma}{\\label{Oklahoma}Homer L. Dodge Department of Physics and Astronomy, University of Oklahoma, Norman, OK 73019, USA}$\n",
       "$\\newcommand{\\UIUC}{\\label{UIUC}Department of Astronomy, University of Illinois, Urbana, IL 61801, USA}$\n",
       "$\\newcommand{\\Harvard}{\\label{Harvard}Harvard-Smithsonian Center for Astrophysics, Cambridge, MA 02138, USA}$\n",
       "$\\newcommand{\\caltech}{\\label{caltech}Department of Astronomy, California Institute of Technology, Pasadena, CA 91125, USA}$\n",
       "$\\newcommand{\\pyf}{\\texttt{pyFIT3D}\\xspace}$\n",
       "$\\newcommand{\\pyp}{\\texttt{pyPipe3D}\\xspace}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# The SDSS-V Local Volume Mapper (LVM): Data Analysis Pipeline\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2411.09729-b31b1b.svg)](https://arxiv.org/abs/2411.09729)<mark>Appeared on: 2024-11-18</mark> -  _35 pages, 17 figures, 8 tables, accepted for publication in AJ_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "S. F. Sánchez, et al. -- incl., <mark>K. Kreckel</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** We introduce the Data Analysis Pipeline (DAP) for the Sloan Digital Sky Survey V (SDSS-V) Local Volume Mapper (LVM) project, referred to as the LVM-DAP. ${ We outline our methods for recovering both stellar and emission line components from the optical integral field spectroscopy, highlighting the developments and changes implemented to address specific challenges of the data set.}$ The observations from the LVM project are unique because they cover a wide range of physical resolutions, from approximately 0.05 pc to 100 pc, depending on the distance to the targets. This, along with the varying number of stars sampled in each aperture (ranging from ${ zero, just one of a few, }$ to thousands), presents challenges in using previous spectral synthesis methods and interpreting the spectral fits. We provide a detailed explanation of how we model the stellar content and separate it from the ionized gas emission lines.  To assess the accuracy of our results, we compare them with both idealized and more realistic simulations, highlighting the limitations of our methods. We find that ${ the DAP}$ robustly correct for stellar continuum features and recover emission line parameters (e.g. flux, equivalent width, systemtic velocity and velocity dispersion) ${ with a precision and accuracy that fulfill the requirements of the primary goal of the analysis. In addition,}$ the recovered stellar parameters are reliable for single stars, the recovery of integrated populations is less precise. We conclude with a description of the data products we provide, instructions for downloading and using our software, and a showcase illustrating the quality of the data and the analysis on a deep exposure taken on the Huygens region at the center of the Orion Nebula.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2411.09729/./figures/m_sel-ORION.png\" alt=\"Fig15\" width=\"100%\"/>\n",
       "\n",
       "**Figure 15. -** Integrated spectrum of the central 5'$\\times$6' region of the Orion Nebula (black solid line), together with the best-fitted stellar model (red solid line), the model of the strongest emission lines fitted with Gaussian functions (blue solid line), and the residual after subtraction of the stellar model (cyan solid line), and the combination of both models, including a final correction to the shape of the residual (yellow solid line). The first three panels from top to bottom present the wavelength ranges covered by the blue (1st row), green (2nd row), and infrared (3rd row) arms that comprise the LVM spectrograph. Shaded regions correspond to the overlapping regimes between them. Like in the case of figures \\ref{fig:lvmsim} and \\ref{fig:dapsim}, the insets in the two bottom rows show a set of zoom-ins at certain particular wavelength ranges. The panels in the 4th row illustrate the quality of the modeling of the strongest emission lines, including the same lines already shown in Fig. \\ref{fig:lvmsim} and \\ref{fig:dapsim}. Finally, the last row of panels includes three wavelength ranges (3651-3726 Å, 4801-4999 Å, and 8151-8299 Å) that illustrate certain particularities of the spectrum discussed in the text. Three additional panels present a zoom around the three auroral lines most frequently used to determine the electron temperature in ionized nebulae: $\\oi$ii 4363, $\\nii$ 5755, and $\\sii$i 6312. The flux ranges in these three last insets are the same to facilitate the comparison between the lines. In the particular case of this very deep spectrum, all three are clearly detected. (*fig:O_spec*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2411.09729/./figures/Scene2_sim_in.png\" alt=\"Fig9.1\" width=\"33%\"/><img src=\"tmp_2411.09729/./figures/Scene2_sim_out.png\" alt=\"Fig9.2\" width=\"33%\"/><img src=\"tmp_2411.09729/./figures/m_fit_Scene1.png\" alt=\"Fig9.3\" width=\"33%\"/>\n",
       "\n",
       "**Figure 9. -** Upper-panels: Spatial distribution of the input (left panel) and recovered (right panel) fluxes of the $\\oi$ii 5007 (blue), H$\\alpha$(green) and $\\nii$ 6583 (red) emission lines in an arbitrary scale. Lower-panel: Example of the spectral modelling, showing the spectrum integrated across the Field-of-View (FoV) of the simulated IFS dataset (black solid line), together the best model for the stellar component (red solid line) and the set of strong ionized emission lines (blue solid line). The residuals of the subtraction of the stellar model (cyan solid line), and both models (yellow solid line) are also included. All the spectra are presented in the original flux intensities (middle panel), and normalized to one at 5000 Å (bottom panel). The orange vertical marks indicate the wavelengths at which the algorithm would attempt to extract the properties of a predefined set of emission lines using a weighted moment analysis, as described in the text. Shaded regions correspond to the overlapping regimes between the three arms of the spectrographs. The panel insets show zoom-ins in the wavelength range covered by a set of strong emission lines, including the $\\oi$i doublet, H$\\delta$, H$\\gamma$, $\\Hb$, $\\oi$ii, $\\Ha$, $\\nii$, $\\sii$, and the $\\sii$i 9069, 9531 doublet.  (*fig:lvmsim*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2411.09729/./figures/Rosetta_sim_in.png\" alt=\"Fig10.1\" width=\"33%\"/><img src=\"tmp_2411.09729/./figures/Rosetta_sim_out.png\" alt=\"Fig10.2\" width=\"33%\"/><img src=\"tmp_2411.09729/./figures/m_fit_00006109_cl_SN1_342_5_5_20.0.png\" alt=\"Fig10.3\" width=\"33%\"/>\n",
       "\n",
       "**Figure 10. -** Similar figure as the one shown in Fig. \\ref{fig:lvmsim}, adopting the same nomenclature, symbols and color schemes, for the realistic simulation performed using one LVM pointing on the Rosetta nebula. White hexagons inside the IFU corresponds to broken and low-transmission fibers in the input data. (*fig:dapsim*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2411.09729\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.004923,
     "end_time": "2024-11-18T04:13:05.663856",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.658933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.674910Z",
     "iopub.status.busy": "2024-11-18T04:13:05.674395Z",
     "iopub.status.idle": "2024-11-18T04:13:05.682448Z",
     "shell.execute_reply": "2024-11-18T04:13:05.681880Z"
    },
    "papermill": {
     "duration": 0.014571,
     "end_time": "2024-11-18T04:13:05.683471",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.668900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.694448Z",
     "iopub.status.busy": "2024-11-18T04:13:05.694246Z",
     "iopub.status.idle": "2024-11-18T04:13:05.710676Z",
     "shell.execute_reply": "2024-11-18T04:13:05.710068Z"
    },
    "papermill": {
     "duration": 0.023099,
     "end_time": "2024-11-18T04:13:05.711768",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.688669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.722912Z",
     "iopub.status.busy": "2024-11-18T04:13:05.722569Z",
     "iopub.status.idle": "2024-11-18T04:13:05.727380Z",
     "shell.execute_reply": "2024-11-18T04:13:05.726824Z"
    },
    "papermill": {
     "duration": 0.011512,
     "end_time": "2024-11-18T04:13:05.728403",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.716891",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.739858Z",
     "iopub.status.busy": "2024-11-18T04:13:05.739418Z",
     "iopub.status.idle": "2024-11-18T04:13:05.744231Z",
     "shell.execute_reply": "2024-11-18T04:13:05.743732Z"
    },
    "papermill": {
     "duration": 0.011515,
     "end_time": "2024-11-18T04:13:05.745211",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.733696",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.756585Z",
     "iopub.status.busy": "2024-11-18T04:13:05.756181Z",
     "iopub.status.idle": "2024-11-18T04:13:05.762555Z",
     "shell.execute_reply": "2024-11-18T04:13:05.762013Z"
    },
    "papermill": {
     "duration": 0.01309,
     "end_time": "2024-11-18T04:13:05.763591",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.750501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T04:13:05.775318Z",
     "iopub.status.busy": "2024-11-18T04:13:05.774938Z",
     "iopub.status.idle": "2024-11-18T04:13:05.781072Z",
     "shell.execute_reply": "2024-11-18T04:13:05.780573Z"
    },
    "papermill": {
     "duration": 0.013069,
     "end_time": "2024-11-18T04:13:05.782127",
     "exception": false,
     "start_time": "2024-11-18T04:13:05.769058",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 104.644244,
   "end_time": "2024-11-18T04:13:06.002806",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2024-11-18T04:11:21.358562",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bf1e24a1e274cd8b187a08c1be2b592": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27461cc4bf5641e29812d0d1a22e0779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0bf1e24a1e274cd8b187a08c1be2b592",
       "placeholder": "​",
       "style": "IPY_MODEL_e3bbee18f05147c7a281f1ea44e117c5",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "99e7271173c742f2a115bbcaaa32a545": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9a335be3e3e1464cbbe779c2b2a53385": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b6633acae16e4485bd3e462861aac42a",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_deb492d93002439586a89a6ffe8061ce",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     },
     "b6633acae16e4485bd3e462861aac42a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be6b922b20e44d3b9782d1941fb5cf96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_da9bcbe639594559b4744814a4c31249",
       "placeholder": "​",
       "style": "IPY_MODEL_99e7271173c742f2a115bbcaaa32a545",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [01:25&lt;00:00, 12.27s/it]"
      }
     },
     "cbbf982d0efd4717b62ff12dfaf7af81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da640b42552b44e9bf05c55410645a75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_27461cc4bf5641e29812d0d1a22e0779",
        "IPY_MODEL_9a335be3e3e1464cbbe779c2b2a53385",
        "IPY_MODEL_be6b922b20e44d3b9782d1941fb5cf96"
       ],
       "layout": "IPY_MODEL_cbbf982d0efd4717b62ff12dfaf7af81",
       "tabbable": null,
       "tooltip": null
      }
     },
     "da9bcbe639594559b4744814a4c31249": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "deb492d93002439586a89a6ffe8061ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e3bbee18f05147c7a281f1ea44e117c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}