{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.003803,
     "end_time": "2025-01-14T04:10:41.407500",
     "exception": false,
     "start_time": "2025-01-14T04:10:41.403697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:10:41.415284Z",
     "iopub.status.busy": "2025-01-14T04:10:41.414670Z",
     "iopub.status.idle": "2025-01-14T04:10:42.070137Z",
     "shell.execute_reply": "2025-01-14T04:10:42.069489Z"
    },
    "papermill": {
     "duration": 0.660731,
     "end_time": "2025-01-14T04:10:42.071514",
     "exception": false,
     "start_time": "2025-01-14T04:10:41.410783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "import re\n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:10:42.078828Z",
     "iopub.status.busy": "2025-01-14T04:10:42.078521Z",
     "iopub.status.idle": "2025-01-14T04:10:42.086762Z",
     "shell.execute_reply": "2025-01-14T04:10:42.086067Z"
    },
    "papermill": {
     "duration": 0.01305,
     "end_time": "2025-01-14T04:10:42.087827",
     "exception": false,
     "start_time": "2025-01-14T04:10:42.074777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt\n",
    "\n",
    "\n",
    "def clean_non_western_encoded_characters_commands(text: str) -> str:\n",
    "    \"\"\" Remove non-western encoded characters from a string\n",
    "    List may need to grow.\n",
    "    \n",
    "    :param text: the text to clean\n",
    "    :return: the cleaned text\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"(\\\\begin{CJK}{UTF8}{gbsn})(.*?)(\\\\end{CJK})\", r\"\\2\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_initials(name: str) -> str:\n",
    "    \"\"\" Get the short name, e.g., A.-B. FamName\n",
    "    :param name: full name\n",
    "    :returns: initials\n",
    "    \"\"\"\n",
    "    initials = []\n",
    "    # account for non western names often in ()\n",
    "    if '(' in name:\n",
    "        name = clean_non_western_encoded_characters_commands(name)\n",
    "        suffix = re.findall(r\"\\((.*?)\\)\", name)[0]\n",
    "        name = name.replace(f\"({suffix})\", '')\n",
    "    else:\n",
    "        suffix = ''\n",
    "    split = name.split()\n",
    "    for token in split[:-1]:\n",
    "        if '-' in token:\n",
    "            current = '-'.join([k[0] + '.' for k in token.split('-')])\n",
    "        else:\n",
    "            current = token[0] + '.'\n",
    "        initials.append(current)\n",
    "    initials.append(split[-1].strip())\n",
    "    if suffix:\n",
    "        initials.append(f\"({suffix})\")\n",
    "    return ' '.join(initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.002894,
     "end_time": "2025-01-14T04:10:42.093662",
     "exception": false,
     "start_time": "2025-01-14T04:10:42.090768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:10:42.100484Z",
     "iopub.status.busy": "2025-01-14T04:10:42.100106Z",
     "iopub.status.idle": "2025-01-14T04:11:01.647792Z",
     "shell.execute_reply": "2025-01-14T04:11:01.647148Z"
    },
    "papermill": {
     "duration": 19.552522,
     "end_time": "2025-01-14T04:11:01.649135",
     "exception": false,
     "start_time": "2025-01-14T04:10:42.096613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Zähringer', 'Scheerer', 'Hoffmann', 'Düe',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'Jäger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:01.656847Z",
     "iopub.status.busy": "2025-01-14T04:11:01.656335Z",
     "iopub.status.idle": "2025-01-14T04:11:02.747875Z",
     "shell.execute_reply": "2025-01-14T04:11:02.747245Z"
    },
    "papermill": {
     "duration": 1.096306,
     "end_time": "2025-01-14T04:11:02.748896",
     "exception": false,
     "start_time": "2025-01-14T04:11:01.652590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E. Schinnerer  ->  E. Schinnerer  |  ['E. Schinnerer']\n",
      "I. J. M. Crossfield  ->  I. J. M. Crossfield  |  ['I. J. M. Crossfield']\n",
      "S. Kraus  ->  S. Kraus  |  ['S. Kraus']\n",
      "A. Pillepich  ->  A. Pillepich  |  ['A. Pillepich']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "J. Li  ->  J. Li  |  ['J. Li']\n",
      "J. Liu  ->  J. Liu  |  ['J. Liu']\n",
      "K. Jahnke  ->  K. Jahnke  |  ['K. Jahnke']\n",
      "Arxiv has 105 new papers today\n",
      "          8 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "def robust_call(fn, value, *args, **kwargs):\n",
    "    try:\n",
    "        return fn(value, *args, **kwargs)\n",
    "    except Exception:\n",
    "        return value\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [robust_call(mpia.get_initials, k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.003158,
     "end_time": "2025-01-14T04:11:02.755554",
     "exception": false,
     "start_time": "2025-01-14T04:11:02.752396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:02.762610Z",
     "iopub.status.busy": "2025-01-14T04:11:02.762365Z",
     "iopub.status.idle": "2025-01-14T04:11:51.965283Z",
     "shell.execute_reply": "2025-01-14T04:11:51.964577Z"
    },
    "papermill": {
     "duration": 49.20768,
     "end_time": "2025-01-14T04:11:51.966272",
     "exception": false,
     "start_time": "2025-01-14T04:11:02.758592",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee10441c5fe7413b812a4b79a1ba7b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2501.06333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2501.06333..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2501.06342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Found documentclass in tmp_2501.06333/main.tex\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2501.06342..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2501.06982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Found documentclass in tmp_2501.06342/main.tex\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'dg_transit_table' from 'tmp_2501.06342/dg_transit_table.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'dg_occurrence_rates' from 'tmp_2501.06342/dg_occurrence_rates.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'trend_systems_table' from 'tmp_2501.06342/trend_systems_table.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'resolved_table' from 'tmp_2501.06342/resolved_table.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'variables' from 'tmp_2501.06342/variables.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2501.06982..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "  0: tmp_2501.06982/ms1.tex, 746 lines\n",
      "  1: tmp_2501.06982/aassymbols.tex, 579 lines\n",
      "Retrieving document from  https://arxiv.org/e-print/2501.07151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Found 2 candidates with documentclass definition.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Assuming tmp_2501.06982/ms1.tex as main document.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2501.07151..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 96 bibliographic references in tmp_2501.07151/draft.bbl.\n",
      "Retrieving document from  https://arxiv.org/e-print/2501.07340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2501.07340..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2501.07361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2501.07361... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2501.07362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2501.07362..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2501.07559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2501.07559..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/pipeline_final\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/pipeline_final as tmp_2501.07559/././figs/pipeline_final.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/nz_diagram_final\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/nz_diagram_final as tmp_2501.07559/././figs/nz_diagram_final.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/w0wa_NONOISE_1x2ptE\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/w0wa_NONOISE_1x2ptE as tmp_2501.07559/././figs/w0wa_NONOISE_1x2ptE.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/w0wa_NONOISE_1x2ptN\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/w0wa_NONOISE_1x2ptN as tmp_2501.07559/././figs/w0wa_NONOISE_1x2ptN.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/w0wa_NONOISE_3x2pt\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/w0wa_NONOISE_3x2pt as tmp_2501.07559/././figs/w0wa_NONOISE_3x2pt.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/w0wa_NOISE_1x2ptE\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/w0wa_NOISE_1x2ptE as tmp_2501.07559/././figs/w0wa_NOISE_1x2ptE.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/w0wa_NOISE_1x2ptN\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/w0wa_NOISE_1x2ptN as tmp_2501.07559/././figs/w0wa_NOISE_1x2ptN.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/w0wa_NOISE_3x2pt\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/w0wa_NOISE_3x2pt as tmp_2501.07559/././figs/w0wa_NOISE_3x2pt.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/w0_wa_fitting\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/w0_wa_fitting as tmp_2501.07559/././figs/w0_wa_fitting.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/correction_factors\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/correction_factors as tmp_2501.07559/././figs/correction_factors.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/contours_equipop_noise_E\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/contours_equipop_noise_E as tmp_2501.07559/././figs/contours_equipop_noise_E.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/contours_equipop_noise_N\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/contours_equipop_noise_N as tmp_2501.07559/././figs/contours_equipop_noise_N.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/contours_equipop_noise_3x2pt\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/contours_equipop_noise_3x2pt as tmp_2501.07559/././figs/contours_equipop_noise_3x2pt.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:132: LatexWarning: attempting recovering figure ./figs/w0wa_areas_appendix_horizontal\n",
      "  warnings.warn(LatexWarning(f'attempting recovering figure {image}'))\n",
      "/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:137: LatexWarning: Recovered figure ./figs/w0wa_areas_appendix_horizontal as tmp_2501.07559/././figs/w0wa_areas_appendix_horizontal.png\n",
      "  warnings.warn(LatexWarning(f'Recovered figure {image} as {fname}'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 89 bibliographic references in tmp_2501.07559/tomographic_binning.bbl.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(\"Issues with the citations\")\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.004396,
     "end_time": "2025-01-14T04:11:51.975270",
     "exception": false,
     "start_time": "2025-01-14T04:11:51.970874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:51.984758Z",
     "iopub.status.busy": "2025-01-14T04:11:51.984516Z",
     "iopub.status.idle": "2025-01-14T04:11:52.003233Z",
     "shell.execute_reply": "2025-01-14T04:11:52.002725Z"
    },
    "papermill": {
     "duration": 0.024627,
     "end_time": "2025-01-14T04:11:52.004221",
     "exception": false,
     "start_time": "2025-01-14T04:11:51.979594",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2501.07151-b31b1b.svg)](https://arxiv.org/abs/2501.07151) | **The diverse physical origins of stars in the dynamically hot bulge: CALIFA vs. IllustrisTNG**  |\n",
       "|| L. Zhang, et al. -- incl., <mark>A. Pillepich</mark> |\n",
       "|*Appeared on*| *2025-01-14*|\n",
       "|*Comments*| *18 pages, 15 figures*|\n",
       "|**Abstract**|            We compare the internal stellar structures of central galaxies in the TNG50 and TNG100 simulations and field galaxies in the CALIFA survey. The luminosity fractions of the dynamically cold, warm, and hot components in both TNG50 and TNG100 galaxies exhibit general consistency with those observed in CALIFA galaxies. For example, they all exhibit a minimum luminosity fraction of the dynamically hot component in galaxies with intermediate stellar masses, and the morphology of each orbital component in the TNG50 and TNG100 galaxies closely resembles that found in the CALIFA galaxies. We therefore use the simulations to quantify the physical origins of the different components, focusing on the dynamically hot component in TNG50. We identify three primary regimes and thus physical processes: (1) in low mass galaxies that have not experienced major mergers, stars are born with a wide range of circularity distributions and have remained relatively unchanged until the present day. Consequently, hot stars in such galaxies at redshift 0 are predominantly born hot. (2) In higher mass galaxies lacking major mergers, most stars are initially born cold but are subsequently heated through secular evolution. (3) In galaxies across the entire mass range, mergers, if they occurred, significantly increased the hot orbital fraction. As a result, the dynamically hot bulge within $R_e$ of present-day galaxies does not indicate their past merger histories; instead, the hot stars in the outer regions are mostly heated or accreted by mergers, thus indicating galaxy merger history. The massive galaxies are initially born with cold, rotationally supported structures, consistent with recent observations from the James Webb Space Telescope (JWST) regarding high-redshift galaxies.         |"
      ],
      "text/plain": [
       "[2501.07151] The diverse physical origins of stars in the dynamically hot bulge: CALIFA vs. IllustrisTNG\n",
       "\tL. Zhang, et al. -- incl., <mark>A. Pillepich</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2501.07559-b31b1b.svg)](https://arxiv.org/abs/2501.07559) | **Euclid: Optimising tomographic redshift binning for 3$\\times$2pt power spectrum constraints on dark energy**  |\n",
       "|| J. H. W. Wong, et al. -- incl., <mark>K. Jahnke</mark> |\n",
       "|*Appeared on*| *2025-01-14*|\n",
       "|*Comments*| *Euclid Consortium paper. 28 pages, 17 figures. For submission to A&A*|\n",
       "|**Abstract**|            We present a simulation-based method to explore the optimum tomographic redshift binning strategy for 3x2pt analyses with Euclid, focusing on the expected configuration of its first major data release (DR1). To do this, we 1) simulate a Euclid-like observation and generate mock shear catalogues from multiple realisations of the 3x2pt fields on the sky, and 2) measure the 3x2pt Pseudo-Cl power spectra for a given tomographic configuration and derive the constraints that they place on the standard dark energy equation of state parameters (w0, wa). For a simulation including Gaussian-distributed photometric redshift uncertainty and shape noise under a LambdaCDM cosmology, we find that bins equipopulated with galaxies yield the best constraints on (w0, wa) for an analysis of the full 3x2pt signal, or the angular clustering component only. For the cosmic shear component, the optimum (w0, wa) constraints are achieved by bins equally spaced in fiducial comoving distance. However, the advantage with respect to alternative binning choices is only a few percent in the size of the $1\\,\\sigma\\,$(w0, wa) contour, and we conclude that the cosmic shear is relatively insensitive to the binning methodology. We find that the information gain extracted on (w0, wa) for any 3x2pt component starts to saturate at $\\gtrsim$ 7-8 bins. Any marginal gains resulting from a greater number of bins is likely to be limited by additional uncertainties present in a real measurement, and the increasing demand for accuracy of the covariance matrix. Finally, we consider a 5% contamination from catastrophic photometric redshift outliers and find that, if these errors are not mitigated in the analysis, the bias induced in the 3x2pt signal for 10 equipopulated bins results in dark energy constraints that are inconsistent with the fiducial LambdaCDM cosmology at $>5\\,\\sigma$.         |"
      ],
      "text/plain": [
       "[2501.07559] Euclid: Optimising tomographic redshift binning for 3$\\times$2pt power spectrum constraints on dark energy\n",
       "\tJ. H. W. Wong, et al. -- incl., <mark>K. Jahnke</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2501.06333-b31b1b.svg)](https://arxiv.org/abs/2501.06333) | **VLA+VLBA to ngVLA Transition Option Concepts**  |\n",
       "|| A. Corsi, et al. -- incl., <mark>E. Schinnerer</mark> |\n",
       "|*Appeared on*| *2025-01-14*|\n",
       "|*Comments*| *This report reflects an initial set of recommendations by the Transition Advisory Group for the ngVLA Project and is distributed for the purposes of obtaining community comment. Modification of this report in response to community comment is expected. Please submit your feedback at ngvla-transition-feedback@listmgr.this http URL*|\n",
       "|**Abstract**|            The next-generation Very Large Array (ngVLA) is intended to be the premier centimeter-wavelength facility for astronomy and astrophysics, building on the substantial scientific legacies of the Karl G. Jansky Very Large Array (VLA) and the Very Long Baseline Array (VLBA). The ngVLA would open a new window on the Universe through ultra-sensitive imaging of thermal line and continuum emission to milliarcsecond resolution, while delivering unprecedented broad-band continuum imaging and polarimetry of non-thermal emission. The ngVLA would provide a critical electromagnetic complement to a suite of particle detectors and gravitational-wave observatories, as well as space- and ground-based telescopes operating from infrared to gamma-ray wavelengths, hence enabling multi-messenger and multi-band astronomy and astrophysics. Current construction plans call for the ngVLA to leverage some of the physical infrastructure of both the VLA and the VLBA, potentially drawing on overlapping personnel and information infrastructure. Multiple options can be envisioned for a VLA+VLBA to ngVLA transition. In order to assess risks and benefits of possible transition plans, the ngVLA project established the VLA+VLBA to ngVLA Transition Advisory Group (TAG). The primary deliverable from the TAG is a ``VLA+VLBA to ngVLA Transition Option Concepts'' report (this report) that includes a prioritized list of transition options.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2501.06342-b31b1b.svg)](https://arxiv.org/abs/2501.06342) | **The TESS-Keck Survey XXIV: Outer Giants may be More Prevalent in the Presence of Inner Small Planets**  |\n",
       "|| J. V. Zandt, et al. -- incl., <mark>I. J. M. Crossfield</mark> |\n",
       "|*Appeared on*| *2025-01-14*|\n",
       "|*Comments*| *32 pages, 20 figures, 4 tables. Comments welcome*|\n",
       "|**Abstract**|            We present the results of the Distant Giants Survey, a three-year radial velocity (RV) campaign to search for wide-separation giant planets orbiting Sun-like stars known to host an inner transiting planet. We defined a distant giant to have $a$ = 1--10 AU and $M_{p} \\sin i = 70-4000$ \\mearth~ = 0.2-12.5 \\mj, and required transiting planets to have $a<1$ AU and $R_{p} = 1-4$ \\rearth. We assembled our sample of 47 stars using a single selection function, and observed each star at monthly intervals to obtain $\\approx$30 RV observations per target. The final catalog includes a total of twelve distant companions: four giant planets detected during our survey, two previously known giant planets, and six objects of uncertain disposition identified through RV/astrometric accelerations. Statistically, half of the uncertain objects are planets and the remainder are stars/brown dwarfs. We calculated target-by-target completeness maps to account for missed planets. We found evidence for a moderate enhancement of distant giants (DG) in the presence of close-in small planets (CS), P(DG|CS) = $30^{+14}_{-12}\\%$, over the field rate of P(DG) = $16^{+2}_{-2}\\%$. No enhancement is disfavored ($p \\sim$ 8%). In contrast to a previous study, we found no evidence that stellar metallicity enhances P(DG|CS). We found evidence that distant giant companions are preferentially found in systems with multiple transiting planets and have lower eccentricities than randomly selected giant planets. This points toward dynamically cool formation pathways for the giants that do not disturb the inner systems.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2501.06982-b31b1b.svg)](https://arxiv.org/abs/2501.06982) | **A Spectroscopic and Interferometric Study of W Serpentis Stars. I. Circumbinary Outflow in the Interacting Binary W Serpentis**  |\n",
       "|| K. Shepard, et al. -- incl., <mark>S. Kraus</mark> |\n",
       "|*Appeared on*| *2025-01-14*|\n",
       "|*Comments*| *Published in ApJ*|\n",
       "|**Abstract**|            W Serpentis is an eclipsing binary system and the prototype of the Serpentid class of variable stars. These are interacting binaries experiencing intense mass transfer and mass loss. However, the identities and properties of both stars in W Ser remain a mystery. Here we present an observational analysis of high quality, visible-band spectroscopy made with the Apache Point Observatory 3.5 m telescope and ARCES spectrograph plus the first near-IR, long-baseline interferometric observations obtained with the CHARA Array. We present examples of the appearance and radial velocities of the main spectral components: prominent emission lines, strong shell absorption lines, and weak absorption lines. We show that some of the weak absorption features are associated with the cool mass donor, and we present the first radial velocity curve for the donor star. The donor's absorption lines are rotationally broadened, and we derive a ratio of donor to gainer mass of 0.36 +/- 0.09 based on the assumptions that the donor fills its Roche lobe and rotates synchronously with the orbit. We use a fit of the ASAS light curve to determine the orbital inclination and mass estimates of 2.0 and 5.7 solar masses for the donor and gainer, respectively. The partially resolved interferometric measurements of orbital motion are consistent with our derived orbital properties and the distance from Gaia EDR3. Spectroscopic evidence indicates that the gainer is enshrouded in an opaque disk that channels the mass transfer stream into an outflow through the L3 region and into a circumbinary disk.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2501.07340-b31b1b.svg)](https://arxiv.org/abs/2501.07340) | **The Spectrum of C/2023 A3 Indicates A Depleted Composition**  |\n",
       "|| Y. Tang, et al. -- incl., <mark>X. Zhang</mark> |\n",
       "|*Appeared on*| *2025-01-14*|\n",
       "|*Comments*| *Published on RNAAS, Oct 2024. 4 pages, 1 figure. Further work in progress and comments are welcome*|\n",
       "|**Abstract**|            We report a spectroscopic observation of comet C/2023 A3 using an 80 mm apochromatic (apo) refractor equipped with a custom-built spectrometer with a resolution of R~2,500 on the night of 4 October 2024. Sodium D lines were detected prominently, while no other emission lines, particularly carbon-bearing species, were observed, which suggests that comet C/2023 A3 may be carbon-depleted. The mobility and flexibility of our observational setup highlight the value of amateur telescopes in observing low-altitude targets like C/2023 A3 as a complement to professional facilities.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2501.07361-b31b1b.svg)](https://arxiv.org/abs/2501.07361) | **Probing the sign-changeable interaction between dark energy and dark matter with DESI baryon acoustic oscillations and DES supernovae data**  |\n",
       "|| T.-N. Li, et al. -- incl., <mark>X. Zhang</mark> |\n",
       "|*Appeared on*| *2025-01-14*|\n",
       "|*Comments*| *10 pages, 3 figures*|\n",
       "|**Abstract**|            There is a possibility of interaction between dark energy and dark matter, and this interaction may also undergo a sign change during the evolution of the universe. In this paper, we utilize the latest observational data to constrain models of a sign-changeable interaction. The data we employ, in addition to the cosmic microwave background data, also encompass the first-year baryon acoustic oscillation data from DESI and the type Ia supernova data of the full 5-year observation from DES. To achieve high generality, we investigate four interacting dark energy (IDE) models with different forms of the interaction term $Q$: (i) IDE1 with $Q = \\beta(a)H\\rho_{\\rm de}$; (ii) IDE2 with $Q = \\beta(a)H\\rho_{\\rm c}$; (iii) IDE3 with $Q = \\beta(a)H_0\\rho_{\\rm de}$; (iv) IDE4 with $Q = \\beta(a)H_0\\rho_{\\rm c}$. From the analysis, we observe that $\\beta(z) > 0$ at early times and $\\beta(z) < 0$ at late times, with the coupling $\\beta(z)$ crossing the non-interacting line $\\beta(z) = 0$ during cosmic evolution at the 2$\\sigma$ confidence level for the IDE1, IDE3, and IDE4 models. However, for the IDE2 model, $\\beta(z)$ remains consistently negative and does not cross $\\beta(z) = 0$ at the 2$\\sigma$ confidence level. Our findings indicate that the energy transfer is from dark matter to dark energy when dark matter dominates the universe, and from dark energy to dark matter when dark energy dominates, for the IDE1 and IDE3 models. Furthermore, Bayesian evidence suggests that the IDE1 and IDE3 models are moderately preferred over the $\\Lambda$CDM model. The overall outcomes of this study clearly indicate that, based on current observational data, the sign-changeable IDE models are quite compelling and merit further attention.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2501.07362-b31b1b.svg)](https://arxiv.org/abs/2501.07362) | **Science objectives of the Einstein Probe mission**  |\n",
       "|| W. Yuan, et al. -- incl., <mark>J. Li</mark>, <mark>J. Liu</mark> |\n",
       "|*Appeared on*| *2025-01-14*|\n",
       "|*Comments*| *67 pages, 24 figures, accepted for publication in SCIENCE CHINA Physics, Mechanics & Astronomy*|\n",
       "|**Abstract**|            The Einstein Probe (EP) is an interdisciplinary mission of time-domain and X-ray astronomy. Equipped with a wide-field lobster-eye X-ray focusing imager, EP will discover cosmic X-ray transients and monitor the X-ray variability of known sources in 0.5-4 keV, at a combination of detecting sensitivity and cadence that is not accessible to the previous and current wide-field monitoring missions. EP can perform quick characterisation of transients or outbursts with a Wolter-I X-ray telescope onboard. In this paper, the science objectives of the Einstein Probe mission are presented. EP is expected to enlarge the sample of previously known or predicted but rare types of transients with a wide range of timescales. Among them, fast extragalactic transients will be surveyed systematically in soft X-rays, which include {\\gamma}-ray bursts and their variants, supernova shock breakouts, and the predicted X-ray transients associated with binary neutron star mergers. EP will detect X-ray tidal disruption events and outbursts from active galactic nuclei, possibly at an early phase of the flares for some. EP will monitor the variability and outbursts of X-rays from white dwarfs, neutron stars and black holes in our and neighbouring galaxies at flux levels fainter than those detectable by the current instruments, and is expected to discover new objects. A large sample of stellar X-ray flares will also be detected and characterised. In the era of multi-messenger astronomy, EP has the potential of detecting the possible X-ray counterparts of gravitational wave events, neutrino sources, and ultra-high energy {\\gamma}-ray and cosmic ray sources. EP is expected to help advance the studies of extreme objects/phenomena and their underlying physical processes revealed in the dynamic X-ray universe, as well as studies in other areas of X-ray astronomy.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.005181,
     "end_time": "2025-01-14T04:11:52.014837",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.009656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.026311Z",
     "iopub.status.busy": "2025-01-14T04:11:52.025906Z",
     "iopub.status.idle": "2025-01-14T04:11:52.032521Z",
     "shell.execute_reply": "2025-01-14T04:11:52.031986Z"
    },
    "papermill": {
     "duration": 0.013442,
     "end_time": "2025-01-14T04:11:52.033524",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.020082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.044814Z",
     "iopub.status.busy": "2025-01-14T04:11:52.044602Z",
     "iopub.status.idle": "2025-01-14T04:11:52.050654Z",
     "shell.execute_reply": "2025-01-14T04:11:52.050082Z"
    },
    "papermill": {
     "duration": 0.012755,
     "end_time": "2025-01-14T04:11:52.051608",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.038853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found figures ['tmp_2501.07151/./figures/Flum.png', 'tmp_2501.07151/./figures/qt_y_age.png', 'tmp_2501.07151/./figures/qe.png']\n",
      "copying  tmp_2501.07151/./figures/Flum.png to _build/html/\n",
      "copying  tmp_2501.07151/./figures/qt_y_age.png to _build/html/\n",
      "copying  tmp_2501.07151/./figures/qe.png to _build/html/\n",
      "exported in  _build/html/2501.07151.md\n",
      "    + _build/html/tmp_2501.07151/./figures/Flum.png\n",
      "    + _build/html/tmp_2501.07151/./figures/qt_y_age.png\n",
      "    + _build/html/tmp_2501.07151/./figures/qe.png\n",
      "found figures ['tmp_2501.07559/././figs/w0wa_NONOISE_1x2ptE.png', 'tmp_2501.07559/././figs/w0wa_NOISE_3x2pt.png', 'tmp_2501.07559/././figs/nz_diagram_final.png']\n",
      "copying  tmp_2501.07559/././figs/w0wa_NONOISE_1x2ptE.png to _build/html/\n",
      "copying  tmp_2501.07559/././figs/w0wa_NOISE_3x2pt.png to _build/html/\n",
      "copying  tmp_2501.07559/././figs/nz_diagram_final.png to _build/html/\n",
      "exported in  _build/html/2501.07559.md\n",
      "    + _build/html/tmp_2501.07559/././figs/w0wa_NONOISE_1x2ptE.png\n",
      "    + _build/html/tmp_2501.07559/././figs/w0wa_NOISE_3x2pt.png\n",
      "    + _build/html/tmp_2501.07559/././figs/nz_diagram_final.png\n"
     ]
    }
   ],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.005392,
     "end_time": "2025-01-14T04:11:52.062346",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.056954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.074159Z",
     "iopub.status.busy": "2025-01-14T04:11:52.073800Z",
     "iopub.status.idle": "2025-01-14T04:11:52.079553Z",
     "shell.execute_reply": "2025-01-14T04:11:52.078903Z"
    },
    "papermill": {
     "duration": 0.012761,
     "end_time": "2025-01-14T04:11:52.080620",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.067859",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\LZ}[1]{{\\color{red} #1}}$\n",
       "$\\newcommand{\\revision}[1]{{\\color{black} #1}}$\n",
       "$\\newcommand{\\ap}[1]{{\\color{cyan} #1}}$\n",
       "$\\newcommand{\\kms}{km s^{-1}}$\n",
       "$\\newcommand{\\dgr}{^\\circ}$\n",
       "$\\newcommand{\\kmsM}{km s^{-1} Mpc^{-1}}$\n",
       "$\\newcommand{\\Msun}{M_\\odot}$\n",
       "$\\newcommand{\\Msunpcsq}{M_\\odot pc^{-2}}$\n",
       "$\\newcommand{\\Msunpccube}{M_\\odot pc^{-3}}$\n",
       "$\\newcommand{\\Lsun}{L_\\odot}$\n",
       "$\\newcommand{\\Lsunpcsq}{L_\\odot pc^{-2}}$\n",
       "$\\newcommand{\\Lsunpccube}{L_\\odot pc^{-3}}$\n",
       "$\\newcommand{\\MLsun}{M_\\odot/L_\\odot}$\n",
       "$\\newcommand{\\magarcsq}{\\mathrm{mag arcsec^{-2}}}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# The diverse physical origins of stars in the dynamically hot bulge: CALIFA vs. IllustrisTNG\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2501.07151-b31b1b.svg)](https://arxiv.org/abs/2501.07151)<mark>Appeared on: 2025-01-14</mark> -  _18 pages, 15 figures_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "L. Zhang, et al. -- incl., <mark>A. Pillepich</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** We compare the internal stellar structures of central galaxies in the TNG50 and TNG100 simulations and field galaxies in the CALIFA survey. The luminosity fractions of the dynamically cold, warm, and hot components in both TNG50 and TNG100 galaxies exhibit general consistency with those observed in CALIFA galaxies. For example, they all exhibit a minimum luminosity fraction ( $f_{\\rm hot} \\sim$ 0.18) of the dynamically hot component in galaxies with stellar masses of $M_*\\sim 1-2 \\times 10^{10}$ $\\Msun$ , and the morphology of each orbital component in the TNG50 and TNG100 galaxies closely resembles that found in the CALIFA galaxies. We therefore use the simulations to quantify the physical origins of the different components, focusing on the dynamically hot component in TNG50. We identify three primary regimes and thus physical processes: (1) in low mass galaxies ( $M_*\\lesssim 10^{10}$ $\\Msun$ ) that have not experienced major mergers, stars are born with a wide range of circularity distributions and have remained relatively unchanged until the present day. Consequently, hot stars in such galaxies at redshift $z = 0$ are predominantly born hot. (2) In higher mass galaxies ( $M_*\\gtrsim 10^{10}$ $\\Msun$ ) lacking major mergers, most stars are initially born cold but are subsequently heated through secular evolution. (3) In galaxies across the entire mass range, mergers, if they occurred, significantly increased the hot orbital fraction. As a result, the dynamically hot bulge within $R_e$ of present-day galaxies does not indicate their past merger histories; instead, the hot stars in the outer regions are mostly heated or accreted by mergers, thus indicating galaxy merger history. Massive galaxies are initially born with cold, rotationally supported structures, consistent with recent observations from the James Webb Space Telescope (JWST) regarding high-redshift galaxies.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2501.07151/./figures/Flum.png\" alt=\"Fig7\" width=\"100%\"/>\n",
       "\n",
       "**Figure 7. -** Comparison of luminosity fractions of four orbital components among CALIFA, TNG50, and TNG100 galaxies at $z\\sim 0$. The trend across the four panels each represents the luminosity fraction of the cold, warm, hot, and CR components as functions of stellar mass. Each red solid curves represent the CALIFA galaxies from [ and Zhu (2018)](), and the associated error bars represent the $1 \\sigma$ uncertainties. The black and blue curves represent the mean values of luminosity fraction as a function of stellar mass for TNG50 and TNG100 galaxies, respectively. The solid lines are for the whole sample and the dashed lines for the sample matched CALIFA in mass, size, and sSFR. The shaded areas represent the corresponding 1$\\sigma$ scatters, indicating that $68\\%$ of the galaxies fall within these regions. Both TNG50 and TNG100 broadly replicate the luminosity fractions of the four components and their dependence on stellar mass, as observed in the CALIFA galaxies. (*fig:Flum*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2501.07151/./figures/qt_y_age.png\" alt=\"Fig3\" width=\"100%\"/>\n",
       "\n",
       "**Figure 3. -** The luminosity fraction of hot orbits heated by secular evolution $f_{\\rm hot,secular-heated}$ vs. the cosmic time when the galaxy quenched (upper panel), and vs. the average stellar age of this group of stars (lower panel). All TNG50 massive galaxies (stellar mass $M_*\\ge 10^{10.5}$\\Msun) with quiescent histories (merger ratio of < 1:10) are included. For galaxies that are still with star formation at $z=0$, we set quench time to be the age of the universe (13.8 Gyr). The Pearson correlation coefficients of the two panels are labeled. Galaxies quenched at an earlier stage are more significantly heated by secular processes, while the average ages of their stars exhibit a weaker correlation. (*fig:qt_y_age*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2501.07151/./figures/qe.png\" alt=\"Fig8\" width=\"100%\"/>\n",
       "\n",
       "**Figure 8. -** The intrinsic flattening ($q_{\\rm R_e}$) of each component as functions of the galaxy's stellar mass $M_*$. The three columns, from left to right, represent the cold, warm, and hot components, respectively. Line styles and colors are same as \\ref{fig:Flum}. (*fig:qe*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2501.07151\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\orcid}[1]$\n",
       "$\\newcommand{\\arraystretch}{1.5}$\n",
       "$\\newcommand{\\arraystretch}{1}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# $\\Euclid$: Optimising tomographic redshift binning for 3$\\times$2pt power spectrum constraints on dark energy$\\thanks{This paper is published on behalf of the Euclid Consortium.}$\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2501.07559-b31b1b.svg)](https://arxiv.org/abs/2501.07559)<mark>Appeared on: 2025-01-14</mark> -  _Euclid Consortium paper. 28 pages, 17 figures. For submission to A&A_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "J. H. W. Wong, et al. -- incl., <mark>K. Jahnke</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** The tomographic approach to analyse the 3 $\\times$ 2pt signal involves dividing the observed galaxy sample into a configuration of redshift bins. We present a simulation-based method to explore the optimum tomographic binning strategy for _Euclid_ , focusing on the expected configuration of its first major data release (DR1). To do this, we 1) simulate a _Euclid_ -like observation and generate mock shear catalogues from multiple realisations of the 3 $\\times$ 2pt fields on the sky, and 2) measure the 3 $\\times$ 2pt Pseudo- $C_{\\ell}$ power spectra for a given tomographic configuration and derive the constraints that they place on the standard dark energy equation of state parameters $(w_{0},w_{a})$ . For a simulation including Gaussian-distributed photometric redshift uncertainty and shape noise under a $\\Lambda$ CDM cosmology, we find that bins equipopulated with galaxies yield the best constraints on $(w_{0},w_{a})$ for an analysis of the full 3 $\\times$ 2pt signal, or the angular clustering component only. For the cosmic shear component, the optimum $(w_{0},w_{a})$ constraints are achieved by bins equally spaced in fiducial comoving distance. However, the advantage with respect to alternative binning choices is only a few percent in the size of the $1 \\sigma (w_{0},w_{a})$ contour, and we conclude that the cosmic shear is relatively insensitive to the binning methodology. We find that the information gain extracted on $(w_{0},w_{a})$ for any 3 $\\times$ 2pt component starts to saturate at $\\gtrsim$ 7--8 bins. Any marginal gains resulting from a greater number of bins is likely to be limited by additional uncertainties present in a real measurement, and the increasing demand for accuracy of the covariance matrix. Finally, we consider a $5\\%$ contamination from catastrophic photometric redshift outliers and find that, if these errors are not mitigated in the analysis, the bias induced in the 3 $\\times$ 2pt signal for 10 equipopulated bins results in dark energy constraints that are inconsistent with the fiducial $\\Lambda$ CDM cosmology at $>5 \\sigma$ .\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2501.07559/././figs/w0wa_NONOISE_1x2ptE.png\" alt=\"Fig3\" width=\"100%\"/>\n",
       "\n",
       "**Figure 3. -** The areas enclosed by the $1 \\sigma$(Blue) and $2 \\sigma$ contours in the $(w_{0}, w_{a})$ plane, for different numbers of redshift bins used in a tomographic analysis of the cosmic shear signal measured from 400 realisations of our simulation. We show in circular markers joined with solid lines the areas measured for the equipopulated binning choice; in square markers joined with dashed lines the equal comoving distance bins; and in triangular markers joined with dotted lines the equal redshift width binning choice. Since the cosmic shear component alone is relatively weakly constraining, the 1 bin measurement does not yield a closed contour in $(w_{0}, w_{a})$ within the ranges of the parameter grid. Hence, the data point for this case represents a lower bound of the true value, which we represent by using a vertical arrow. (*fig:w0wa_NONOISE_1x2ptE*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2501.07559/././figs/w0wa_NOISE_3x2pt.png\" alt=\"Fig8\" width=\"100%\"/>\n",
       "\n",
       "**Figure 8. -** The contour areas enclosed by the 1 and 2 $\\sigma$ constraints on the dark energy $(w_{0}, w_{a})$ parameters, measured for the full 3$\\times$2pt signal in the presence of Gaussian shape noise and photo-$z$ uncertainty. We vary the number of redshift bins used for each of the equipopulated, equally spaced in fiducial comoving distance, and equal redshift width binning strategies. (*fig:w0wa_NOISE_3x2pt*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2501.07559/././figs/nz_diagram_final.png\" alt=\"Fig2\" width=\"100%\"/>\n",
       "\n",
       "**Figure 2. -** Illustration of the method used to simulate a mock weak lensing survey. 2D maps of the correlated 3$\\times$2pt fields are generated at finely-sampled points in redshift. These 2D maps are used to approximate the full 3D cosmological information of the 3$\\times$2pt signal. From the overdensity fields, we Poisson sample a galaxy population that traces the underlying $n(z)$ distribution. We then assign the correlated weak lensing observables to each galaxy from the shear field values at the galaxy's angular position on the sky at a given redshift. We show an early approximation of the _Euclid_ DR1 footprint at the bottom of the figure which we have used to create our _Euclid_-like simulations. The `observed' region is shown in yellow. (The actual _Euclid_ DR1 footprint will be significantly different to that shown here.) (*fig:nz_diagram*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2501.07559\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.005622,
     "end_time": "2025-01-14T04:11:52.091989",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.086367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.104341Z",
     "iopub.status.busy": "2025-01-14T04:11:52.103913Z",
     "iopub.status.idle": "2025-01-14T04:11:52.112515Z",
     "shell.execute_reply": "2025-01-14T04:11:52.111950Z"
    },
    "papermill": {
     "duration": 0.015896,
     "end_time": "2025-01-14T04:11:52.113567",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.097671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.125804Z",
     "iopub.status.busy": "2025-01-14T04:11:52.125620Z",
     "iopub.status.idle": "2025-01-14T04:11:52.143379Z",
     "shell.execute_reply": "2025-01-14T04:11:52.142870Z"
    },
    "papermill": {
     "duration": 0.025139,
     "end_time": "2025-01-14T04:11:52.144402",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.119263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.157258Z",
     "iopub.status.busy": "2025-01-14T04:11:52.156837Z",
     "iopub.status.idle": "2025-01-14T04:11:52.161868Z",
     "shell.execute_reply": "2025-01-14T04:11:52.161312Z"
    },
    "papermill": {
     "duration": 0.012358,
     "end_time": "2025-01-14T04:11:52.162850",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.150492",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.175554Z",
     "iopub.status.busy": "2025-01-14T04:11:52.175123Z",
     "iopub.status.idle": "2025-01-14T04:11:52.180263Z",
     "shell.execute_reply": "2025-01-14T04:11:52.179633Z"
    },
    "papermill": {
     "duration": 0.012585,
     "end_time": "2025-01-14T04:11:52.181279",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.168694",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.194078Z",
     "iopub.status.busy": "2025-01-14T04:11:52.193835Z",
     "iopub.status.idle": "2025-01-14T04:11:52.200662Z",
     "shell.execute_reply": "2025-01-14T04:11:52.200101Z"
    },
    "papermill": {
     "duration": 0.014295,
     "end_time": "2025-01-14T04:11:52.201640",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.187345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T04:11:52.214487Z",
     "iopub.status.busy": "2025-01-14T04:11:52.214066Z",
     "iopub.status.idle": "2025-01-14T04:11:52.220325Z",
     "shell.execute_reply": "2025-01-14T04:11:52.219817Z"
    },
    "papermill": {
     "duration": 0.013761,
     "end_time": "2025-01-14T04:11:52.221331",
     "exception": false,
     "start_time": "2025-01-14T04:11:52.207570",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.886698,
   "end_time": "2025-01-14T04:11:52.442379",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2025-01-14T04:10:40.555681",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "12292349102745a489a612f65f92054d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "198b2c5a1fd340688bab5bbc962de249": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "28bbbfee09524225b959e799621684f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b165eb0e50e415f8d47b3c420e801f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28bbbfee09524225b959e799621684f7",
       "max": 8.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_198b2c5a1fd340688bab5bbc962de249",
       "tabbable": null,
       "tooltip": null,
       "value": 8.0
      }
     },
     "3ebb771d9e9a47b19324f05a90ebd720": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42876e7f27b74bfcac82ffecf92e54e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_be683087e39749dfac7c9a2ae5ed9758",
       "placeholder": "​",
       "style": "IPY_MODEL_3ebb771d9e9a47b19324f05a90ebd720",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "64ed50ad88a6407e8723b9f133e8b135": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_12292349102745a489a612f65f92054d",
       "placeholder": "​",
       "style": "IPY_MODEL_d819978bba184a2c95d651ac6519f619",
       "tabbable": null,
       "tooltip": null,
       "value": " 8/8 [00:49&lt;00:00,  7.15s/it]"
      }
     },
     "825e0e5c3b214dde8fbcf3ddadbac09b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be683087e39749dfac7c9a2ae5ed9758": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d819978bba184a2c95d651ac6519f619": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ee10441c5fe7413b812a4b79a1ba7b8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_42876e7f27b74bfcac82ffecf92e54e3",
        "IPY_MODEL_2b165eb0e50e415f8d47b3c420e801f3",
        "IPY_MODEL_64ed50ad88a6407e8723b9f133e8b135"
       ],
       "layout": "IPY_MODEL_825e0e5c3b214dde8fbcf3ddadbac09b",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}