{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.003766,
     "end_time": "2024-09-05T04:10:00.641440",
     "exception": false,
     "start_time": "2024-09-05T04:10:00.637674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:00.648616Z",
     "iopub.status.busy": "2024-09-05T04:10:00.648192Z",
     "iopub.status.idle": "2024-09-05T04:10:01.140991Z",
     "shell.execute_reply": "2024-09-05T04:10:01.140379Z"
    },
    "papermill": {
     "duration": 0.498195,
     "end_time": "2024-09-05T04:10:01.142697",
     "exception": false,
     "start_time": "2024-09-05T04:10:00.644502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:01.150256Z",
     "iopub.status.busy": "2024-09-05T04:10:01.149681Z",
     "iopub.status.idle": "2024-09-05T04:10:01.154688Z",
     "shell.execute_reply": "2024-09-05T04:10:01.154166Z"
    },
    "papermill": {
     "duration": 0.010116,
     "end_time": "2024-09-05T04:10:01.156072",
     "exception": false,
     "start_time": "2024-09-05T04:10:01.145956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.002822,
     "end_time": "2024-09-05T04:10:01.161786",
     "exception": false,
     "start_time": "2024-09-05T04:10:01.158964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:01.168675Z",
     "iopub.status.busy": "2024-09-05T04:10:01.168304Z",
     "iopub.status.idle": "2024-09-05T04:10:17.595165Z",
     "shell.execute_reply": "2024-09-05T04:10:17.594533Z"
    },
    "papermill": {
     "duration": 16.432078,
     "end_time": "2024-09-05T04:10:17.596805",
     "exception": false,
     "start_time": "2024-09-05T04:10:01.164727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Wolf', 'Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Zähringer', 'Scheerer', 'Hoffmann', 'Düe',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'Jäger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:17.604267Z",
     "iopub.status.busy": "2024-09-05T04:10:17.603876Z",
     "iopub.status.idle": "2024-09-05T04:10:18.471142Z",
     "shell.execute_reply": "2024-09-05T04:10:18.470481Z"
    },
    "papermill": {
     "duration": 0.872378,
     "end_time": "2024-09-05T04:10:18.472487",
     "exception": false,
     "start_time": "2024-09-05T04:10:17.600109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K. El-Badry  ->  K. El-Badry  |  ['K. El-Badry']\n",
      "L. Xie  ->  Z.-L. Xie  |  ['L. Xie']\n",
      "I. J. M. Crossfield  ->  I. J. M. Crossfield  |  ['I. J. M. Crossfield']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "J. Li  ->  J. Li  |  ['J. Li']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J. Liu  ->  J. Liu  |  ['J. Liu']\n",
      "K. Jahnke  ->  K. Jahnke  |  ['K. Jahnke']\n",
      "Arxiv has 83 new papers today\n",
      "          6 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [mpia.get_initials(k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.003056,
     "end_time": "2024-09-05T04:10:18.479801",
     "exception": false,
     "start_time": "2024-09-05T04:10:18.476745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:18.487099Z",
     "iopub.status.busy": "2024-09-05T04:10:18.486653Z",
     "iopub.status.idle": "2024-09-05T04:10:22.475283Z",
     "shell.execute_reply": "2024-09-05T04:10:22.474610Z"
    },
    "papermill": {
     "duration": 3.994774,
     "end_time": "2024-09-05T04:10:22.477571",
     "exception": false,
     "start_time": "2024-09-05T04:10:18.482797",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed3df617aa244ec90f3bf771ea50662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2409.02157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.02157... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.02194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.02194... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.02286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/tmp/ipykernel_2676/1211882699.py:51: LatexWarning: 2409.02194 did not run properly\n",
      "'PosixPath' object is not subscriptable\n",
      "  warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.02286... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.02405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.02405..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "  0: tmp_2409.02405/mnras_template.tex, 1,363 lines\n",
      "  1: tmp_2409.02405/main.x.tex, 1,120 lines\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.02734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Found 2 candidates with documentclass definition.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Assuming tmp_2409.02405/mnras_template.tex as main document.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.02734... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2409.02783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2409.02783..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.19/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/tmp/ipykernel_2676/1211882699.py:51: LatexWarning: 2409.02783 did not run properly\n",
      "'PosixPath' object is not subscriptable\n",
      "  warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [mpia.get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.003753,
     "end_time": "2024-09-05T04:10:22.485513",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.481760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.494203Z",
     "iopub.status.busy": "2024-09-05T04:10:22.493810Z",
     "iopub.status.idle": "2024-09-05T04:10:22.510681Z",
     "shell.execute_reply": "2024-09-05T04:10:22.510161Z"
    },
    "papermill": {
     "duration": 0.022777,
     "end_time": "2024-09-05T04:10:22.512019",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.489242",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.02157-b31b1b.svg)](https://arxiv.org/abs/2409.02157) | **An Earth-Mass Planet and a Brown Dwarf in Orbit Around a White Dwarf**  |\n",
       "|| K. Zhang, et al. -- incl., <mark>K. El-Badry</mark> |\n",
       "|*Appeared on*| *2024-09-05*|\n",
       "|*Comments*| *Accepted. 25 pages, 7 figures, 4 tables*|\n",
       "|**Abstract**|            Terrestrial planets born beyond 1-3 AU have been theorized to avoid being engulfed during the red-giant phases of their host stars. Nevertheless, only a few gas-giant planets have been observed around white dwarfs (WDs) -- the end product left behind by a red giant. Here we report on evidence that the lens system that produced the microlensing event KMT-2020-BLG-0414 is composed of a WD orbited by an Earth-mass planet and a brown dwarf (BD) companion, as shown by the non-detection of the lens flux using Keck Adaptive Optics (AO). From microlensing orbital motion constraints, we determine the planet to be a $1.9\\pm0.2$ Earth-mass ($M_\\oplus$) planet at a physical separation of $2.1\\pm0.2$ au from the WD during the event. By considering the system evolutionary history, we determine the BD companion to have a projected separation of 22 au from the WD, and reject an alternative model that places the BD at 0.2 au. Given planetary orbital expansion during the final evolutionary stages of the host star, this Earth-mass planet may have existed in an initial orbit close to 1 au, thereby offering a glimpse into the possible survival of planet Earth in the distant future.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.02286-b31b1b.svg)](https://arxiv.org/abs/2409.02286) | **The Wanderer: Charting WASP-77A b's Formation and Migration Using a System-Wide Inventory of Carbon and Oxygen Abundances**  |\n",
       "|| D. R. Coria, N. Hejazi, <mark>I. J. M. Crossfield</mark>, M. Rhem |\n",
       "|*Appeared on*| *2024-09-05*|\n",
       "|*Comments*| *21 pages, 4 figures, 3 tables Accepted for publication in ApJ (8/14/2024)*|\n",
       "|**Abstract**|            The elemental and isotopic abundances of volatiles like carbon, oxygen, and nitrogen may trace a planet's formation location relative to H$_2$O, CO$_2$, CO, NH$_3$, and N$_2$ \"snowlines\", or the distance from the star at which these volatile elements sublimate. By comparing the C/O and $^{12}$C/$^{13}$C ratios measured in giant exoplanet atmospheres to complementary measurements of their host stars, we can determine whether the planet inherited stellar abundances from formation inside the volatile snowlines, or non-stellar C/O and $^{13}$C enrichment characteristic of formation beyond the snowlines. To date, there are still only a handful of exoplanet systems where we can make a direct comparison of elemental and isotopic CNO abundances between an exoplanet and its host star. Here, we present a $^{12}$C/$^{13}$C abundance analysis for host star WASP-77A (whose hot Jupiter's $^{12}$C/$^{13}$C abundance was recently measured). We use MARCS stellar atmosphere models and the radiative transfer code TurboSpectrum to generate synthetic stellar spectra for isotopic abundance calculations. We find a $^{12}$C/$^{13}$C ratio of $51\\pm 6$ for WASP-77A, which is sub-solar ($\\sim 91$) but may still indicate $^{13}$C-enrichment in its companion planet WASP-77A b ($^{12}$C/$^{13}$C = 26 $\\pm$ 16, previously reported). Together with the inventory of carbon and oxygen abundances in both the host and companion planet, these chemical constraints point to WASP-77A b's formation beyond the H$_2$O and CO$_2$ snowlines and provide chemical evidence for the planet's migration to its current location $\\sim$0.024 AU from its host star.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.02405-b31b1b.svg)](https://arxiv.org/abs/2409.02405) | **Rapid Automatic Multiple Moving Objects Detection Method Based on Feature Extraction from Images with Non-sidereal Tracking**  |\n",
       "|| L. Wang, et al. -- incl., <mark>X. Zhang</mark>, <mark>J. Li</mark> |\n",
       "|*Appeared on*| *2024-09-05*|\n",
       "|*Comments*| **|\n",
       "|**Abstract**|            Optically observing and monitoring moving objects, both natural and artificial, is important to human space security. Non-sidereal tracking can improve the system's limiting magnitude for moving objects, which benefits the surveillance. However, images with non-sidereal tracking include complex background, as well as objects with different brightness and moving mode, posing a significant challenge for accurate multi-object detection in such images, especially in wide field of view (WFOV) telescope images. To achieve a higher detection precision in a higher speed, we proposed a novel object detection method, which combines the source feature extraction and the neural network. First, our method extracts object features from optical images such as centroid, shape, and flux. Then it conducts a naive labeling based on those features to distinguish moving objects from stars. After balancing the labeled data, we employ it to train a neural network aimed at creating a classification model for point-like and streak-like objects. Ultimately, based on the neural network model's classification outcomes, moving objects whose motion modes consistent with the tracked objects are detected via track association, while objects with different motion modes are detected using morphological statistics. The validation, based on the space objects images captured in target tracking mode with the 1-meter telescope at Nanshan, Xinjiang Astronomical Observatory, demonstrates that our method achieves 94.72% detection accuracy with merely 5.02% false alarm rate, and a processing time of 0.66s per frame. Consequently, our method can rapidly and accurately detect objects with different motion modes from wide-field images with non-sidereal tracking.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.02734-b31b1b.svg)](https://arxiv.org/abs/2409.02734) | **Reply to Comment on \"A slightly oblate dark matter halo revealed by a retrograde precessing Galactic disk warp\"**  |\n",
       "|| Y. Huang, et al. -- incl., <mark>J. Liu</mark> |\n",
       "|*Appeared on*| *2024-09-05*|\n",
       "|*Comments*| *4 pages, 2 figures, 1 table, in response to Dehnen et al. (arXiv:2407.06341)*|\n",
       "|**Abstract**|            In this reply, we present a comprehensive analysis addressing the concerns raised by Dehnen et al. (2024) regarding our recent measurement of the disk warp precession using the `motion-picture' method (Huang et al. 2024). We carefully examine the impact of ignoring the twist of the disk warp and the so-called $R$-$\\tau$ correlation on the estimation of the precession rate. The results indicate that the effect is minor and does not exceed the systematic and statistical uncertainties. Using N-body+SPH simulation data, we confirm that the `motion-picture' technique is effective in measuring retrograde precession of disk warp in stellar populations younger than 170 Myr, similar to classical Cepheids. Therefore, the overall conclusions of Huang et al. (2024) remain robust.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.02194-b31b1b.svg)](https://arxiv.org/abs/2409.02194) | **Galaxy clustering in a new implementation of the GAEA semi-analytical galaxy formation model**  |\n",
       "|| F. Fontanot, et al. -- incl., <mark>L. Xie</mark> |\n",
       "|*Appeared on*| *2024-09-05*|\n",
       "|*Comments*| *10 Pages, 5 figures, 2 tables, 1 appendix - A&A submitted*|\n",
       "|**Abstract**|            We present results from the latest version of the GAEA model of galaxy formation coupled with merger trees extracted from the P-Millennium Simulation (PMS), which provides a better mass resolution, a larger volume and assumes cosmological parameters consistent with latest results from the Planck mission. The model includes, at the same time, a treatment for the partition of cold gas into atomic and molecular (H$_2$) components; a better treatment for environmental processes acting on satellite galaxies; an updated modelling of cold gas accretion on Super-Massive Black Hole and relative AGN feedback on the host galaxy. We compare GAEA predictions based on the PMS, with model realizations based on other simulations in the Millennium Suite at different resolution, showing that the new model provides a remarkable consistency in the statistical properties of galaxy populations. We interpret this as due to the interplay between AGN feedback and H$_2$-based SFR (both acting as regulators of the cold gas content). We then compare model predictions with available data for the galaxy 2-point correlation function (2pCF) in the redshift range 0<z<3. We show that GAEA runs are able to correctly recover the main dependencies of the 2pCF as a function of stellar mass (M$_\\star$), star formation activity, HI-content and redshift for M$_\\star$ < 10$^{11}$ M$_\\odot$ galaxies. Our model correctly captures both the distribution of galaxy populations in the Large Scale Structure and the interplay between the main physical processes regulating their baryonic content, both for central and satellite galaxies. At larger stellar masses GAEA underpredicts the 2pCF amplitude, suggesting that model massive galaxies live in less massive dark matter haloes. The model predicts a rather small redshift evolution of the clustering amplitude up to z$\\sim$3, consistent with available observational evidence.         |\n",
       "|<p style=\"color:red\"> **ERROR** </p>| <p style=\"color:red\">latex error 'PosixPath' object is not subscriptable</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2409.02783-b31b1b.svg)](https://arxiv.org/abs/2409.02783) | **Euclid preparation: Determining the weak lensing mass accuracy and precision for galaxy clusters**  |\n",
       "|| E. Collaboration, et al. -- incl., <mark>K. Jahnke</mark> |\n",
       "|*Appeared on*| *2024-09-05*|\n",
       "|*Comments*| **|\n",
       "|**Abstract**|            We investigate the level of accuracy and precision of cluster weak-lensing (WL) masses measured with the \\Euclid data processing pipeline. We use the DEMNUni-Cov $N$-body simulations to assess how well the WL mass probes the true halo mass, and, then, how well WL masses can be recovered in the presence of measurement uncertainties. We consider different halo mass density models, priors, and mass point estimates. WL mass differs from true mass due to, e.g., the intrinsic ellipticity of sources, correlated or uncorrelated matter and large-scale structure, halo triaxiality and orientation, and merging or irregular morphology. In an ideal scenario without observational or measurement errors, the maximum likelihood estimator is the most accurate, with WL masses biased low by $\\langle b_M \\rangle = -14.6 \\pm 1.7 \\, \\%$ on average over the full range $M_\\text{200c} > 5 \\times 10^{13} \\, M_\\odot$ and $z < 1$. Due to the stabilising effect of the prior, the biweight, mean, and median estimates are more precise. The scatter decreases with increasing mass and informative priors significantly reduce the scatter. Halo mass density profiles with a truncation provide better fits to the lensing signal, while the accuracy and precision are not significantly affected. We further investigate the impact of additional sources of systematic uncertainty on the WL mass, namely the impact of photometric redshift uncertainties and source selection, the expected performance of \\Euclid cluster detection algorithms, and the presence of masks. Taken in isolation, we find that the largest effect is induced by non-conservative source selection. This effect can be mostly removed with a robust selection. As a final \\Euclid-like test, we combine systematic effects in a realistic observational setting and find results similar to the ideal case, $\\langle b_M \\rangle = - 15.5 \\pm 2.4 \\, \\%$, under a robust selection.         |\n",
       "|<p style=\"color:red\"> **ERROR** </p>| <p style=\"color:red\">latex error 'PosixPath' object is not subscriptable</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.004564,
     "end_time": "2024-09-05T04:10:22.521167",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.516603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.531283Z",
     "iopub.status.busy": "2024-09-05T04:10:22.531088Z",
     "iopub.status.idle": "2024-09-05T04:10:22.537701Z",
     "shell.execute_reply": "2024-09-05T04:10:22.537147Z"
    },
    "papermill": {
     "duration": 0.013292,
     "end_time": "2024-09-05T04:10:22.539027",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.525735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.549327Z",
     "iopub.status.busy": "2024-09-05T04:10:22.548849Z",
     "iopub.status.idle": "2024-09-05T04:10:22.551882Z",
     "shell.execute_reply": "2024-09-05T04:10:22.551320Z"
    },
    "papermill": {
     "duration": 0.009445,
     "end_time": "2024-09-05T04:10:22.553128",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.543683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.004506,
     "end_time": "2024-09-05T04:10:22.562283",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.557777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.572227Z",
     "iopub.status.busy": "2024-09-05T04:10:22.572033Z",
     "iopub.status.idle": "2024-09-05T04:10:22.575149Z",
     "shell.execute_reply": "2024-09-05T04:10:22.574613Z"
    },
    "papermill": {
     "duration": 0.009471,
     "end_time": "2024-09-05T04:10:22.576373",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.566902",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.00452,
     "end_time": "2024-09-05T04:10:22.585490",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.580970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.595949Z",
     "iopub.status.busy": "2024-09-05T04:10:22.595586Z",
     "iopub.status.idle": "2024-09-05T04:10:22.603251Z",
     "shell.execute_reply": "2024-09-05T04:10:22.602703Z"
    },
    "papermill": {
     "duration": 0.01437,
     "end_time": "2024-09-05T04:10:22.604566",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.590196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.614923Z",
     "iopub.status.busy": "2024-09-05T04:10:22.614511Z",
     "iopub.status.idle": "2024-09-05T04:10:22.628211Z",
     "shell.execute_reply": "2024-09-05T04:10:22.627687Z"
    },
    "papermill": {
     "duration": 0.020219,
     "end_time": "2024-09-05T04:10:22.629451",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.609232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.640125Z",
     "iopub.status.busy": "2024-09-05T04:10:22.639674Z",
     "iopub.status.idle": "2024-09-05T04:10:22.644585Z",
     "shell.execute_reply": "2024-09-05T04:10:22.644051Z"
    },
    "papermill": {
     "duration": 0.011569,
     "end_time": "2024-09-05T04:10:22.645869",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.634300",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.656469Z",
     "iopub.status.busy": "2024-09-05T04:10:22.656044Z",
     "iopub.status.idle": "2024-09-05T04:10:22.660847Z",
     "shell.execute_reply": "2024-09-05T04:10:22.660352Z"
    },
    "papermill": {
     "duration": 0.011468,
     "end_time": "2024-09-05T04:10:22.662097",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.650629",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.672641Z",
     "iopub.status.busy": "2024-09-05T04:10:22.672445Z",
     "iopub.status.idle": "2024-09-05T04:10:22.678600Z",
     "shell.execute_reply": "2024-09-05T04:10:22.677998Z"
    },
    "papermill": {
     "duration": 0.012965,
     "end_time": "2024-09-05T04:10:22.679991",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.667026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-05T04:10:22.690714Z",
     "iopub.status.busy": "2024-09-05T04:10:22.690377Z",
     "iopub.status.idle": "2024-09-05T04:10:22.696600Z",
     "shell.execute_reply": "2024-09-05T04:10:22.696054Z"
    },
    "papermill": {
     "duration": 0.012992,
     "end_time": "2024-09-05T04:10:22.697889",
     "exception": false,
     "start_time": "2024-09-05T04:10:22.684897",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.173108,
   "end_time": "2024-09-05T04:10:22.919020",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2024-09-05T04:09:59.745912",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b0ca4d6d278439e86ed1a4856d775a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2c021c98be034f5b92a890972d41bfa4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2ed3df617aa244ec90f3bf771ea50662": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5d63c30a52c24781b3426d4b777eee38",
        "IPY_MODEL_b99b46f2f26f4e65a04e615cd533ad93",
        "IPY_MODEL_4a4cf60c740c4139a0c59156d6a88a86"
       ],
       "layout": "IPY_MODEL_9fcf5b56050342f3b2afd0c2bf21a660",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4a4cf60c740c4139a0c59156d6a88a86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_532cce07a3c4403baf0ff7e1f0ccb618",
       "placeholder": "​",
       "style": "IPY_MODEL_f035c690e0fe402fb40007f9c1f61ecb",
       "tabbable": null,
       "tooltip": null,
       "value": " 6/6 [00:03&lt;00:00,  1.00it/s]"
      }
     },
     "532cce07a3c4403baf0ff7e1f0ccb618": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53d10c9c0ed948de83a62bdfa64ff007": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d63c30a52c24781b3426d4b777eee38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_957ef66a09aa4a269932be5f522017c4",
       "placeholder": "​",
       "style": "IPY_MODEL_2c021c98be034f5b92a890972d41bfa4",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "957ef66a09aa4a269932be5f522017c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9fcf5b56050342f3b2afd0c2bf21a660": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b99b46f2f26f4e65a04e615cd533ad93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_53d10c9c0ed948de83a62bdfa64ff007",
       "max": 6.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b0ca4d6d278439e86ed1a4856d775a2",
       "tabbable": null,
       "tooltip": null,
       "value": 6.0
      }
     },
     "f035c690e0fe402fb40007f9c1f61ecb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}