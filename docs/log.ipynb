{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.003842,
     "end_time": "2025-06-24T04:21:55.279892",
     "exception": false,
     "start_time": "2025-06-24T04:21:55.276050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:21:55.287860Z",
     "iopub.status.busy": "2025-06-24T04:21:55.287197Z",
     "iopub.status.idle": "2025-06-24T04:21:55.533580Z",
     "shell.execute_reply": "2025-06-24T04:21:55.532842Z"
    },
    "papermill": {
     "duration": 0.251894,
     "end_time": "2025-06-24T04:21:55.535094",
     "exception": false,
     "start_time": "2025-06-24T04:21:55.283200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "import re\n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:21:55.542827Z",
     "iopub.status.busy": "2025-06-24T04:21:55.542215Z",
     "iopub.status.idle": "2025-06-24T04:21:55.550468Z",
     "shell.execute_reply": "2025-06-24T04:21:55.549889Z"
    },
    "papermill": {
     "duration": 0.013241,
     "end_time": "2025-06-24T04:21:55.551593",
     "exception": false,
     "start_time": "2025-06-24T04:21:55.538352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt\n",
    "\n",
    "\n",
    "def clean_non_western_encoded_characters_commands(text: str) -> str:\n",
    "    \"\"\" Remove non-western encoded characters from a string\n",
    "    List may need to grow.\n",
    "    \n",
    "    :param text: the text to clean\n",
    "    :return: the cleaned text\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"(\\\\begin{CJK}{UTF8}{gbsn})(.*?)(\\\\end{CJK})\", r\"\\2\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_initials(name: str) -> str:\n",
    "    \"\"\" Get the short name, e.g., A.-B. FamName\n",
    "    :param name: full name\n",
    "    :returns: initials\n",
    "    \"\"\"\n",
    "    initials = []\n",
    "    # account for non western names often in ()\n",
    "    if '(' in name:\n",
    "        name = clean_non_western_encoded_characters_commands(name)\n",
    "        suffix = re.findall(r\"\\((.*?)\\)\", name)[0]\n",
    "        name = name.replace(f\"({suffix})\", '')\n",
    "    else:\n",
    "        suffix = ''\n",
    "    split = name.split()\n",
    "    for token in split[:-1]:\n",
    "        if '-' in token:\n",
    "            current = '-'.join([k[0] + '.' for k in token.split('-')])\n",
    "        else:\n",
    "            current = token[0] + '.'\n",
    "        initials.append(current)\n",
    "    initials.append(split[-1].strip())\n",
    "    if suffix:\n",
    "        initials.append(f\"({suffix})\")\n",
    "    return ' '.join(initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.00289,
     "end_time": "2025-06-24T04:21:55.557602",
     "exception": false,
     "start_time": "2025-06-24T04:21:55.554712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:21:55.564968Z",
     "iopub.status.busy": "2025-06-24T04:21:55.564436Z",
     "iopub.status.idle": "2025-06-24T04:22:20.247376Z",
     "shell.execute_reply": "2025-06-24T04:22:20.246615Z"
    },
    "papermill": {
     "duration": 24.688158,
     "end_time": "2025-06-24T04:22:20.248735",
     "exception": false,
     "start_time": "2025-06-24T04:21:55.560577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Zähringer', 'Scheerer', 'Hoffmann', 'Düe',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'Jäger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:20.256197Z",
     "iopub.status.busy": "2025-06-24T04:22:20.255783Z",
     "iopub.status.idle": "2025-06-24T04:22:21.124547Z",
     "shell.execute_reply": "2025-06-24T04:22:21.123835Z"
    },
    "papermill": {
     "duration": 0.873554,
     "end_time": "2025-06-24T04:22:21.125680",
     "exception": false,
     "start_time": "2025-06-24T04:22:20.252126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I. J. M. Crossfield  ->  I. J. M. Crossfield  |  ['I. J. M. Crossfield']\n",
      "N. Storm  ->  N. Storm  |  ['N. Storm']\n",
      "P. Eitner  ->  P. Eitner  |  ['P. Eitner']\n",
      "M. Bergemann  ->  M. Bergemann  |  ['M. Bergemann']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n",
      "J.A.  ->  S. Jiao  |  ['Jiao']\n",
      "X. Zhang  ->  X. Zhang  |  ['X. Zhang']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M. Fouesneau  ->  M. Fouesneau  |  ['M. Fouesneau']\n",
      "Arxiv has 89 new papers today\n",
      "          7 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "def robust_call(fn, value, *args, **kwargs):\n",
    "    try:\n",
    "        return fn(value, *args, **kwargs)\n",
    "    except Exception:\n",
    "        return value\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [robust_call(mpia.get_initials, k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.003117,
     "end_time": "2025-06-24T04:22:21.132403",
     "exception": false,
     "start_time": "2025-06-24T04:22:21.129286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:21.139812Z",
     "iopub.status.busy": "2025-06-24T04:22:21.139225Z",
     "iopub.status.idle": "2025-06-24T04:22:55.989637Z",
     "shell.execute_reply": "2025-06-24T04:22:55.988803Z"
    },
    "papermill": {
     "duration": 34.859351,
     "end_time": "2025-06-24T04:22:55.994842",
     "exception": false,
     "start_time": "2025-06-24T04:22:21.135491",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83027ccc297449db45e1b70f3563f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2506.17550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2506.17550..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2506.17711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2506.17711..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.22/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.22/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Found documentclass in tmp_2506.17711/mnras_template.tex\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.22/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'text/raw_data_Ia_cc' from 'tmp_2506.17711/text/raw_data_Ia_cc.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n",
      "/opt/hostedtoolcache/Python/3.9.22/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'text/table' from 'tmp_2506.17711/text/table.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n",
      "/opt/hostedtoolcache/Python/3.9.22/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:414: LatexWarning: Latex injecting: 'text/model' from 'tmp_2506.17711/text/model.tex'\n",
      "  warnings.warn(LatexWarning(f\"Latex injecting: '{ext}' from '{subsource}'\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 bibliographic references in tmp_2506.17711/mnras_template.bbl.\n",
      "Issues with the citations\n",
      "syntax error in line 144: '=' expected\n",
      "Retrieving document from  https://arxiv.org/e-print/2506.17926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2506.17926... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2506.17933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2506.17933... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2506.18277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2506.18277..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 bibliographic references in tmp_2506.18277/HAWC_Performance_Enhanced_by_Machine_Learning_in_Gamma-Hadron_Separation.bbl.\n",
      "Retrieving document from  https://arxiv.org/e-print/2506.18477\n",
      "extracting tarball to tmp_2506.18477... done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2506.18708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2506.18708..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M. Fouesneau  ->  M. Fouesneau  |  ['M. Fouesneau']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 bibliographic references in tmp_2506.18708/aa52614-24.bbl.\n",
      "Issues with the citations\n",
      "syntax error in line 522: '=' expected\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(\"Issues with the citations\")\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.004001,
     "end_time": "2025-06-24T04:22:56.002994",
     "exception": false,
     "start_time": "2025-06-24T04:22:55.998993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.012168Z",
     "iopub.status.busy": "2025-06-24T04:22:56.011800Z",
     "iopub.status.idle": "2025-06-24T04:22:56.031843Z",
     "shell.execute_reply": "2025-06-24T04:22:56.031247Z"
    },
    "papermill": {
     "duration": 0.02592,
     "end_time": "2025-06-24T04:22:56.032909",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.006989",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2506.17711-b31b1b.svg)](https://arxiv.org/abs/2506.17711) | **Current Galactic Chemical Evolution models fail to explain rising Na-abundances of young thick disc stars**  |\n",
       "|| E. K. Owusu, et al. -- incl., <mark>N. Storm</mark>, <mark>P. Eitner</mark>, <mark>M. Bergemann</mark> |\n",
       "|*Appeared on*| *2025-06-24*|\n",
       "|*Comments*| *12 pages, 5 figures, 3 tables*|\n",
       "|**Abstract**|            We recently identified an upturn in [Na/Fe] for the population of Solar-type stars in the Galactic thick disc ($-0.3 < [\\mathrm{Fe/H}] < +0.3$ dex) at super-Solar metallicity in GALactic Archaeology with HERMES (GALAH) data. Here, we investigate the cause of this unexplained Na enrichment between ([Fe/H] $\\sim 0 - 0.6$ dex) using the OMEGA$+$ galactic chemical evolution code. We investigate the increase of [Na/Fe] with four combinations of nucleosynthetic yields from the literature, with source contributions from core-collapse supernovae, asymptotic giant branch stars, and Type Ia supernovae. We focus on two possible causes for the Na-enhancement: the \"metallicity effect\" resulting from core-collapse supernovae at super-Solar metallicity and the contribution of metal-rich AGB stars. We adopt two sets of Type Ia supernova yields with one model assuming only Chandrasekhar-mass explosions, and another assuming only sub-Chandrasekhar-mass explosions. We find that the assumed Type Ia explosion has little effect on the [Na/Fe] Galactic chemical evolution modelling, and all Galactic chemical evolution models tested fail to reproduce the observed [\\mathrm{Na/Fe}] enrichment in the young thick disc population at super-Solar metallicities. Our study indicates a possible \"under-pollution effect\" by SNe Ia, which are the dominant producers of iron, in the Galactic disc's Solar-type star population. These findings provide a step forward toward understanding the origin of the unexplained sodium enrichment at super-Solar metallicities in the Galactic disc.         |"
      ],
      "text/plain": [
       "[2506.17711] Current Galactic Chemical Evolution models fail to explain rising Na-abundances of young thick disc stars\n",
       "\tE. K. Owusu, et al. -- incl., <mark>N. Storm</mark>, <mark>P. Eitner</mark>, <mark>M. Bergemann</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2506.18277-b31b1b.svg)](https://arxiv.org/abs/2506.18277) | **HAWC Performance Enhanced by Machine Learning in Gamma-Hadron Separation**  |\n",
       "|| R. Alfaro, et al. -- incl., <mark>J.A.</mark> |\n",
       "|*Appeared on*| *2025-06-24*|\n",
       "|*Comments*| **|\n",
       "|**Abstract**|            Improving gamma-hadron separation is one of the most effective ways to enhance the performance of ground-based gamma-ray observatories. With over a decade of continuous operation, the High-Altitude Water Cherenkov (HAWC) Observatory has contributed significantly to high-energy astrophysics. To further leverage its rich dataset, we introduce a machine learning approach for gamma-hadron separation. A Multilayer Perceptron shows the best performance, surpassing traditional and other Machine Learning based methods. This approach shows a notable improvement in the detector's sensitivity, supported by results from both simulated and real HAWC data. In particular, it achieves a 19\\% increase in significance for the Crab Nebula, commonly used as a benchmark. These improvements highlight the potential of machine learning to significantly enhance the performance of HAWC and provide a valuable reference for ground-based observatories, such as Large High Altitude Air Shower Observatory (LHAASO) and the upcoming Southern Wide-field Gamma-ray Observatory (SWGO).         |"
      ],
      "text/plain": [
       "[2506.18277] HAWC Performance Enhanced by Machine Learning in Gamma-Hadron Separation\n",
       "\tR. Alfaro, et al. -- incl., <mark>J.A.</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2506.18708-b31b1b.svg)](https://arxiv.org/abs/2506.18708) | **The completeness of the open cluster census towards the Galactic anticentre**  |\n",
       "|| E. L. Hunt, et al. -- incl., <mark>M. Fouesneau</mark> |\n",
       "|*Appeared on*| *2025-06-24*|\n",
       "|*Comments*| *18 pages, 13 figures. Accepted in A&A*|\n",
       "|**Abstract**|            Open clusters have long been used as tracers of Galactic structure. However, without a selection function to describe the completeness of the cluster census, it is difficult to quantitatively interpret their distribution. We create a method to empirically determine the selection function of a Galactic cluster catalogue. We test it by investigating the completeness of the cluster census in the outer Milky Way, where old and young clusters exhibit different spatial distributions. We develop a method to generate realistic mock clusters as a function of their parameters, in addition to accounting for Gaia's selection function and astrometric errors. We then inject mock clusters into Gaia DR3 data, and attempt to recover them in a blind search using HDBSCAN. We find that the main parameters influencing cluster detectability are mass, extinction, and distance. Age also plays an important role, making older clusters harder to detect due to their fainter luminosity function. High proper motions also improve detectability. After correcting for these selection effects, we find that old clusters are $2.97\\pm0.11$ times more common at a Galactocentric radius of 13~kpc than in the solar neighbourhood -- despite positive detection biases in their favour, such as hotter orbits or a higher scale height. The larger fraction of older clusters in the outer Galaxy cannot be explained by an observational bias, and must be a physical property of the Milky Way: young outer-disc clusters are not forming in the outer Galaxy, or at least not with sufficient masses to be identified as clusters in Gaia DR3. We predict that in this region, more old clusters than young ones remain to be discovered. The current presence of old, massive outer-disc clusters could be explained by radial heating and migration, or alternatively by a lower cluster destruction rate in the anticentre.         |"
      ],
      "text/plain": [
       "[2506.18708] The completeness of the open cluster census towards the Galactic anticentre\n",
       "\tE. L. Hunt, et al. -- incl., <mark>M. Fouesneau</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2506.17550-b31b1b.svg)](https://arxiv.org/abs/2506.17550) | **A High Geometric Albedo for LTT9779b Points Towards a Metal-rich Atmosphere and Silicate Clouds**  |\n",
       "|| S. Saha, et al. -- incl., <mark>I. J. M. Crossfield</mark> |\n",
       "|*Appeared on*| *2025-06-24*|\n",
       "|*Comments*| *18 pages, 11 figures, 3 tables, Accepted for publication in A&A*|\n",
       "|**Abstract**|            Aims: In this work, we aim to confirm the high albedo of the benchmark ultrahot Neptune LTT9779b using 20 secondary eclipse measurements of the planet observed with CHEOPS. In addition, we perform a search for variability in the reflected light intensity of the planet as a function of time. Methods: First, we used the TESS follow-up data of LTT9779b from three sectors (2, 29, and 69) to remodel the transit signature and estimate an updated set of transit and ephemeris parameters, which were directly used in the modeling of the secondary eclipse lightcurves. This involved a critical noise-treatment algorithm, including sophisticated techniques such as wavelet denoising and Gaussian Process (GP) regression, to constrain noise levels from various sources. In addition to using the officially released reduced aperture photometry data from CHEOPS DRP, we also reduced the raw data using an independent PSF photometry pipeline, known as PIPE, to verify the robustness of our analysis. The extracted secondary eclipse lightcurves were modeled using the PYCHEOPS package, where we have detrended the background noise correlated with the spacecraft roll angle, originating from the inhomogeneous and asymmetric shape of the CHEOPS point spread function, using an N-order glint function. Results: Our independent lightcurve analyses have resulted in consistent estimations of the eclipse depths, with values of 89.9$\\pm$13.7 ppm for the DRP analysis and 85.2$\\pm$13.1 ppm from PIPE, indicating a high degree of statistical agreement. Adopting the DRP value yields a highly constrained geometric albedo of 0.73$\\pm$0.11. No significant eclipse depth variability is detected down to a level of $\\sim$37 ppm. Conclusions: Our results confirm that LTT9779b exhibits a strikingly high optical albedo, which substantially reduces the internal energy budget of the planet compared to more opaque...         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2506.17926-b31b1b.svg)](https://arxiv.org/abs/2506.17926) | **Cosmic Distance Duality Relation with DESI DR2 and Transparency**  |\n",
       "|| <mark>X. Zhang</mark>, et al. |\n",
       "|*Appeared on*| *2025-06-24*|\n",
       "|*Comments*| **|\n",
       "|**Abstract**|            The Cosmic Distance Duality Relation (CDDR), a fundamental assumption in modern cosmology, posits a direct link between angular diameter distance and luminosity distance. This study presents a comprehensive, model-independent, and data-driven test of the CDDR using a combination of cosmological observations, including Supernovae (SN), Baryon Acoustic Oscillations (BAO), and Hubble parameter ($H(z)$) measurements. We employ both Gaussian Process Regression (GPR) and a novel Compressed Point (CPI) method for reconstructing the CDDR, alongside four distinct parameterizations for potential deviations. Nuisance parameters, such as the supernova absolute magnitude and BAO scale, are rigorously handled via both joint numerical fitting (Method I) and analytic marginalization (Method II). Our findings reveal that while direct reconstruction of the CDDR exhibits no significant deviation (less than 1-$\\sigma$) under specific prior assumptions, a notable departure emerges when the SH0ES prior is incorporated, suggesting a systematic influence from the Hubble constant tension. Independently, our parameterized analysis corroborates the consistency of CDDR and confirms the equivalence of the two constraint methodologies. We also find no significant evidence for cosmic opacity. A comparative assessment of reconstruction techniques indicates that GPR generally yields higher precision. These results emphasize the critical role of prior choices and statistical methods in CDDR analyses, providing valuable insights into fundamental cosmological principles and the ongoing Hubble tension.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2506.17933-b31b1b.svg)](https://arxiv.org/abs/2506.17933) | **Holographic dark energy models in $f(Q,T)$ gravity and cosmic constraint**  |\n",
       "|| <mark>X. Zhang</mark>, et al. |\n",
       "|*Appeared on*| *2025-06-24*|\n",
       "|*Comments*| **|\n",
       "|**Abstract**|            In this work, we propose a new model that combines holographic dark energy with modified gravity $f(Q,T)$ to explore a possible explanation for the accelerated expansion of the universe. We incorporate the holographic principle into non-metric gravity with non-minimal matter coupling and introduce the Barrow holographic dark energy model to account for a tighter corrections, allowing for a more generalized discussion. Furthermore, we perform parameter estimation using the latest observational data, including Type Ia supernova, BAO and Hubble parameter direct measurements. Our results show that the model provides a theoretical framework to describe late-time cosmic evolution and the universe's accelerated expansion. Despite the additional complexity introduced, the model offers a viable approach for investigating dark energy within modified gravity theories.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2506.18477-b31b1b.svg)](https://arxiv.org/abs/2506.18477) | **Cosmic Sign-Reversal: Non-Parametric Reconstruction of Interacting Dark Energy with DESI DR2**  |\n",
       "|| Y.-H. Li, <mark>X. Zhang</mark> |\n",
       "|*Appeared on*| *2025-06-24*|\n",
       "|*Comments*| *8 pages, 4 figures*|\n",
       "|**Abstract**|            A direct interaction between dark energy and dark matter provides a natural and important extension to the standard $\\Lambda$CDM cosmology. We perform a non-parametric reconstruction of the vacuum energy ($w=-1$) interacting with cold dark matter using the cosmological data from DESI DR2, Planck CMB, and three SNIa samples (PP, DESY5, and Union3). By discretizing the coupling function $\\beta(z)$ into 20 redshift bins and assuming a Gaussian smoothness prior, we reconstruct $\\beta(z)$ without assuming any specific parameterization. The mean reconstructed $\\beta(z)$ changes sign during cosmic evolution, indicating an energy transfer from cold dark matter to dark energy at early times and a reverse flow at late times. At high redshifts, $\\beta(z)$ shows a $\\sim 2\\sigma$ deviation from $\\Lambda$CDM. At low redshifts, the results depend on the SNIa sample: CMB+DESI and CMB+DESI+PP yield $\\beta(z)$ consistent with zero within $2\\sigma$, while CMB+DESI+DESY5 and CMB+DESI+Union3 prefer negative $\\beta$ at $\\sim2\\sigma$. Both $\\chi^2$ tests and Bayesian analyses favor the $\\beta(z)$ model, with CMB+DESI DR2+DESY5 showing the most significant support through the largest improvement in goodness of fit ($\\Delta\\chi^2_{\\rm MAP}=-17.76$) and strongest Bayesian evidence ($\\ln\\mathcal{B} = 5.98 \\pm 0.69$). Principal component analysis reveals that the data effectively constrain three additional degrees of freedom in the $\\beta(z)$ model, accounting for most of the improvement in goodness of fit. Our results demonstrate that the dynamical dark energy preference in current data can be equally well explained by such a sign-reversal interacting dark energy, highlighting the need for future observations to break this degeneracy.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.004732,
     "end_time": "2025-06-24T04:22:56.043304",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.038572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.054255Z",
     "iopub.status.busy": "2025-06-24T04:22:56.053591Z",
     "iopub.status.idle": "2025-06-24T04:22:56.061146Z",
     "shell.execute_reply": "2025-06-24T04:22:56.060519Z"
    },
    "papermill": {
     "duration": 0.014146,
     "end_time": "2025-06-24T04:22:56.062198",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.048052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.073321Z",
     "iopub.status.busy": "2025-06-24T04:22:56.072858Z",
     "iopub.status.idle": "2025-06-24T04:22:56.084256Z",
     "shell.execute_reply": "2025-06-24T04:22:56.083715Z"
    },
    "papermill": {
     "duration": 0.018142,
     "end_time": "2025-06-24T04:22:56.085419",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.067277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found figures ['tmp_2506.17711/./figures/figure5.png', 'tmp_2506.17711/./figures/figure2.png', 'tmp_2506.17711/./figures/figure1.png']\n",
      "copying  tmp_2506.17711/./figures/figure5.png to _build/html/\n",
      "copying  tmp_2506.17711/./figures/figure2.png to _build/html/\n",
      "copying  tmp_2506.17711/./figures/figure1.png to _build/html/\n",
      "exported in  _build/html/2506.17711.md\n",
      "    + _build/html/tmp_2506.17711/./figures/figure5.png\n",
      "    + _build/html/tmp_2506.17711/./figures/figure2.png\n",
      "    + _build/html/tmp_2506.17711/./figures/figure1.png\n",
      "found figures ['tmp_2506.18277/./efficiency_C0_effi.png', 'tmp_2506.18277/./efficiency_C1_effi.png', 'tmp_2506.18277/./efficiency_C0_qfactor.png', 'tmp_2506.18277/./efficiency_C1_qfactor.png', 'tmp_2506.18277/./roc_curve_c0_log_blind2.png', 'tmp_2506.18277/./roc_curve_c1_log_blind2.png']\n",
      "copying  tmp_2506.18277/./efficiency_C0_effi.png to _build/html/\n",
      "copying  tmp_2506.18277/./efficiency_C1_effi.png to _build/html/\n",
      "copying  tmp_2506.18277/./efficiency_C0_qfactor.png to _build/html/\n",
      "copying  tmp_2506.18277/./efficiency_C1_qfactor.png to _build/html/\n",
      "copying  tmp_2506.18277/./roc_curve_c0_log_blind2.png to _build/html/\n",
      "copying  tmp_2506.18277/./roc_curve_c1_log_blind2.png to _build/html/\n",
      "exported in  _build/html/2506.18277.md\n",
      "    + _build/html/tmp_2506.18277/./efficiency_C0_effi.png\n",
      "    + _build/html/tmp_2506.18277/./efficiency_C1_effi.png\n",
      "    + _build/html/tmp_2506.18277/./efficiency_C0_qfactor.png\n",
      "    + _build/html/tmp_2506.18277/./efficiency_C1_qfactor.png\n",
      "    + _build/html/tmp_2506.18277/./roc_curve_c0_log_blind2.png\n",
      "    + _build/html/tmp_2506.18277/./roc_curve_c1_log_blind2.png\n",
      "found figures ['tmp_2506.18708/./eh_r_z_with_ocs.png', 'tmp_2506.18708/./shap_beeswarm.png', 'tmp_2506.18708/./shap_pmdec.png', 'tmp_2506.18708/./XY_RgcZ_threepanels_2025.png']\n",
      "copying  tmp_2506.18708/./eh_r_z_with_ocs.png to _build/html/\n",
      "copying  tmp_2506.18708/./shap_beeswarm.png to _build/html/\n",
      "copying  tmp_2506.18708/./shap_pmdec.png to _build/html/\n",
      "copying  tmp_2506.18708/./XY_RgcZ_threepanels_2025.png to _build/html/\n",
      "exported in  _build/html/2506.18708.md\n",
      "    + _build/html/tmp_2506.18708/./eh_r_z_with_ocs.png\n",
      "    + _build/html/tmp_2506.18708/./shap_beeswarm.png\n",
      "    + _build/html/tmp_2506.18708/./shap_pmdec.png\n",
      "    + _build/html/tmp_2506.18708/./XY_RgcZ_threepanels_2025.png\n"
     ]
    }
   ],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.004903,
     "end_time": "2025-06-24T04:22:56.095469",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.090566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.107165Z",
     "iopub.status.busy": "2025-06-24T04:22:56.106536Z",
     "iopub.status.idle": "2025-06-24T04:22:56.114147Z",
     "shell.execute_reply": "2025-06-24T04:22:56.113555Z"
    },
    "papermill": {
     "duration": 0.014604,
     "end_time": "2025-06-24T04:22:56.115216",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.100612",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\thebibliography}{\\DeclareRobustCommand{\\VAN}[3]{##3}\\VANthebibliography}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# Current Galactic Chemical Evolution models fail to explain rising Na-abundances of young thick disc stars\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2506.17711-b31b1b.svg)](https://arxiv.org/abs/2506.17711)<mark>Appeared on: 2025-06-24</mark> -  _12 pages, 5 figures, 3 tables_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "E. K. Owusu, et al. -- incl., <mark>N. Storm</mark>, <mark>P. Eitner</mark>, <mark>M. Bergemann</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** We recently identified an upturn in [ Na/Fe ] for the population of Solar-type stars in the Galactic thick disc ( $-0.3 < \\mathrm{[Fe/H]} < +0.3$ dex) at super-Solar metallicity in GALactic Archaeology with HERMES (GALAH) data. Here, we investigate the cause of this unexplained Na enrichment between ( [ Fe/H ] $\\approx 0$ -- $0.6$ dex) using the OMEGA $+$ galactic chemical evolution code. We investigate the increase of [ Na/Fe ] with four combinations of nucleosynthetic yields from the literature, with source contributions from core-collapse supernovae, asymptotic giant branch stars, and Type Ia supernovae. We focus on two possible causes for the Na-enhancement: the `metallicity effect’ resulting from core-collapse supernovae at super-Solar metallicity and the contribution of metal-rich AGB stars. We adopt two sets of Type Ia supernova yields with one model assuming only Chandrasekhar-mass explosions, and another assuming only sub-Chandrasekhar-mass explosions. We find that the assumed Type Ia explosion has little effect on the [ Na/Fe ] Galactic Chemical Evolution modelling, and all Galactic chemical evolution models tested fail to reproduce the observed [ Na/Fe ] enrichment in the young thick disc population at super-Solar metallicities. Our study indicates a possible `under-pollution effect' by SNe Ia, which are the dominant producers of iron, in the Galactic disc's Solar-type star population. These findings provide a step forward toward understanding the origin of the unexplained sodium enrichment at super-Solar metallicities in the Galactic disc.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2506.17711/./figures/figure5.png\" alt=\"Fig4\" width=\"100%\"/>\n",
       "\n",
       "**Figure 4. -** Panels (a)-(f) are the [Fe/H]-age, age-[Fe/H], [Fe/H]-[Na/Fe], age-[Na/Fe], [Fe/H]-[Na/H] and age-[Na/H] planes, produced by our adjusted GCE code parameters for this study. `Age' here refers to stellar ages. The grey bins are Solar-type thick disc stars selected from the GALAH DR3 catalogue using Equation \\ref{eq:Z_range}, with the yellower area having a higher concentration of stars. Solid lines represent GCE models in which all SN Ia explosions are assumed to be from Chandrasekhar mass WDs, while for the dashed lines, sub-Chandrasekhar mass explosions from WD mergers are assumed. We defined the model label in Table \\ref{tab:model}. SN Ia contribution is based on the two-exploding white dwarf from \\citep{Pakmor2022} and delayed detonation for Chandrasekhar-mass white dwarfs, as described in \\citep{Seitenzahl2013}. (*fig:figure5*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2506.17711/./figures/figure2.png\" alt=\"Fig1\" width=\"100%\"/>\n",
       "\n",
       "**Figure 1. -** Normalised Na ($^{23}$Na) production ratios as a function of stellar metallicity (Z) for massive stars with initial masses 15 and 20 M$_{\\odot}$. The models shown are massive star yields from \\citet[WW95, blue triangles]{Woosley1995}, \\citet[Nomoto13, red circles]{Nomoto2013} and \\citet[LC18, orange squares]{Limongi2018}. The normalised production ratio (y-axis: Normalised $^{23}$Na Production Ratio) is calculated for each model by dividing the raw $^{23}$Na yield at each metallicity by the minimum $^{23}$Na obtained across all metallicities for that specific model. This normalisation highlights the relative change in Na production as a function of metallicity for each set of stellar models. (*fig:figure2*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2506.17711/./figures/figure1.png\" alt=\"Fig2\" width=\"100%\"/>\n",
       "\n",
       "**Figure 2. -** [Na/Fe] as a function of metallicity [Fe/H] for the sample of Solar-type stars from GALAH DR3 used in this work (see Section \\ref{sec:data}). The left panel (a) shows the distribution coloured by stellar age, illustrating the median stellar age in (Gyr) at each ([Fe/H], [Na/Fe]) bin. The right panel displays the same distribution, highlighting the standard deviation in stellar age within the corresponding bins. The Bayesian Stellar Parameters Estimator (BSTEP) was used to compute the stellar ages. The Solar abundance position is marked by the symbol $(\\odot)$ at [Fe/H], [Na/Fe]$= (0,0)$. (*fig:figure1*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2506.17711\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\vdag}{(v)^\\dagger}$\n",
       "$\\newcommand$\n",
       "$\\newcommand$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# HAWC Performance Enhanced by Machine Learning in Gamma-Hadron Separation\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2506.18277-b31b1b.svg)](https://arxiv.org/abs/2506.18277)<mark>Appeared on: 2025-06-24</mark> - \n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "R. Alfaro, et al. -- incl., <mark>J.A.</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** Improving gamma-hadron separation is one of the most effective ways to enhance the performance of ground-based gamma-ray observatories. With over a decade of continuous operation, the High-Altitude Water Cherenkov (HAWC) Observatory has contributed significantly to high-energy astrophysics. To further leverage its rich dataset, we introduce a machine learning approach for gamma-hadron separation. A Multilayer Perceptron shows the best performance, surpassing traditional and other Machine Learning based methods. This approach shows a notable improvement in the detector's sensitivity, supported by results from both simulated and real HAWC data. In particular, it achieves a 19 \\% increase in significance for the Crab Nebula, commonly used as a benchmark. These improvements highlight the potential of machine learning to significantly enhance the performance of HAWC and provide a valuable reference for ground-based observatories, such as Large High Altitude Air Shower Observatory (LHAASO) and the upcoming Southern Wide-field Gamma-ray Observatory (SWGO).\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2506.18277/./efficiency_C0_effi.png\" alt=\"Fig1.1\" width=\"50%\"/><img src=\"tmp_2506.18277/./efficiency_C1_effi.png\" alt=\"Fig1.2\" width=\"50%\"/>\n",
       "\n",
       "**Figure 1. -** Gamma-ray efficiencies (dashed lines) and hadron efficiencies (solid lines) as a function of fHit bins for different classification methods. (a): Results for on-array events. (b): Results for off-array events. Classification methods compared include SC, MLP, CNN, and BDT. (*fig:eff*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2506.18277/./efficiency_C0_qfactor.png\" alt=\"Fig2.1\" width=\"50%\"/><img src=\"tmp_2506.18277/./efficiency_C1_qfactor.png\" alt=\"Fig2.2\" width=\"50%\"/>\n",
       "\n",
       "**Figure 2. -** Q-factor as a function of fHit bins for different classification methods. (a): Results for on-array events. (b): Results for off-array events. Classification methods compared include SC, MLP, CNN, and BDT. Q-factors improve with increasing fHit bins, with notable differences across methods, especially in high-fHit bins. (*fig:qfactor*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2506.18277/./roc_curve_c0_log_blind2.png\" alt=\"Fig3.1\" width=\"50%\"/><img src=\"tmp_2506.18277/./roc_curve_c1_log_blind2.png\" alt=\"Fig3.2\" width=\"50%\"/>\n",
       "\n",
       "**Figure 3. -** Receiver Operating Characteristic (ROC) curves and Area Under the Curve (AUC) values for MLP model performance across different fHit bins. Left panel (a): Results for on-array events. Right panel (b): Results for off-array events. Each curve corresponds to a specific fHit bin, labeled from B0 to B10. The MLP model exhibits progressively better classification performance with increasing fHit, as indicated by higher AUC values. (*fig:ROC_curve*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2506.18277\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# The completeness of the open cluster census towards the Galactic anticentre\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2506.18708-b31b1b.svg)](https://arxiv.org/abs/2506.18708)<mark>Appeared on: 2025-06-24</mark> -  _18 pages, 13 figures. Accepted in A&A_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "E. L. Hunt, et al. -- incl., <mark>M. Fouesneau</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** Open clusters have long been used as tracers of Galactic structure. However, without a selection function to describe the completeness of the cluster census, it is difficult to quantitatively interpret their distribution. We create a method to empirically determine the selection function of a Galactic cluster catalogue. We test it by investigating the completeness of the cluster census in the outer Milky Way, where old and young clusters exhibit different spatial distributions. We develop a method to generate realistic mock clusters as a function of their parameters, in addition to accounting for $*Gaia*$ 's selection function and astrometric errors. We then inject mock clusters into _Gaia_ DR3 data, and attempt to recover them in a blind search using HDBSCAN. We find that the main parameters influencing cluster detectability are mass, extinction, and distance. Age also plays an important role, making older clusters harder to detect due to their fainter luminosity function. High proper motions also improve detectability. After correcting for these selection effects, we find that old clusters are $2.97\\pm0.11$ times more common at a Galactocentric radius of 13 kpc than in the solar neighbourhood -- despite positive detection biases in their favour, such as hotter orbits or a higher scale height. The larger fraction of older clusters in the outer Galaxy cannot be explained by an observational bias, and must be a physical property of the Milky Way: young outer-disc clusters are not forming in the outer Galaxy, or at least not with sufficient masses to be identified as clusters in $*Gaia*$ DR3. We predict that in this region, more old clusters than young ones remain to be discovered. The current presence of old, massive outer-disc clusters could be explained by radial heating and migration, or alternatively by a lower cluster destruction rate in the anticentre.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2506.18708/./eh_r_z_with_ocs.png\" alt=\"Fig12\" width=\"100%\"/>\n",
       "\n",
       "**Figure 12. -** Fraction of simulated clusters recovered as a function of $R_\\text{GC}$ and $Z$ divided into multiple different mass and ages ranges, and compared against the distribution of OCs in HR24 within those ranges. Each row shows clusters in a different mass range, indicated by the label on each subplot. The subplots in the left column show young clusters with $\\log t < 8.5$, while subplots in the right column show old clusters with $\\log t > 8.5$. Although proper motions only have a small impact on cluster detectability, we nevertheless only show the detection results of simulated clusters with proper motions $|\\mu_{\\alpha^*}| < 2.5$ and $|\\mu_\\delta| < 2.5$, providing a slightly more conservative estimate on cluster detectability at these locations. (*fig:r_z_overall_detections*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2506.18708/./shap_beeswarm.png\" alt=\"Fig7.1\" width=\"50%\"/><img src=\"tmp_2506.18708/./shap_pmdec.png\" alt=\"Fig7.2\" width=\"50%\"/>\n",
       "\n",
       "**Figure 7. -**  SHAP feature importance values for the CST predictor. *Top:* Beeswarm plot where each cluster in the validation dataset is shown as a dot. Each row corresponds to the impact of a different input parameter. The colour coding corresponds to whether it was a high or low value of the parameter. The $x$ axis shows the final impact on the output of the model, which is how much the CST is changed for that given cluster and that given parameter value. For example: for cluster mass, low mass values (blue) correspond to a much lower SHAP/CST, whereas high mass values (red) correspond to a much higher SHAP/CST. On the other hand, most age values have minimal impact on CST, although high ages significantly reduce it. *Bottom:* SHAP value at a given \\texttt{pmdec} as a function of \\texttt{pmdec} and shown for all clusters in the validation dataset. Colour coding shows the Galactic longitude, $l$. (*fig:cst_shap*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2506.18708/./XY_RgcZ_threepanels_2025.png\" alt=\"Fig8\" width=\"100%\"/>\n",
       "\n",
       "**Figure 8. -**  Spatial distribution of high-certainty clusters (\\texttt{CST}$>$4) from \\citet{2023A&A...673A.114H}. Ages are taken from \\citet{2024AJ....167...12C} as they are more accurate for old clusters (see Sect. \\ref{sec:catalogues} for discussion).\n",
       "    *Top left*: Histogram of cluster galactocentric radii divided into young ($\\log t < 8.5$, blue) and old ($\\log t > 8.5$, red) clusters and with a 200 pc bin width.\n",
       "    *Bottom left*: Distribution of the same young and old clusters but in terms of altitude $Z$ and Galactocentric radius $R_{\\mathrm{GC}}$, assuming $R_{\\mathrm{GC},\\odot}$=8.2 kpc.\n",
       "    *Bottom right*: Projection of these clusters in heliocentric Galactic co-ordinates, with the Sun located at ($X$,$Y$)=(0,0). The dotted lines indicate Galactocentric radii from 10 to 18 kpc. The shaded area is the region investigated in this study ($140^{\\circ} \\leq \\ell \\leq 240^{\\circ}$ starting 2 kpc from the Sun) . In both lower panels, the cross indicates the cluster Saurer 1, visible in _Gaia_ data but not recovered in the blind search of \\citet{2023A&A...673A.114H}. (*fig:XY_RgcZ*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2506.18708\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.005349,
     "end_time": "2025-06-24T04:22:56.126571",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.121222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.138779Z",
     "iopub.status.busy": "2025-06-24T04:22:56.138469Z",
     "iopub.status.idle": "2025-06-24T04:22:56.150009Z",
     "shell.execute_reply": "2025-06-24T04:22:56.149384Z"
    },
    "papermill": {
     "duration": 0.018963,
     "end_time": "2025-06-24T04:22:56.151069",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.132106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.163833Z",
     "iopub.status.busy": "2025-06-24T04:22:56.163522Z",
     "iopub.status.idle": "2025-06-24T04:22:56.191315Z",
     "shell.execute_reply": "2025-06-24T04:22:56.190636Z"
    },
    "papermill": {
     "duration": 0.035546,
     "end_time": "2025-06-24T04:22:56.192488",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.156942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.205851Z",
     "iopub.status.busy": "2025-06-24T04:22:56.205528Z",
     "iopub.status.idle": "2025-06-24T04:22:56.211186Z",
     "shell.execute_reply": "2025-06-24T04:22:56.210584Z"
    },
    "papermill": {
     "duration": 0.01357,
     "end_time": "2025-06-24T04:22:56.212250",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.198680",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.225792Z",
     "iopub.status.busy": "2025-06-24T04:22:56.225242Z",
     "iopub.status.idle": "2025-06-24T04:22:56.231053Z",
     "shell.execute_reply": "2025-06-24T04:22:56.230296Z"
    },
    "papermill": {
     "duration": 0.01375,
     "end_time": "2025-06-24T04:22:56.232155",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.218405",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.245137Z",
     "iopub.status.busy": "2025-06-24T04:22:56.244645Z",
     "iopub.status.idle": "2025-06-24T04:22:56.252601Z",
     "shell.execute_reply": "2025-06-24T04:22:56.251932Z"
    },
    "papermill": {
     "duration": 0.015491,
     "end_time": "2025-06-24T04:22:56.253744",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.238253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:22:56.266808Z",
     "iopub.status.busy": "2025-06-24T04:22:56.266091Z",
     "iopub.status.idle": "2025-06-24T04:22:56.273336Z",
     "shell.execute_reply": "2025-06-24T04:22:56.272599Z"
    },
    "papermill": {
     "duration": 0.014818,
     "end_time": "2025-06-24T04:22:56.274386",
     "exception": false,
     "start_time": "2025-06-24T04:22:56.259568",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 62.132519,
   "end_time": "2025-06-24T04:22:56.496528",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2025-06-24T04:21:54.364009",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2f9f9d4ffbd943279df13b04d78d59c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "38ff0ff9bf624941904417a234b56ecb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b11b438e9d4b4e37a65f8dd8cebc3b72",
       "placeholder": "​",
       "style": "IPY_MODEL_850ea4b5118f447a9701f1a1d05bfb58",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "39f75f2f01e449da93e46ddbeafea1c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5f9ded1cb0824eb69fa64de3ab7c51fb",
       "max": 7.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2f9f9d4ffbd943279df13b04d78d59c7",
       "tabbable": null,
       "tooltip": null,
       "value": 7.0
      }
     },
     "422b634e3b44466abd372f39423839ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f9ded1cb0824eb69fa64de3ab7c51fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64583bd67bf740bca87b2aeb6205910c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "850ea4b5118f447a9701f1a1d05bfb58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aa5e36c7baec4b8aa138bc0371ccea86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b11b438e9d4b4e37a65f8dd8cebc3b72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5d570d170a0417786e634d19fa52ead": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_422b634e3b44466abd372f39423839ad",
       "placeholder": "​",
       "style": "IPY_MODEL_64583bd67bf740bca87b2aeb6205910c",
       "tabbable": null,
       "tooltip": null,
       "value": " 7/7 [00:34&lt;00:00,  7.15s/it]"
      }
     },
     "f83027ccc297449db45e1b70f3563f72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_38ff0ff9bf624941904417a234b56ecb",
        "IPY_MODEL_39f75f2f01e449da93e46ddbeafea1c8",
        "IPY_MODEL_c5d570d170a0417786e634d19fa52ead"
       ],
       "layout": "IPY_MODEL_aa5e36c7baec4b8aa138bc0371ccea86",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}