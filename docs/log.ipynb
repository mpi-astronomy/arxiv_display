{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bcb855",
   "metadata": {
    "papermill": {
     "duration": 0.00388,
     "end_time": "2024-10-02T04:10:34.892643",
     "exception": false,
     "start_time": "2024-10-02T04:10:34.888763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MPIA Arxiv on Deck 2\n",
    "\n",
    "Contains the steps to produce the paper extractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0d6e11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:10:34.900296Z",
     "iopub.status.busy": "2024-10-02T04:10:34.899783Z",
     "iopub.status.idle": "2024-10-02T04:10:35.301533Z",
     "shell.execute_reply": "2024-10-02T04:10:35.300919Z"
    },
    "papermill": {
     "duration": 0.40701,
     "end_time": "2024-10-02T04:10:35.302971",
     "exception": false,
     "start_time": "2024-10-02T04:10:34.895961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from PIL import Image \n",
    "import re\n",
    "\n",
    "# requires arxiv_on_deck_2\n",
    "\n",
    "from arxiv_on_deck_2.arxiv2 import (get_new_papers, \n",
    "                                    get_paper_from_identifier,\n",
    "                                    retrieve_document_source, \n",
    "                                    get_markdown_badge)\n",
    "from arxiv_on_deck_2 import (latex,\n",
    "                             latex_bib,\n",
    "                             mpia,\n",
    "                             highlight_authors_in_list)\n",
    "\n",
    "# Sometimes images are really big\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aa9d44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:10:35.310581Z",
     "iopub.status.busy": "2024-10-02T04:10:35.310071Z",
     "iopub.status.idle": "2024-10-02T04:10:35.318125Z",
     "shell.execute_reply": "2024-10-02T04:10:35.317557Z"
    },
    "papermill": {
     "duration": 0.012924,
     "end_time": "2024-10-02T04:10:35.319229",
     "exception": false,
     "start_time": "2024-10-02T04:10:35.306305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some useful definitions.\n",
    "\n",
    "class AffiliationWarning(UserWarning):\n",
    "    pass\n",
    "\n",
    "class AffiliationError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def validation(source: str):\n",
    "    \"\"\"Raises error paper during parsing of source file\n",
    "    \n",
    "    Allows checks before parsing TeX code.\n",
    "    \n",
    "    Raises AffiliationWarning\n",
    "    \"\"\"\n",
    "    check = mpia.affiliation_verifications(source, verbose=True)\n",
    "    if check is not True:\n",
    "        raise AffiliationError(\"mpia.affiliation_verifications: \" + check)\n",
    "\n",
    "        \n",
    "warnings.simplefilter('always', AffiliationWarning)\n",
    "\n",
    "\n",
    "def get_markdown_qrcode(paper_id: str):\n",
    "    \"\"\" Generate a qrcode to the arxiv page using qrserver.com\n",
    "    \n",
    "    :param paper: Arxiv paper\n",
    "    :returns: markdown text\n",
    "    \"\"\"\n",
    "    url = r\"https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"\n",
    "    txt = f\"\"\"<img src={url}\"https://arxiv.org/abs/{paper_id}\">\"\"\"\n",
    "    txt = '<div id=\"qrcode\">' + txt + '</div>'\n",
    "    return txt\n",
    "\n",
    "\n",
    "def clean_non_western_encoded_characters_commands(text: str) -> str:\n",
    "    \"\"\" Remove non-western encoded characters from a string\n",
    "    List may need to grow.\n",
    "    \n",
    "    :param text: the text to clean\n",
    "    :return: the cleaned text\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"(\\\\begin{CJK}{UTF8}{gbsn})(.*?)(\\\\end{CJK})\", r\"\\2\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_initials(name: str) -> str:\n",
    "    \"\"\" Get the short name, e.g., A.-B. FamName\n",
    "    :param name: full name\n",
    "    :returns: initials\n",
    "    \"\"\"\n",
    "    initials = []\n",
    "    # account for non western names often in ()\n",
    "    if '(' in name:\n",
    "        name = clean_non_western_encoded_characters_commands(name)\n",
    "        suffix = re.findall(r\"\\((.*?)\\)\", name)[0]\n",
    "        name = name.replace(f\"({suffix})\", '')\n",
    "    else:\n",
    "        suffix = ''\n",
    "    split = name.split()\n",
    "    for token in split[:-1]:\n",
    "        if '-' in token:\n",
    "            current = '-'.join([k[0] + '.' for k in token.split('-')])\n",
    "        else:\n",
    "            current = token[0] + '.'\n",
    "        initials.append(current)\n",
    "    initials.append(split[-1].strip())\n",
    "    if suffix:\n",
    "        initials.append(f\"({suffix})\")\n",
    "    return ' '.join(initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd6310",
   "metadata": {
    "papermill": {
     "duration": 0.002967,
     "end_time": "2024-10-02T04:10:35.325266",
     "exception": false,
     "start_time": "2024-10-02T04:10:35.322299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## get list of arxiv paper candidates\n",
    "\n",
    "We use the MPIA mitarbeiter list webpage from mpia.de to get author names\n",
    "We then get all new papers from Arxiv and match authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea813a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:10:35.331985Z",
     "iopub.status.busy": "2024-10-02T04:10:35.331792Z",
     "iopub.status.idle": "2024-10-02T04:10:56.091813Z",
     "shell.execute_reply": "2024-10-02T04:10:56.090998Z"
    },
    "papermill": {
     "duration": 20.764972,
     "end_time": "2024-10-02T04:10:56.093184",
     "exception": false,
     "start_time": "2024-10-02T04:10:35.328212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deal with the author list and edge cases of people that cannot be consistent on their name  \n",
    "\n",
    "def filter_non_scientists(name: str) -> bool:\n",
    "    \"\"\" Loose filter on expected authorships\n",
    "\n",
    "    removing IT, administration, technical staff\n",
    "    :param name: name\n",
    "    :returns: False if name is not a scientist\n",
    "    \"\"\"\n",
    "    remove_list = ['Licht', 'Binroth', 'Witzel', 'Jordan',\n",
    "                   'Zähringer', 'Scheerer', 'Hoffmann', 'Düe',\n",
    "                   'Hellmich', 'Enkler-Scharpegge', 'Witte-Nguy',\n",
    "                   'Dehen', 'Beckmann', 'Jager', 'Jäger'\n",
    "                  ]\n",
    "\n",
    "    for k in remove_list:\n",
    "        if k in name:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def add_author_to_list(author_list: list) -> list:\n",
    "    \"\"\" Add author to list if not already in list\n",
    "    \n",
    "    :param author: author name\n",
    "    :param author_list: list of authors\n",
    "    :returns: updated list of authors\n",
    "    \"\"\"\n",
    "    add_list = ['T. Henning']\n",
    "\n",
    "    for author in add_list:\n",
    "        if author not in author_list:\n",
    "            author_list.append(author)\n",
    "    return author_list\n",
    "\n",
    "# get list from MPIA website\n",
    "# filter for non-scientists (mpia.get_mpia_mitarbeiter_list() does some filtering)\n",
    "mpia_authors = [k[1] for k in mpia.get_mpia_mitarbeiter_list() if filter_non_scientists(k[1])]\n",
    "# add some missing author because of inconsistencies in their MPIA name and author name on papers\n",
    "mpia_authors = add_author_to_list(mpia_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645e73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:10:56.101181Z",
     "iopub.status.busy": "2024-10-02T04:10:56.100676Z",
     "iopub.status.idle": "2024-10-02T04:10:56.842568Z",
     "shell.execute_reply": "2024-10-02T04:10:56.841938Z"
    },
    "papermill": {
     "duration": 0.746967,
     "end_time": "2024-10-02T04:10:56.843599",
     "exception": false,
     "start_time": "2024-10-02T04:10:56.096632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R. Burn  ->  R. Burn  |  ['R. Burn']\n",
      "H.-W. Rix  ->  H.-W. Rix  |  ['H.-W. Rix']\n",
      "K. Kreckel  ->  K. Kreckel  |  ['K. Kreckel']\n",
      "A. Kospal  ->  A. Kospal  |  ['A. Kospal']\n",
      "L. Xie  ->  Z.-L. Xie  |  ['L. Xie']\n",
      "J. Li  ->  J. Li  |  ['J. Li']\n",
      "J. Liu  ->  J. Liu  |  ['J. Liu']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arxiv has 78 new papers today\n",
      "          7 with possible author matches\n"
     ]
    }
   ],
   "source": [
    "new_papers = get_new_papers()\n",
    "# add manual references\n",
    "add_paper_refs = []\n",
    "new_papers.extend([get_paper_from_identifier(k) for k in add_paper_refs])\n",
    "\n",
    "def robust_call(fn, value, *args, **kwargs):\n",
    "    try:\n",
    "        return fn(value, *args, **kwargs)\n",
    "    except Exception:\n",
    "        return value\n",
    "\n",
    "candidates = []\n",
    "for paperk in new_papers:\n",
    "    # Check author list with their initials\n",
    "    normed_author_list = [robust_call(mpia.get_initials, k) for k in paperk['authors']]\n",
    "    hl_authors = highlight_authors_in_list(normed_author_list, mpia_authors, verbose=True)\n",
    "    matches = [(hl, orig) for hl, orig in zip(hl_authors, paperk['authors']) if 'mark' in hl]\n",
    "    paperk['authors'] = hl_authors\n",
    "    if matches:\n",
    "        # only select paper if an author matched our list\n",
    "        candidates.append(paperk)\n",
    "print(\"\"\"Arxiv has {0:,d} new papers today\"\"\".format(len(new_papers)))        \n",
    "print(\"\"\"          {0:,d} with possible author matches\"\"\".format(len(candidates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543b34a",
   "metadata": {
    "papermill": {
     "duration": 0.00317,
     "end_time": "2024-10-02T04:10:56.850343",
     "exception": false,
     "start_time": "2024-10-02T04:10:56.847173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parse sources and generate relevant outputs\n",
    "\n",
    "From the candidates, we do the following steps:\n",
    "* get their tarball from ArXiv (and extract data)\n",
    "* find the main .tex file: find one with \\documentclass{...} (sometimes it's non trivial)\n",
    "* Check affiliations with :func:`validation`, which uses :func:`mpia.affiliation_verifications`\n",
    "* If passing the affiliations: we parse the .tex source\n",
    "   * inject sub-documents into the main (flatten the main document)\n",
    "   * parse structure, extract information (title, abstract, authors, figures...)\n",
    "   * handles `\\graphicspath` if provided\n",
    "* Generate the .md document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9576b79e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:10:56.857818Z",
     "iopub.status.busy": "2024-10-02T04:10:56.857396Z",
     "iopub.status.idle": "2024-10-02T04:12:18.298425Z",
     "shell.execute_reply": "2024-10-02T04:12:18.297656Z"
    },
    "papermill": {
     "duration": 81.445977,
     "end_time": "2024-10-02T04:12:18.299529",
     "exception": false,
     "start_time": "2024-10-02T04:10:56.853552",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346351d7a9b6442fa35037ba1c92d921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving document from  https://arxiv.org/e-print/2410.00093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2410.00093..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/arxiv_on_deck_2/latex.py:488: LatexWarning: Error parsing the document directly. Trying to recover.\n",
      "  warnings.warn(LatexWarning(f\"Error parsing the document directly. Trying to recover.\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ → 0:header\n",
      "  ↳ 6560:\\section{Introduction}\n",
      "✔ → 6560:\\section{Introduction}\n",
      "  ↳ 14194:\\section{Statistical observational constraints}\\label{sect:statobsconst}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ → 14194:\\section{Statistical observational constraints}\\label{sect:statobsconst}\n",
      "  ↳ 25562:\\section{Brief outline of planet formation processes}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ → 25562:\\section{Brief outline of planet formation processes}\n",
      "  ↳ 55977:\\section{Population synthesis method}\\label{sect:popsynthmethod}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ → 55977:\\section{Population synthesis method}\\label{sect:popsynthmethod}\n",
      "  ↳ 82730:\\section{Results: Comparative analysis of population synthesis models}\\label{sect:results}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ → 82730:\\section{Results: Comparative analysis of population synthesis models}\\label{sect:results}\n",
      "  ↳ 121413:\\section{Outlook}\n",
      "✔ → 121413:\\section{Outlook}\n",
      "  ↳ 127940:\\section{{Summary and conclusions}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ → 127940:\\section{{Summary and conclusions}}\n",
      "  ↳ 132031:end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R. Burn  ->  R. Burn  |  ['R. Burn']\n",
      "Retrieving document from  https://arxiv.org/e-print/2410.00102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2731/2822249172.py:52: LatexWarning: 2410.00093 did not run properly\n",
      "list index out of range\n",
      "  warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2410.00102..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H.-W. Rix  ->  H.-W. Rix  |  ['H.-W. Rix']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 167 bibliographic references in tmp_2410.00102/main.bbl.\n",
      "Issues with the citations\n",
      "syntax error in line 410: '=' expected\n",
      "Retrieving document from  https://arxiv.org/e-print/2410.00106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2410.00106..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2410.00136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2410.00136..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79 bibliographic references in tmp_2410.00136/main.bbl.\n",
      "Retrieving document from  https://arxiv.org/e-print/2410.00237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2410.00237..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "Retrieving document from  https://arxiv.org/e-print/2410.00326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2410.00326..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done.\n",
      "  0: tmp_2410.00326/cas-dc-sample.tex, 762 lines\n",
      "  2: tmp_2410.00326/doc/elsdoc-cas.tex, 638 lines\n",
      "Retrieving document from  https://arxiv.org/e-print/2410.00401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Multiple tex files.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Found 2 candidates with documentclass definition.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3550: LatexWarning: Assuming tmp_2410.00326/cas-dc-sample.tex as main document.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tarball to tmp_2410.00401... done.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "failed = []\n",
    "for paper in tqdm(candidates):\n",
    "    # debug crap\n",
    "    paper['identifier'] = paper['identifier'].lower().replace('arxiv:', '').replace(r'\\n', '').strip()\n",
    "    paper_id = paper['identifier']\n",
    "    \n",
    "    folder = f'tmp_{paper_id}'\n",
    "\n",
    "    try:\n",
    "        if not os.path.isdir(folder):\n",
    "            folder = retrieve_document_source(f\"{paper_id}\", f'tmp_{paper_id}')\n",
    "        \n",
    "        try:\n",
    "            doc = latex.LatexDocument(folder, validation=validation)    \n",
    "        except AffiliationError as affilerror:\n",
    "            msg = f\"ArXiv:{paper_id:s} is not an MPIA paper... \" + str(affilerror)\n",
    "            failed.append((paper, \"affiliation error: \" + str(affilerror) ))\n",
    "            continue\n",
    "        \n",
    "        # Hack because sometimes author parsing does not work well\n",
    "        if (len(doc.authors) != len(paper['authors'])):\n",
    "            doc._authors = paper['authors']\n",
    "        else:\n",
    "            # highlight authors (FIXME: doc.highlight_authors)\n",
    "            # done on arxiv paper already\n",
    "            doc._authors = highlight_authors_in_list(\n",
    "                [get_initials(k) for k in doc.authors], \n",
    "                mpia_authors, verbose=True)\n",
    "        if (doc.abstract) in (None, ''):\n",
    "            doc._abstract = paper['abstract']\n",
    "            \n",
    "        doc.comment = (get_markdown_badge(paper_id) + \n",
    "                       \"<mark>Appeared on: \" + paper['date'] + \"</mark> - \")\n",
    "        if paper['comments']:\n",
    "            doc.comment += \" _\" + paper['comments'] + \"_\"\n",
    "        \n",
    "        full_md = doc.generate_markdown_text()\n",
    "        \n",
    "        full_md += get_markdown_qrcode(paper_id)\n",
    "        \n",
    "        # replace citations\n",
    "        try:\n",
    "            bibdata = latex_bib.LatexBib.from_doc(doc)\n",
    "            full_md = latex_bib.replace_citations(full_md, bibdata)\n",
    "        except Exception as e:\n",
    "            print(\"Issues with the citations\")\n",
    "            print(e)\n",
    "        \n",
    "        documents.append((paper_id, full_md))\n",
    "    except Exception as e:\n",
    "        warnings.warn(latex.LatexWarning(f\"{paper_id:s} did not run properly\\n\" +\n",
    "                                         str(e)\n",
    "                                        ))\n",
    "        failed.append((paper, \"latex error \" + str(e)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505a25c",
   "metadata": {
    "papermill": {
     "duration": 0.004546,
     "end_time": "2024-10-02T04:12:18.308962",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.304416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Export the logs\n",
    "\n",
    "Throughout, we also keep track of the logs per paper. see `logs-{today date}.md` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d733828a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.318906Z",
     "iopub.status.busy": "2024-10-02T04:12:18.318690Z",
     "iopub.status.idle": "2024-10-02T04:12:18.336802Z",
     "shell.execute_reply": "2024-10-02T04:12:18.336144Z"
    },
    "papermill": {
     "duration": 0.024448,
     "end_time": "2024-10-02T04:12:18.337909",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.313461",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Successful papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2410.00102-b31b1b.svg)](https://arxiv.org/abs/2410.00102) | **APOKASC-3: The Third Joint Spectroscopic and Asteroseismic catalog for Evolved Stars in the Kepler Fields**  |\n",
       "|| M. H. Pinsonneault, et al. -- incl., <mark>H.-W. Rix</mark> |\n",
       "|*Appeared on*| *2024-10-02*|\n",
       "|*Comments*| *43 pages, 25 figures, submitted ApJSupp. Comments welcome. Data tables available on request from pinsonneault.1@osu.edu*|\n",
       "|**Abstract**|            In the third APOKASC catalog, we present data for the complete sample of 15,808 evolved stars with APOGEE spectroscopic parameters and Kepler asteroseismology. We used ten independent asteroseismic analysis techniques and anchor our system on fundamental radii derived from Gaia $L$ and spectroscopic $T_{\\rm eff}$. We provide evolutionary state, asteroseismic surface gravity, mass, radius, age, and the spectroscopic and asteroseismic measurements used to derive them for 12,418 stars. This includes 10,036 exceptionally precise measurements, with median fractional uncertainties in \\nmax, \\dnu, mass, radius and age of 0.6\\%, 0.6\\%, 3.8\\%, 1.8\\%, and 11.1\\% respectively. We provide more limited data for 1,624 additional stars which either have lower quality data or are outside of our primary calibration domain. Using lower red giant branch (RGB) stars, we find a median age for the chemical thick disk of $9.14 \\pm 0.05 ({\\rm ran}) \\pm 0.9 ({\\rm sys})$ Gyr with an age dispersion of 1.1 Gyr, consistent with our error model. We calibrate our red clump (RC) mass loss to derive an age consistent with the lower RGB and provide asymptotic GB and RGB ages for luminous stars. We also find a sharp upper age boundary in the chemical thin disk. We find that scaling relations are precise and accurate on the lower RGB and RC, but they become more model dependent for more luminous giants and break down at the tip of the RGB. We recommend the usage of multiple methods, calibration to a fundamental scale, and the usage of stellar models to interpret frequency spacings.         |"
      ],
      "text/plain": [
       "[2410.00102] APOKASC-3: The Third Joint Spectroscopic and Asteroseismic catalog for Evolved Stars in the Kepler Fields\n",
       "\tM. H. Pinsonneault, et al. -- incl., <mark>H.-W. Rix</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2410.00136-b31b1b.svg)](https://arxiv.org/abs/2410.00136) | **JWST captures a sudden stellar outburst and inner disk wall destruction**  |\n",
       "|| C. Xie, et al. -- incl., <mark>A. Kospal</mark> |\n",
       "|*Appeared on*| *2024-10-02*|\n",
       "|*Comments*| *16 pages, 7 figures, submitted to ApJ*|\n",
       "|**Abstract**|            We present JWST/MIRI observations of T~Cha, a highly variable ($\\Delta V \\sim$3-5\\,mag) accreting Sun-like star surrounded by a disk with a large ($\\sim 15$\\,au) dust gap. We find that the JWST mid-infrared spectrum is signiticantly different from the {\\it Spitzer} spectrum obtained 17 years before, where the emission at short wavelengths ($5-10 \\mu m$) has decreased by $\\sim 2/3$ while at longer wavelengths ($15-25 \\mu m$) it increased by up to a factor of $\\sim 3$. This 'seesaw' behavior is contemporary with a fairly constant higher optical emission captured by the All Sky Automated Survey. By analyzing and modelling both SEDs, we propose that JWST caught the star during an outburst that destructed the asymmetric inner disk wall responsible for the high optical variability and lower $15-25$\\,micron\\ emission during the {\\it Spitzer} time. The dust mass lost during this outburst is estimated to be comparable ($\\sim 1/5$) to the upper limit of the total micron-sized dust mass in the inner disk of T~Cha now. Monitoring this system during possible future outbursts and more observations of its quiescent state will reveal if the inner disk can be replenished or will continue to be depleted and vanish.         |"
      ],
      "text/plain": [
       "[2410.00136] JWST captures a sudden stellar outburst and inner disk wall destruction\n",
       "\tC. Xie, et al. -- incl., <mark>A. Kospal</mark>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Failed papers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2410.00237-b31b1b.svg)](https://arxiv.org/abs/2410.00237) | **Discovering Large-Scale Structure at $2<z<5$ in the C3VO Survey**  |\n",
       "|| D. Hung, et al. -- incl., <mark>L. Xie</mark> |\n",
       "|*Appeared on*| *2024-10-02*|\n",
       "|*Comments*| *36 pages, 16 figures, 5 tables, submitted to ApJ*|\n",
       "|**Abstract**|            The Charting Cluster Construction with VUDS and ORELSE (C3VO) survey is an ongoing imaging and spectroscopic campaign aiming to map out the growth of structure up to $z\\sim5$ and was born from the combination of the VIMOS Ultra Deep Survey (VUDS) and the Observations of Redshift Evolution in Large-Scale Environments (ORELSE) survey. As we previously accomplished with the ORELSE survey, we apply our technique known as Voronoi tessellation Monte-Carlo (VMC) mapping to search for serendipitous galaxy overdensities at $2<z<5$ in the three C3VO fields. We also apply the same technique to mock observations of simulated galaxies with properties derived from the GAlaxy Evolution and Assembly (GAEA) semi-analytic model (SAM) in order to judge the effectiveness of our as a function of redshift, total mass, and fraction of spectroscopic redshifts. We find typical completeness and purity values of the order 30-50%, with a strong dependence on mass and redshift, with values as high as $\\sim$80% and $\\sim$70%, respectively, in the best-case scenario for $\\log (M_{z=0}/M_{\\odot}) > 14$. In the C3VO fields, we were able to recover many of the previously known structures in the literature as well as find hundreds of new overdensity candidates, once again demonstrating the powerful capabilities of VMC mapping when applied to wide-field optical and infrared galaxy evolution surveys at ever higher redshifts.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2410.00326-b31b1b.svg)](https://arxiv.org/abs/2410.00326) | **Resonant amplitude distribution of the Hilda asteroids and the free-floating planet flyby scenario**  |\n",
       "|| <mark>J. Li</mark>, et al. |\n",
       "|*Appeared on*| *2024-10-02*|\n",
       "|*Comments*| *22 pages, 10 figures, accepted for publication in Icarus*|\n",
       "|**Abstract**|            In some recent work, we provided a quantitative explanation for the number asymmetry of Jupiter Trojans by hypothesizing a free-floating planet (FFP) flyby into the Solar System. In support of that explanation, this paper examines the influence of the same FFP flyby on the Hilda asteroids, which orbit stably in the 3:2 mean motion resonance with Jupiter. The observed Hilda population exhibits two distinct resonant patterns: (1) a lack of Hildas with resonant amplitudes < 40 deg. at eccentricities < 0.1; (2) a nearly complete absence of Hildas with amplitudes < 20 deg., regardless of eccentricity. Previous models of Jupiter migration and resonance capture could account for the eccentricity distribution of Hildas but have failed to replicate the unusual absence of those with the smallest resonant amplitudes, which theoretically should be the most stable. Here we report that the FFP flyby can trigger an extremely rapid outward migration of Jupiter, causing a sudden shift in the 3:2 Jovian resonance. Consequently, Hildas with varying eccentricities would have their resonant amplitudes changed by different degrees, leading to the observed resonant patterns. We additionally show that, in our FFP flyby scenario, these patterns are consistently present across different resonant amplitude distributions of primordial Hildas arising from various formation models. We also place constraints on the potential parameters of the FFP, suggesting it should have an eccentricity of 1-1.3 or larger, an inclination up to 30 deg. or higher, and a minimum mass of about 50 Earth masses.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2410.00401-b31b1b.svg)](https://arxiv.org/abs/2410.00401) | **Cosmological constraints using Minkowski functionals from the first year data of the Hyper Suprime-Cam**  |\n",
       "|| J. Armijo, et al. -- incl., <mark>J. Liu</mark> |\n",
       "|*Appeared on*| *2024-10-02*|\n",
       "|*Comments*| *8 pages, 5 figures. Submitted to MNRAS*|\n",
       "|**Abstract**|            We use Minkowski functionals to analyse weak lensing convergence maps from the first-year data release of the Subaru Hyper Suprime-Cam (HSC-Y1) survey. Minkowski functionals provide a description of the morphological properties of a field, capturing the non-Gaussian features of the Universe matter-density distribution. Using simulated catalogs that reproduce survey conditions and encode cosmological information, we emulate Minkowski functionals predictions across a range of cosmological parameters to derive the best-fit from the data. By applying multiple scales cuts, we rigorously mitigate systematic effects, including baryonic feedback and intrinsic alignments. From the analysis, combining constraints of the angular power spectrum and Minkowski functionals, we obtain $S_8 \\equiv \\sigma_8\\sqrt{\\Omega_{\\rm m}/0.3} = {0.808}_{-0.046}^{+0.033}$ and $\\Omega_{\\rm m} = {0.293}_{-0.043}^{+0.157}$. These results represent a $40\\%$ improvement on the $S_8$ constraints compared to using power spectrum only, and are consistent with previous non-Gaussian statistics analyses of the same dataset. Our study demonstrates the power of Minkowski functionals beyond two-point statistics for constraining and breaking the degeneracy between $\\Omega_{\\rm m}$ and $\\sigma_8$.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Heidelberg' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2410.00106-b31b1b.svg)](https://arxiv.org/abs/2410.00106) | **Metallicity calibrations based on auroral lines from PHANGS-MUSE data**  |\n",
       "|| M. Brazzini, et al. -- incl., <mark>K. Kreckel</mark> |\n",
       "|*Appeared on*| *2024-10-02*|\n",
       "|*Comments*| *20 pages, 14 figures, 6 tables; accepted for publication in Astronomy & Astrophysics*|\n",
       "|**Abstract**|            We present a chemical analysis of selected HII regions from the PHANGS-MUSE nebular catalogue. Our intent is to empirically re-calibrate strong-line diagnostics of gas-phase metallicity, applicable across a wide range of metallicities within nearby star-forming galaxies. To ensure reliable measurements of auroral line fluxes, we carried out a new spectral fitting procedure whereby only restricted wavelength regions around the emission lines of interest are taken into account: this assures a better fit for the stellar continuum. No prior cuts to nebulae luminosity were applied to limit biases in auroral line detections. Ionic abundances of O+, O++, N+, S+, and S++ were estimated by applying the direct method. We integrated the selected PHANGS-MUSE sample with other existing auroral line catalogues, appropriately re-analysed to obtain a homogeneous dataset. This was used to derive strong-line diagnostic calibrations that span from 12+log(O/H) = 7.5 to 8.8. We investigate their dependence on the ionisation parameter and conclude that it is likely the primary cause of the significant scatter observed in these diagnostics. We apply our newly calibrated strong-line diagnostics to the total sample of HII regions from the PHANGS-MUSE nebular catalogue, and we exploit these indirect metallicity estimates to study the radial metallicity gradient within each of the 19 galaxies of the sample. We compare our results with the literature and find good agreement, validating our procedure and findings. With this paper, we release the full catalogue of auroral and nebular line fluxes for the selected HII regions from the PHANGS-MUSE nebular catalogue. This is the first catalogue of direct chemical abundance measurements carried out with PHANGS-MUSE data.         |\n",
       "|<p style=\"color:green\"> **ERROR** </p>| <p style=\"color:green\">affiliation error: mpia.affiliation_verifications: 'Planck' keyword not found.</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "|||\n",
       "|---:|:---|\n",
       "| [![arXiv](https://img.shields.io/badge/arXiv-2410.00093-b31b1b.svg)](https://arxiv.org/abs/2410.00093) | **Planetary population synthesis**  |\n",
       "|| <mark>R. Burn</mark>, C. Mordasini |\n",
       "|*Appeared on*| *2024-10-02*|\n",
       "|*Comments*| *To be published in: Handbook of Exoplanets, 2nd Edition, Hans Deeg and Juan Antonio Belmonte (Eds. in Chief), Springer International Publishing AG, part of Springer Nature. 59 pages, 8 figures. This is an update of arXiv:1804.01532*|\n",
       "|**Abstract**|            The planetary population synthesis method aims at comprehensively testing planet formation theories against observational evidence and providing theoretical sets of planets to help interpret observations and inform instrument development. Recent developments on the theoretical and observational sides are reviewed: First, observational constraints are summarized, then, the work flow of population synthesis and its two main components are presented, which are, global end-to-end models of planetary formation and evolution and probability distributions for the disk initial conditions. Next, the output of four recent population synthesis models is compared in detail and differences and similarities are discussed. The goal is to help the reader understand the assumptions that were made and how they impact the results. Furthermore, future directions of research are identified and the impact of current and future observational programs is discussed. With JWST, evidence on disk and planet compositions emerges. Planet formation models need to prepare for these near-future developments by including self-consistent magnetic wind-driven gas and dust disk evolution, planetary migration, as well as employ hybrid pebble and planetesimal accretion, which are identified as dominant modes of accretion in different mass regimes.         |\n",
       "|<p style=\"color:red\"> **ERROR** </p>| <p style=\"color:red\">latex error list index out of range</p> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.date.today())\n",
    "logfile = f\"_build/html/logs/log-{today}.md\"\n",
    "\n",
    "\n",
    "with open(logfile, 'w') as logs:\n",
    "    # Success\n",
    "    logs.write(f'# Arxiv on Deck 2: Logs - {today}\\n\\n')\n",
    "    logs.write(\"\"\"* Arxiv had {0:,d} new papers\\n\"\"\".format(len(new_papers)))\n",
    "    logs.write(\"\"\"    * {0:,d} with possible author matches\\n\\n\"\"\".format(len(candidates)))\n",
    "    logs.write(\"## Sucessful papers\\n\\n\")\n",
    "    display(Markdown(\"## Successful papers\"))\n",
    "    success = [k[0] for k in documents]\n",
    "    for candid in candidates:\n",
    "        if candid['identifier'].split(':')[-1] in success:\n",
    "            display(candid)\n",
    "            logs.write(candid.generate_markdown_text() + '\\n\\n')\n",
    "\n",
    "    ## failed\n",
    "    logs.write(\"## Failed papers\\n\\n\")\n",
    "    display(Markdown(\"## Failed papers\"))\n",
    "    failed = sorted(failed, key=lambda x: x[1])\n",
    "    current_reason = \"\"\n",
    "    for paper, reason in failed:\n",
    "        if 'affiliation' in reason:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        data = Markdown(\n",
    "                paper.generate_markdown_text() + \n",
    "                f'\\n|<p style=\"color:{color:s}\"> **ERROR** </p>| <p style=\"color:{color:s}\">{reason:s}</p> |'\n",
    "               )\n",
    "        if reason != current_reason:\n",
    "            logs.write(f'### {reason:s} \\n\\n')\n",
    "            current_reason = reason\n",
    "        logs.write(data.data + '\\n\\n')\n",
    "        \n",
    "        # only display here the important errors (all in logs)\n",
    "        # if color in ('red',):\n",
    "        display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d20ee",
   "metadata": {
    "papermill": {
     "duration": 0.005329,
     "end_time": "2024-10-02T04:12:18.348868",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.343539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Export documents\n",
    "\n",
    "We now write the .md files and export relevant images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d426aed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.360690Z",
     "iopub.status.busy": "2024-10-02T04:12:18.360297Z",
     "iopub.status.idle": "2024-10-02T04:12:18.367165Z",
     "shell.execute_reply": "2024-10-02T04:12:18.366631Z"
    },
    "papermill": {
     "duration": 0.013806,
     "end_time": "2024-10-02T04:12:18.368111",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.354305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_markdown_summary(md: str, md_fname:str, directory: str):\n",
    "    \"\"\"Export MD document and associated relevant images\"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "    import re\n",
    "\n",
    "    if (os.path.exists(directory) and not os.path.isdir(directory)):\n",
    "        raise RuntimeError(f\"a non-directory file exists with name {directory:s}\")\n",
    "\n",
    "    if (not os.path.exists(directory)):\n",
    "        print(f\"creating directory {directory:s}\")\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    fig_fnames = (re.compile(r'\\[Fig.*\\]\\((.*)\\)').findall(md) + \n",
    "                  re.compile(r'\\<img src=\"([^>\\s]*)\"[^>]*/>').findall(md))\n",
    "    print(\"found figures\", fig_fnames)\n",
    "    for fname in fig_fnames:\n",
    "        if 'http' in fname:\n",
    "            # No need to copy online figures\n",
    "            continue\n",
    "        if not os.path.exists(fname):\n",
    "            print(\"file not found\", fname)\n",
    "            continue\n",
    "        print(\"copying \", fname, \"to\", directory)\n",
    "        destdir = os.path.join(directory, os.path.dirname(fname))\n",
    "        destfname = os.path.join(destdir, os.path.basename(fname))\n",
    "        try:\n",
    "            os.makedirs(destdir)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        shutil.copy(fname, destfname)\n",
    "    with open(os.path.join(directory, md_fname), 'w') as fout:\n",
    "        fout.write(md)\n",
    "    print(\"exported in \", os.path.join(directory, md_fname))\n",
    "    [print(\"    + \" + os.path.join(directory,fk)) for fk in fig_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d04a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.379912Z",
     "iopub.status.busy": "2024-10-02T04:12:18.379674Z",
     "iopub.status.idle": "2024-10-02T04:12:18.388762Z",
     "shell.execute_reply": "2024-10-02T04:12:18.388224Z"
    },
    "papermill": {
     "duration": 0.016042,
     "end_time": "2024-10-02T04:12:18.389703",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.373661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found figures ['tmp_2410.00102/./Figure6.PDF', 'tmp_2410.00102/./Figure7.PDF', 'tmp_2410.00102/./Figure10.PDF']\n",
      "copying  tmp_2410.00102/./Figure6.PDF to _build/html/\n",
      "copying  tmp_2410.00102/./Figure7.PDF to _build/html/\n",
      "copying  tmp_2410.00102/./Figure10.PDF to _build/html/\n",
      "exported in  _build/html/2410.00102.md\n",
      "    + _build/html/tmp_2410.00102/./Figure6.PDF\n",
      "    + _build/html/tmp_2410.00102/./Figure7.PDF\n",
      "    + _build/html/tmp_2410.00102/./Figure10.PDF\n",
      "found figures ['tmp_2410.00136/./Photometry_Time_larger.png', 'tmp_2410.00136/./OverviewBoth.png', 'tmp_2410.00136/./SingleParameters_plusdata.png']\n",
      "copying  tmp_2410.00136/./Photometry_Time_larger.png to _build/html/\n",
      "copying  tmp_2410.00136/./OverviewBoth.png to _build/html/\n",
      "copying  tmp_2410.00136/./SingleParameters_plusdata.png to _build/html/\n",
      "exported in  _build/html/2410.00136.md\n",
      "    + _build/html/tmp_2410.00136/./Photometry_Time_larger.png\n",
      "    + _build/html/tmp_2410.00136/./OverviewBoth.png\n",
      "    + _build/html/tmp_2410.00136/./SingleParameters_plusdata.png\n"
     ]
    }
   ],
   "source": [
    "for paper_id, md in documents:\n",
    "    export_markdown_summary(md, f\"{paper_id:s}.md\", '_build/html/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087a0a7",
   "metadata": {
    "papermill": {
     "duration": 0.005412,
     "end_time": "2024-10-02T04:12:18.400718",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.395306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Display the papers\n",
    "\n",
    "Not necessary but allows for a quick check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.413057Z",
     "iopub.status.busy": "2024-10-02T04:12:18.412579Z",
     "iopub.status.idle": "2024-10-02T04:12:18.418511Z",
     "shell.execute_reply": "2024-10-02T04:12:18.417978Z"
    },
    "papermill": {
     "duration": 0.013062,
     "end_time": "2024-10-02T04:12:18.419536",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.406474",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\mh}[0]{[M/H]}$\n",
       "$\\newcommand{\\afe}[0]{[\\alpha/Fe] }$\n",
       "$\\newcommand{\\afens}[0]{[\\alpha/Fe]}$\n",
       "$\\newcommand{\\am}[0]{[\\alpha/M] }$\n",
       "$\\newcommand{\\amns}[0]{[\\alpha/M]}$\n",
       "$\\newcommand{\\feh}[0]{[Fe/H] }$\n",
       "$\\newcommand{\\fehns}[0]{[Fe/H]}$\n",
       "$\\newcommand{\\teff}[0]{T_{\\rm eff} }$\n",
       "$\\newcommand{\\teffns}[0]{T_{\\rm eff}}$\n",
       "$\\newcommand{\\logg}[0]{\\log{g} }$\n",
       "$\\newcommand{\\loggns}[0]{\\log{g}}$\n",
       "$\\newcommand{\\dnu}[0]{\\ensuremath{\\Delta \\nu}}$\n",
       "$\\newcommand{\\fdnu}[0]{\\ensuremath{f_{\\Delta \\nu}}}$\n",
       "$\\newcommand{\\nmax}[0]{\\ensuremath{\\nu_{\\rm \\max}}}$\n",
       "$\\newcommand{\\fnmax}[0]{\\ensuremath{f_{\\nu \\max}}}$\n",
       "$\\newcommand{\\rsun}[0]{\\ensuremath{R_{\\odot}}}$\n",
       "$\\newcommand{\\msun}[0]{\\ensuremath{M_{\\odot}}}$\n",
       "$\\newcommand{\\kep}[0]{\\textsl{Kepler}}$\n",
       "$\\newcommand{\\gaia}[0]{\\textsl{Gaia}}$\n",
       "$\\newcommand{\\jt}[1]{\\textcolor{blue}{#1}}$\n",
       "$\\newcommand{\\kc}[1]{\\textcolor{green}{[K. Cao: #1]}}$\n",
       "$\\newcommand{\\jcz}[1]{\\textcolor{grey}{#1}}$\n",
       "$\\newcommand{\\ams}[1]{\\textcolor{orange}{#1}}$\n",
       "$\\newcommand{\\RAG}[1]{\\textcolor{blue}{#1}}$\n",
       "$\\newcommand{\\amscomm}[1]{\\textcolor{purple}{#1}}$\n",
       "$\\newcommand{\\BM}[1]{\\textcolor{purple}{[BM: #1]}}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# APOKASC-3: The Third Joint Spectroscopic and Asteroseismic Catalog for Evolved Stars in the $\\kep$ Fields\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2410.00102-b31b1b.svg)](https://arxiv.org/abs/2410.00102)<mark>Appeared on: 2024-10-02</mark> -  _43 pages, 25 figures, submitted ApJSupp. Comments welcome. Data tables available on request from pinsonneault.1@osu.edu_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "M. H. Pinsonneault, et al. -- incl., <mark>H.-W. Rix</mark>\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** In the third APOKASC catalog, we present data for the complete sample of 15,808 evolved stars with APOGEE spectroscopic parameters and $\\kep$ asteroseismology. We used ten independent asteroseismic analysis techniques and anchor our system on fundamental radii derived from $\\gaia$ $L$ and spectroscopic $T_{\\rm eff}$ .  We provide evolutionary state, asteroseismic surface gravity, mass, radius, age, and the spectroscopic and asteroseismic measurements used to derive them for 12,418 stars. This includes 10,036 exceptionally precise measurements, with median fractional uncertainties in $\\nmax$ , $\\dnu$ , mass, radius and age of 0.6 \\% , 0.6 \\% , 3.8 \\% , 1.8 \\% , and 11.1 \\% respectively. We provide more limited data  for 1,624 additional stars which either have lower quality data or are outside of our primary calibration domain. Using lower red giant branch (RGB) stars, we find a median age for the chemical thick disk of $9.14 \\pm 0.05 ({\\rm ran}) \\pm 0.9 ({\\rm sys})$ Gyr with an age dispersion of 1.1 Gyr, consistent with our error model. We calibrate our red clump (RC) mass loss to derive an age consistent with the lower RGB and provide asymptotic GB and RGB ages for luminous stars. We also find a sharp upper age boundary in the chemical thin disk. We find that scaling relations are precise and accurate on the lower RGB and RC, but they become more model dependent for more luminous giants and break down at the tip of the RGB. We recommend the usage of multiple methods, calibration to a fundamental scale, and the usage of stellar models to interpret frequency spacings.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2410.00102/./Figure6.PDF\" alt=\"Fig6\" width=\"100%\"/>\n",
       "\n",
       "**Figure 6. -** Frequency spacing corrections for RC stars using the Garstec+Mosser (top left), Garstec+White (middle left) and Sharma+White (lower left) models and weights. Differences between Garstec+Mosser and Garstec+White (top right) measure the impact of the assigned weighting scheme. Differences between Garstec+White and Sharma+White measure the impact of the models used. For a minority of stars, the true $\\logg$ range of the sample did not correspond to the range in the model grid, which is responsible for some of the structures seen in the BeSPP results. (*fig:rccor*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2410.00102/./Figure7.PDF\" alt=\"Fig7\" width=\"100%\"/>\n",
       "\n",
       "**Figure 7. -** Frequency spacing corrections for RGB stars using the Garstec+Mosser (top left), Garstec+White (middle left), and Sharma+White (lower left) models and weights. Differences between Garstec+Mosser and Garstec+White (top right) measure the impact of the assigned weighting scheme. Differences between Garstec+White and Sharma+White measure the impact of the models used. (*fig:rgbcor*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2410.00102/./Figure10.PDF\" alt=\"Fig10\" width=\"100%\"/>\n",
       "\n",
       "**Figure 10. -** Fractional difference in age between AGB and RGB stars (top) and the total mass loss on the RGB (bottom) as a function of the current mass of the star. Low mass stars experience much more mass loss. (*fig:mdot*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2410.00102\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div class=\"macros\" style=\"visibility:hidden;\">\n",
       "$\\newcommand{\\ensuremath}{}$\n",
       "$\\newcommand{\\xspace}{}$\n",
       "$\\newcommand{\\object}[1]{\\texttt{#1}}$\n",
       "$\\newcommand{\\farcs}{{.}''}$\n",
       "$\\newcommand{\\farcm}{{.}'}$\n",
       "$\\newcommand{\\arcsec}{''}$\n",
       "$\\newcommand{\\arcmin}{'}$\n",
       "$\\newcommand{\\ion}[2]{#1#2}$\n",
       "$\\newcommand{\\textsc}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\hl}[1]{\\textrm{#1}}$\n",
       "$\\newcommand{\\footnote}[1]{}$\n",
       "$\\newcommand{\\vdag}{(v)^\\dagger}$\n",
       "$\\newcommand$\n",
       "$\\newcommand$\n",
       "$\\newcommand{\\ilaria}[1]$\n",
       "$\\newcommand{\\cyxie}[1]$\n",
       "$\\newcommand{\\uat}[2]{\\href{http://vocabs.ands.org.au/repository/api/lda/aas/the-unified-astronomy-thesaurus/current/resource.html?uri=http://astrothesaurus.org/uat/#1}{#2  (#1)}}$\n",
       "$\\newcommand{\\affilLPL}{\\affiliation{Lunar and Planetary Laboratory, The University of Arizona, Tucson, AZ 85721, USA; \\url{cyxie@arizona.edu}}}$</div>\n",
       "\n",
       "\n",
       "\n",
       "<div id=\"title\">\n",
       "\n",
       "# JWST captures a sudden stellar outburst and inner disk wall destruction\n",
       "\n",
       "</div>\n",
       "<div id=\"comments\">\n",
       "\n",
       "[![arXiv](https://img.shields.io/badge/arXiv-2410.00136-b31b1b.svg)](https://arxiv.org/abs/2410.00136)<mark>Appeared on: 2024-10-02</mark> -  _16 pages, 7 figures, submitted to ApJ_\n",
       "\n",
       "</div>\n",
       "<div id=\"authors\">\n",
       "\n",
       "C. Xie, et al.\n",
       "\n",
       "</div>\n",
       "<div id=\"abstract\">\n",
       "\n",
       "**Abstract:** We present JWST/MIRI observations of T Cha, a highly variable ( $\\Delta V \\sim$ 3-5 mag) accreting Sun-like star surrounded by a disk with a large ( $\\sim 15$ au) dust gap. We find that the JWST mid-infrared spectrum is signiticantly different from the $_ Spitzer_$ spectrum obtained 17 years before, where the emission at short wavelengths ( $5-10 \\mu m$ ) has decreased by $\\sim 2/3$ while at longer wavelengths ( $15-25 \\mu m$ ) it increased by up to a factor of $\\sim 3$ . This ‘seesaw’ behavior is contemporary with a fairly constant higher optical emission captured by the All Sky Automated Survey. By analyzing and modelling both SEDs, we propose that JWST caught the star during an outburst that destructed the asymmetric inner disk wall responsible for the high optical variability and lower $15-25$ micron emission during the $_ Spitzer_$ time. The dust mass lost during this outburst is estimated to be comparable ( $\\sim 1/5$ ) to the upper limit of the total micron-sized dust mass in the inner disk of T Cha now. Monitoring this system during possible future outbursts and more observations of its quiescent state will reveal if the inner disk can be replenished or will continue to be depleted and vanish.\n",
       "\n",
       "</div>\n",
       "\n",
       "<div id=\"div_fig1\">\n",
       "\n",
       "<img src=\"tmp_2410.00136/./Photometry_Time_larger.png\" alt=\"Fig1\" width=\"100%\"/>\n",
       "\n",
       "**Figure 1. -** Optical and mid-IR light curves of T Cha. The lines and shaded area indicates the date when some of the photometric points we analyzed in this paper were taken. Blue shaded areas indicates the period when T Cha has less variable but brighter optical emission. The `LCOGT and Andicam' is from [Walter, Brown and France (2018)]().\n",
       "     (*fig:Photometry*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig2\">\n",
       "\n",
       "<img src=\"tmp_2410.00136/./OverviewBoth.png\" alt=\"Fig3\" width=\"100%\"/>\n",
       "\n",
       "**Figure 3. -** Overview of the SED of T Cha. The grey dased line is 5600 K stellar photosphere emission. The red and blue solid lines are _ Spitzer_/IRS SED and JWST MIRI/MRS spectra, respectively. The two strong lines in the JWST spectrum are [ArII] and [NeII], and the broad features are PAH features, which are discussed in [Bajaj, Pascucci and Gorti (2024)](). The photometric points in optical bands are from [Alcala, Covino and Franchini (1993)](), [Walter, Brown and France (2018)]() and AAVSO, and the IR photometric points are from various papers (see Table \\ref{app:tab:ref}). We highlight some points in blue to indicate they are taken contemporary with the JWST observation (see the blue shaded region next to the JWST line in Fig \\ref{fig:Photometry}). The near and mid-IR points connected with dotted lines indicate one contemporary observation at JHKLM bands  ([Alcala, Covino and Franchini 1993]()) .\n",
       "     (*fig:Overview*)\n",
       "\n",
       "</div>\n",
       "<div id=\"div_fig3\">\n",
       "\n",
       "<img src=\"tmp_2410.00136/./SingleParameters_plusdata.png\" alt=\"Fig7\" width=\"100%\"/>\n",
       "\n",
       "**Figure 7. -** SED changes with each single parameter. When changing one parameter, other parameters are kept fixed as shown in Table \\ref{app:tab:Start}. In Panel 3 the optically thick part is between the star and the observer to illustrate how the maximum optical extinction vary with $\\delta \\phi$. Notice that the initial parameters set here are not exactly the same as our fitted model for _ Spitzer_.\n",
       "     (*app:fig:single*)\n",
       "\n",
       "</div><div id=\"qrcode\"><img src=https://api.qrserver.com/v1/create-qr-code/?size=100x100&data=\"https://arxiv.org/abs/2410.00136\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[display(Markdown(k[1])) for k in documents];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873873a4",
   "metadata": {
    "papermill": {
     "duration": 0.00591,
     "end_time": "2024-10-02T04:12:18.431399",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.425489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create HTML index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf665672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.444375Z",
     "iopub.status.busy": "2024-10-02T04:12:18.443829Z",
     "iopub.status.idle": "2024-10-02T04:12:18.451863Z",
     "shell.execute_reply": "2024-10-02T04:12:18.451220Z"
    },
    "papermill": {
     "duration": 0.015552,
     "end_time": "2024-10-02T04:12:18.452916",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.437364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205  publications files modified in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('_build/html/*.md')\n",
    "days = 7\n",
    "now = datetime.today()\n",
    "res = []\n",
    "for fk in files:\n",
    "    stat_result = os.stat(fk).st_ctime\n",
    "    modified = datetime.fromtimestamp(stat_result, tz=timezone.utc).replace(tzinfo=None)\n",
    "    delta = now.today() - modified\n",
    "    if delta <= timedelta(days=days):\n",
    "        res.append((delta.seconds, fk))\n",
    "res = [k[1] for k in reversed(sorted(res, key=lambda x:x[1]))]\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications files modified in the last {days:d} days.\")\n",
    "# [ print('\\t', k) for k in res ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015de740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.465688Z",
     "iopub.status.busy": "2024-10-02T04:12:18.465349Z",
     "iopub.status.idle": "2024-10-02T04:12:18.479629Z",
     "shell.execute_reply": "2024-10-02T04:12:18.478959Z"
    },
    "papermill": {
     "duration": 0.021758,
     "end_time": "2024-10-02T04:12:18.480643",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.458885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  publications in the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "def get_last_n_days(lst, days=1):\n",
    "    \"\"\" Get the documents from the last n days \"\"\"\n",
    "    sorted_lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "    for fname, date in sorted_lst:\n",
    "        if date >= str(datetime.date.today() - datetime.timedelta(days=days)):\n",
    "            yield fname\n",
    "\n",
    "def extract_appearance_dates(lst_file):\n",
    "    dates = []\n",
    "\n",
    "    def get_date(line):\n",
    "        return line\\\n",
    "            .split('Appeared on:')[-1]\\\n",
    "            .split('</mark>')[0].strip()\n",
    "\n",
    "    for fname in lst:\n",
    "        with open(fname, 'r') as f:\n",
    "            found_date = False\n",
    "            for line in f:\n",
    "                if not found_date:\n",
    "                    if \"Appeared on\" in line:\n",
    "                        found_date = True\n",
    "                        dates.append((fname, get_date(line)))\n",
    "                else:\n",
    "                    break\n",
    "    return dates\n",
    "\n",
    "from glob import glob\n",
    "lst = glob('_build/html/*md')\n",
    "days = 7\n",
    "dates = extract_appearance_dates(lst)\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last {days:d} days.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca0208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.493921Z",
     "iopub.status.busy": "2024-10-02T04:12:18.493585Z",
     "iopub.status.idle": "2024-10-02T04:12:18.498466Z",
     "shell.execute_reply": "2024-10-02T04:12:18.497887Z"
    },
    "papermill": {
     "duration": 0.012562,
     "end_time": "2024-10-02T04:12:18.499458",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.486896",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_carousel(npub=4):\n",
    "    \"\"\" Generate the HTML code for a carousel with `npub` slides \"\"\"\n",
    "    carousel = [\"\"\"  <div class=\"carousel\" \"\"\",\n",
    "                \"\"\"       data-flickity='{ \"autoPlay\": 10000, \"adaptiveHeight\": true, \"resize\": true, \"wrapAround\": true, \"pauseAutoPlayOnHover\": true, \"groupCells\": 1 }' id=\"asyncTypeset\">\"\"\"\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"carousel-cell\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        carousel.append(item_str.format(k=k))\n",
    "    carousel.append(\"  </div>\")\n",
    "    return '\\n'.join(carousel)\n",
    "\n",
    "def create_grid(npub=4):\n",
    "    \"\"\" Generate the HTML code for a flat grid with `npub` slides \"\"\"\n",
    "    grid = [\"\"\"  <div class=\"grid\"> \"\"\",\n",
    "                ]\n",
    "    \n",
    "    item_str = \"\"\"    <div class=\"grid-item\"> <div id=\"slide{k}\" class=\"md_view\">Content {k}</div> </div>\"\"\"\n",
    "    for k in range(1, npub + 1):\n",
    "        grid.append(item_str.format(k=k))\n",
    "    grid.append(\"  </div>\")\n",
    "    return '\\n'.join(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6eac5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.512628Z",
     "iopub.status.busy": "2024-10-02T04:12:18.512180Z",
     "iopub.status.idle": "2024-10-02T04:12:18.517064Z",
     "shell.execute_reply": "2024-10-02T04:12:18.516575Z"
    },
    "papermill": {
     "duration": 0.012424,
     "end_time": "2024-10-02T04:12:18.517974",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.505550",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"7-day archives\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "with open(\"_build/html/index_7days.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc1a1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.531658Z",
     "iopub.status.busy": "2024-10-02T04:12:18.531089Z",
     "iopub.status.idle": "2024-10-02T04:12:18.537548Z",
     "shell.execute_reply": "2024-10-02T04:12:18.536888Z"
    },
    "papermill": {
     "duration": 0.014187,
     "end_time": "2024-10-02T04:12:18.538586",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.524399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  publications in the last day.\n"
     ]
    }
   ],
   "source": [
    "# redo for today\n",
    "days = 1\n",
    "res = list(get_last_n_days(dates, days))\n",
    "npub = len(res)\n",
    "print(len(res), f\" publications in the last day.\")\n",
    "\n",
    "carousel = create_carousel(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"daily_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- carousel:s --%}\", carousel)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  \"Daily\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(carousel, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_daily.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00eece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T04:12:18.552038Z",
     "iopub.status.busy": "2024-10-02T04:12:18.551581Z",
     "iopub.status.idle": "2024-10-02T04:12:18.557946Z",
     "shell.execute_reply": "2024-10-02T04:12:18.557410Z"
    },
    "papermill": {
     "duration": 0.014101,
     "end_time": "2024-10-02T04:12:18.558931",
     "exception": false,
     "start_time": "2024-10-02T04:12:18.544830",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  6 publications selected.\n"
     ]
    }
   ],
   "source": [
    "# Create the flat grid of the last N papers (fixed number regardless of dates)\n",
    "from itertools import islice \n",
    "\n",
    "npub = 6\n",
    "res = [k[0] for k in (islice(reversed(sorted(dates, key=lambda x: x[1])), 6))]\n",
    "print(len(res), f\" {npub} publications selected.\")\n",
    "\n",
    "grid = create_grid(npub)\n",
    "docs = ', '.join(['\"{0:s}\"'.format(k.split('/')[-1]) for k in res])\n",
    "slides = ', '.join([f'\"slide{k}\"' for k in range(1, npub + 1)])\n",
    "\n",
    "with open(\"grid_template.html\", \"r\") as tpl:\n",
    "    page = tpl.read()\n",
    "    page = page.replace(\"{%-- grid-content:s --%}\", grid)\\\n",
    "               .replace(\"{%-- suptitle:s --%}\",  f\"Last {npub:,d} papers\" )\\\n",
    "               .replace(\"{%-- docs:s --%}\", docs)\\\n",
    "               .replace(\"{%-- slides:s --%}\", slides)\n",
    "    \n",
    "# print(grid, docs, slides)\n",
    "# print(page)\n",
    "with open(\"_build/html/index_npub_grid.html\", 'w') as fout:\n",
    "    fout.write(page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 104.749985,
   "end_time": "2024-10-02T04:12:18.781276",
   "environment_variables": {},
   "exception": null,
   "input_path": "MPIA daily digest.ipynb",
   "output_path": "log.ipynb",
   "parameters": {},
   "start_time": "2024-10-02T04:10:34.031291",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0152954371d64a93b4153e1eccf60f3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0330ffe720db472b98aace0458a0398d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2278a0ef640841fa8c093ac6af644ca8",
       "placeholder": "​",
       "style": "IPY_MODEL_eeead7d82595461ebb849cdac3843fae",
       "tabbable": null,
       "tooltip": null,
       "value": " 7/7 [01:21&lt;00:00, 10.70s/it]"
      }
     },
     "07b3440bfe4c408fa6383f52c1e8fce9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2278a0ef640841fa8c093ac6af644ca8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "346351d7a9b6442fa35037ba1c92d921": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_36ec14fff82746b78b39bb0f5717564f",
        "IPY_MODEL_6f611ab0e30548d3b8446e92e9ca7c93",
        "IPY_MODEL_0330ffe720db472b98aace0458a0398d"
       ],
       "layout": "IPY_MODEL_9b8891c95a9e4db58e1b41721438824b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "36ec14fff82746b78b39bb0f5717564f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0152954371d64a93b4153e1eccf60f3b",
       "placeholder": "​",
       "style": "IPY_MODEL_07b3440bfe4c408fa6383f52c1e8fce9",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "6f611ab0e30548d3b8446e92e9ca7c93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_890b115b33294390bbb129c8759fed7d",
       "max": 7.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e247b2fd56c54a3fa530afee6aeadf6c",
       "tabbable": null,
       "tooltip": null,
       "value": 7.0
      }
     },
     "890b115b33294390bbb129c8759fed7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b8891c95a9e4db58e1b41721438824b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e247b2fd56c54a3fa530afee6aeadf6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eeead7d82595461ebb849cdac3843fae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}